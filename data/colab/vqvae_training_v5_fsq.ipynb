{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQ-VAE v5 Training - FSQ + Terrain-Aware Metrics\n",
    "\n",
    "## Key Changes from v4\n",
    "\n",
    "| Change | v4 | v5 |\n",
    "|--------|-----|-----|\n",
    "| Quantization | VQ-VAE (EMA codebook) | **FSQ (Finite Scalar Quantization)** |\n",
    "| Codebook | 512 learned codes | **390,625 implicit codes** |\n",
    "| Collapse risk | High (97% similarity) | **None (by design)** |\n",
    "| Terrain handling | None | **Terrain-weighted loss + metrics** |\n",
    "| Key metric | Structure Recall | **Building Accuracy** (excludes terrain) |\n",
    "\n",
    "## Why FSQ?\n",
    "\n",
    "Our v4 codebook collapsed - all 512 codes had 0.97 cosine similarity.\n",
    "FSQ eliminates this by using fixed quantization levels instead of learned codes.\n",
    "\n",
    "## Why Terrain-Aware?\n",
    "\n",
    "Many builds sit on terrain bases (dirt, grass). Reconstructing flat terrain\n",
    "is trivial and inflates our metrics. By separating terrain from buildings,\n",
    "we get a truer picture of reconstruction quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/minecraft_ai/vqvae_v5'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Output will be saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any, Set\n",
    "from collections import Counter\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Configuration\n",
    "\n",
    "**IMPORTANT**: Update the data paths below to match your Google Drive structure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data Paths (UPDATE THESE FOR YOUR DRIVE) ===\n",
    "DRIVE_BASE = '/content/drive/MyDrive/minecraft_ai'\n",
    "\n",
    "DATA_DIR = f\"{DRIVE_BASE}/splits/train\"      # Training H5 files\n",
    "VAL_DIR = f\"{DRIVE_BASE}/splits/val\"         # Validation H5 files\n",
    "VOCAB_PATH = f\"{DRIVE_BASE}/tok2block.json\"  # Token to block mapping\n",
    "V3_EMBEDDINGS_PATH = f\"{DRIVE_BASE}/block_embeddings_v3.npy\"  # V3 embeddings\n",
    "\n",
    "OUTPUT_DIR = f\"{DRIVE_BASE}/vqvae_v5\"        # Output directory\n",
    "\n",
    "# === V5 Model Architecture ===\n",
    "HIDDEN_DIMS = [96, 192]  # 2 stages for 32->8\n",
    "LATENT_DIM = 8  # FSQ dimension (NOT 256 like v4)\n",
    "FSQ_LEVELS = [5, 5, 5, 5, 5, 5, 5, 5]  # 8 dims x 5 levels = 390,625 implicit codes\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# === FSQ Settings (replaces VQ) ===\n",
    "# No commitment cost, no EMA decay - FSQ has no learned codebook!\n",
    "\n",
    "# === Structure weights ===\n",
    "STRUCTURE_WEIGHT = 50.0\n",
    "FALSE_AIR_WEIGHT = 5.0\n",
    "VOLUME_WEIGHT = 2.0\n",
    "STRUCTURE_TO_AIR_WEIGHT = 10.0\n",
    "USE_SHAPE_LOSS = True\n",
    "USE_ASYMMETRIC_LOSS = True\n",
    "\n",
    "# === TERRAIN SETTINGS (NEW in v5) ===\n",
    "TERRAIN_WEIGHT = 0.2  # Lower weight for terrain blocks\n",
    "BUILDING_WEIGHT = 1.0  # Full weight for building blocks\n",
    "AIR_WEIGHT = 0.1  # Very low weight for air\n",
    "\n",
    "# === Training ===\n",
    "TOTAL_EPOCHS = 15\n",
    "BATCH_SIZE = 4\n",
    "BASE_LR = 3e-4\n",
    "USE_AMP = True\n",
    "GRAD_ACCUM_STEPS = 4\n",
    "\n",
    "SEED = 42\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "# Calculate implicit codebook size\n",
    "IMPLICIT_CODEBOOK_SIZE = int(np.prod(FSQ_LEVELS))\n",
    "\n",
    "print(\"VQ-VAE v5 (FSQ) Configuration:\")\n",
    "print(f\"  Latent grid: 8x8x8\")\n",
    "print(f\"  FSQ levels: {FSQ_LEVELS}\")\n",
    "print(f\"  Implicit codebook size: {IMPLICIT_CODEBOOK_SIZE:,}\")\n",
    "print(f\"  Hidden dims: {HIDDEN_DIMS}\")\n",
    "print(f\"  Epochs: {TOTAL_EPOCHS}\")\n",
    "print(f\"\\nTerrain-Aware Training (NEW):\")\n",
    "print(f\"  Terrain weight: {TERRAIN_WEIGHT}\")\n",
    "print(f\"  Building weight: {BUILDING_WEIGHT}\")\n",
    "print(f\"  Air weight: {AIR_WEIGHT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Load Vocabulary and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VOCAB_PATH, 'r') as f:\n",
    "    tok2block = {int(k): v for k, v in json.load(f).items()}\n",
    "\n",
    "block2tok = {v: k for k, v in tok2block.items()}\n",
    "VOCAB_SIZE = len(tok2block)\n",
    "print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
    "\n",
    "# Find air tokens\n",
    "AIR_TOKENS: Set[int] = set()\n",
    "for tok, block in tok2block.items():\n",
    "    if 'air' in block.lower() and 'stair' not in block.lower():\n",
    "        AIR_TOKENS.add(tok)\n",
    "        print(f\"  Air token: {tok} = {block}\")\n",
    "\n",
    "AIR_TOKENS_LIST = sorted(AIR_TOKENS)\n",
    "AIR_TOKENS_TENSOR = torch.tensor(AIR_TOKENS_LIST, dtype=torch.long)\n",
    "\n",
    "# Load V3 embeddings\n",
    "v3_embeddings = np.load(V3_EMBEDDINGS_PATH).astype(np.float32)\n",
    "EMBEDDING_DIM = v3_embeddings.shape[1]\n",
    "print(f\"V3 embeddings: {v3_embeddings.shape} (dim={EMBEDDING_DIM})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Terrain Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TERRAIN_BLOCKS: Set[str] = {\n",
    "    # Dirt family\n",
    "    'minecraft:dirt', 'minecraft:grass_block', 'minecraft:coarse_dirt',\n",
    "    'minecraft:podzol', 'minecraft:mycelium', 'minecraft:rooted_dirt',\n",
    "    'minecraft:dirt_path', 'minecraft:farmland', 'minecraft:mud',\n",
    "\n",
    "    # Stone family\n",
    "    'minecraft:stone', 'minecraft:cobblestone', 'minecraft:mossy_cobblestone',\n",
    "    'minecraft:bedrock', 'minecraft:deepslate', 'minecraft:tuff',\n",
    "    'minecraft:granite', 'minecraft:diorite', 'minecraft:andesite',\n",
    "\n",
    "    # Sand family\n",
    "    'minecraft:sand', 'minecraft:red_sand', 'minecraft:gravel', 'minecraft:clay',\n",
    "\n",
    "    # Water\n",
    "    'minecraft:water', 'minecraft:lava',\n",
    "\n",
    "    # Terracotta\n",
    "    'minecraft:terracotta', 'minecraft:white_terracotta', 'minecraft:orange_terracotta',\n",
    "    'minecraft:brown_terracotta', 'minecraft:red_terracotta',\n",
    "\n",
    "    # Netherrack\n",
    "    'minecraft:netherrack', 'minecraft:soul_sand', 'minecraft:soul_soil',\n",
    "\n",
    "    # End\n",
    "    'minecraft:end_stone',\n",
    "\n",
    "    # Snow/Ice\n",
    "    'minecraft:snow_block', 'minecraft:ice', 'minecraft:packed_ice',\n",
    "}\n",
    "\n",
    "# Build terrain token set\n",
    "TERRAIN_TOKENS: Set[int] = set()\n",
    "for tok, block in tok2block.items():\n",
    "    base_name = block.split('[')[0] if '[' in block else block\n",
    "    if base_name in TERRAIN_BLOCKS:\n",
    "        TERRAIN_TOKENS.add(tok)\n",
    "\n",
    "TERRAIN_TOKENS_TENSOR = torch.tensor(sorted(TERRAIN_TOKENS), dtype=torch.long)\n",
    "print(f\"Terrain tokens: {len(TERRAIN_TOKENS)}\")\n",
    "\n",
    "def detect_terrain(block_ids: torch.Tensor, device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"Return mask where True = terrain block (excludes air).\"\"\"\n",
    "    terrain_tensor = TERRAIN_TOKENS_TENSOR.to(device)\n",
    "    air_tensor = AIR_TOKENS_TENSOR.to(device)\n",
    "\n",
    "    is_terrain = torch.isin(block_ids, terrain_tensor)\n",
    "    is_air = torch.isin(block_ids, air_tensor)\n",
    "\n",
    "    return is_terrain & ~is_air"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAEDataset(Dataset):\n",
    "    def __init__(self, data_dir: str):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.h5_files = sorted(self.data_dir.glob(\"*.h5\"))\n",
    "        if not self.h5_files:\n",
    "            raise ValueError(f\"No H5 files in {data_dir}\")\n",
    "        print(f\"Found {len(self.h5_files)} structures in {data_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.h5_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.h5_files[idx], 'r') as f:\n",
    "            key = list(f.keys())[0]\n",
    "            structure = f[key][:].astype(np.int64)\n",
    "        return torch.from_numpy(structure).long()\n",
    "\n",
    "train_dataset = VQVAEDataset(DATA_DIR)\n",
    "val_dataset = VQVAEDataset(VAL_DIR)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: FSQ Module (replaces VQ-VAE codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSQ(nn.Module):\n",
    "    \"\"\"\n",
    "    Finite Scalar Quantization - no learned codebook, no collapse.\n",
    "\n",
    "    Each dimension is quantized to fixed levels.\n",
    "    Implicit codebook size = product of all levels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, levels: List[int], eps: float = 1e-3):\n",
    "        super().__init__()\n",
    "        self.levels = levels\n",
    "        self.dim = len(levels)\n",
    "        self.eps = eps\n",
    "        self.codebook_size = int(np.prod(levels))\n",
    "\n",
    "        self.register_buffer('_levels', torch.tensor(levels, dtype=torch.float32))\n",
    "\n",
    "        # Precompute for index calculation\n",
    "        basis = []\n",
    "        acc = 1\n",
    "        for L in reversed(levels):\n",
    "            basis.append(acc)\n",
    "            acc *= L\n",
    "        self.register_buffer('_basis', torch.tensor(list(reversed(basis)), dtype=torch.long))\n",
    "\n",
    "        half_levels = [(L - 1) / 2 for L in levels]\n",
    "        self.register_buffer('_half_levels', torch.tensor(half_levels, dtype=torch.float32))\n",
    "\n",
    "        # Track usage for metrics\n",
    "        self.register_buffer('_usage', torch.zeros(self.codebook_size))\n",
    "\n",
    "    def reset_usage(self):\n",
    "        self._usage.zero_()\n",
    "\n",
    "    def get_usage_stats(self) -> Tuple[float, float]:\n",
    "        \"\"\"Return (usage_fraction, perplexity).\"\"\"\n",
    "        usage = (self._usage > 0).float().mean().item()\n",
    "\n",
    "        if self._usage.sum() == 0:\n",
    "            return usage, 0.0\n",
    "\n",
    "        probs = self._usage / self._usage.sum()\n",
    "        probs = probs[probs > 0]\n",
    "        entropy = -(probs * probs.log()).sum()\n",
    "        perplexity = entropy.exp().item()\n",
    "\n",
    "        return usage, perplexity\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Quantize latent vectors.\n",
    "\n",
    "        Args:\n",
    "            z: Shape [..., dim] continuous latent vectors\n",
    "\n",
    "        Returns:\n",
    "            z_q: Quantized vectors, same shape\n",
    "            indices: Integer indices [...], each in [0, codebook_size)\n",
    "        \"\"\"\n",
    "        # Bound to (-1, 1)\n",
    "        z_bounded = torch.tanh(z)\n",
    "\n",
    "        # Quantize each dimension\n",
    "        z_q_list = []\n",
    "        for i in range(self.dim):\n",
    "            L = self._levels[i]\n",
    "            half_L = self._half_levels[i]\n",
    "\n",
    "            z_i = z_bounded[..., i]\n",
    "            z_i = z_i * half_L\n",
    "            z_i = torch.round(z_i)\n",
    "            z_i = torch.clamp(z_i, -half_L, half_L)\n",
    "            z_i = z_i / half_L\n",
    "\n",
    "            z_q_list.append(z_i)\n",
    "\n",
    "        z_q = torch.stack(z_q_list, dim=-1)\n",
    "\n",
    "        # Straight-through estimator\n",
    "        z_q = z_bounded + (z_q - z_bounded).detach()\n",
    "\n",
    "        # Compute indices\n",
    "        indices = torch.zeros(z_q.shape[:-1], dtype=torch.long, device=z_q.device)\n",
    "        for i in range(self.dim):\n",
    "            L = self._levels[i].long()\n",
    "            half_L = self._half_levels[i]\n",
    "            z_i = z_q[..., i]\n",
    "            level_idx = ((z_i * half_L) + half_L).round().long()\n",
    "            level_idx = torch.clamp(level_idx, 0, L - 1)\n",
    "            indices = indices + level_idx * self._basis[i]\n",
    "\n",
    "        # Track usage\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                for idx in indices.unique():\n",
    "                    if idx < self.codebook_size:\n",
    "                        self._usage[idx] += (indices == idx).sum()\n",
    "\n",
    "        return z_q, indices\n",
    "\n",
    "print(f\"FSQ module: {FSQ_LEVELS} -> {IMPLICIT_CODEBOOK_SIZE:,} implicit codes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: VQ-VAE v5 Architecture with FSQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock3D(nn.Module):\n",
    "    def __init__(self, channels: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(channels, channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(channels, channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(channels)\n",
    "        self.bn2 = nn.BatchNorm3d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        return F.relu(x + residual)\n",
    "\n",
    "\n",
    "class EncoderV5(nn.Module):\n",
    "    \"\"\"32x32x32 -> 8x8x8 encoder, outputs FSQ dimension.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, hidden_dims: List[int], fsq_dim: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        current = in_channels\n",
    "\n",
    "        for h in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Conv3d(current, h, 4, stride=2, padding=1),\n",
    "                nn.BatchNorm3d(h),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout3d(dropout),\n",
    "                ResidualBlock3D(h),\n",
    "            ])\n",
    "            current = h\n",
    "\n",
    "        layers.extend([\n",
    "            ResidualBlock3D(current),\n",
    "            ResidualBlock3D(current),\n",
    "            nn.Conv3d(current, fsq_dim, 3, padding=1),  # Output FSQ dim\n",
    "        ])\n",
    "\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "class DecoderV5(nn.Module):\n",
    "    \"\"\"8x8x8 -> 32x32x32 decoder, takes FSQ dimension as input.\"\"\"\n",
    "\n",
    "    def __init__(self, fsq_dim: int, hidden_dims: List[int], num_blocks: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # First expand FSQ dim to first hidden dim\n",
    "        layers = [\n",
    "            nn.Conv3d(fsq_dim, hidden_dims[0], 3, padding=1),\n",
    "            nn.BatchNorm3d(hidden_dims[0]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ResidualBlock3D(hidden_dims[0]),\n",
    "            ResidualBlock3D(hidden_dims[0]),\n",
    "        ]\n",
    "\n",
    "        current = hidden_dims[0]\n",
    "        for h in hidden_dims[1:]:\n",
    "            layers.extend([\n",
    "                ResidualBlock3D(current),\n",
    "                nn.ConvTranspose3d(current, h, 4, stride=2, padding=1),\n",
    "                nn.BatchNorm3d(h),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout3d(dropout),\n",
    "            ])\n",
    "            current = h\n",
    "\n",
    "        # Final upsample and output\n",
    "        layers.extend([\n",
    "            ResidualBlock3D(current),\n",
    "            nn.ConvTranspose3d(current, current, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(current),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(current, num_blocks, 3, padding=1),\n",
    "        ])\n",
    "\n",
    "        self.decoder = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z_q):\n",
    "        return self.decoder(z_q)\n",
    "\n",
    "\n",
    "class TerrainWeightedLoss(nn.Module):\n",
    "    \"\"\"Cross-entropy with lower weight for terrain blocks.\"\"\"\n",
    "\n",
    "    def __init__(self, terrain_weight: float = 0.2, building_weight: float = 1.0, air_weight: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.terrain_weight = terrain_weight\n",
    "        self.building_weight = building_weight\n",
    "        self.air_weight = air_weight\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor,\n",
    "                terrain_mask: torch.Tensor, air_mask: torch.Tensor) -> torch.Tensor:\n",
    "        ce_loss = F.cross_entropy(logits, targets, reduction='none')\n",
    "\n",
    "        weights = torch.full_like(ce_loss, self.building_weight)\n",
    "        weights[terrain_mask] = self.terrain_weight\n",
    "        weights[air_mask] = self.air_weight\n",
    "\n",
    "        return (ce_loss * weights).sum() / weights.sum()\n",
    "\n",
    "\n",
    "class VQVAEv5(nn.Module):\n",
    "    \"\"\"VQ-VAE v5 with FSQ and terrain-aware training.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size: int, emb_dim: int, hidden_dims: List[int],\n",
    "                 fsq_levels: List[int], pretrained_emb: np.ndarray,\n",
    "                 terrain_weight: float = 0.2, building_weight: float = 1.0,\n",
    "                 air_weight: float = 0.1, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_dim = emb_dim\n",
    "        self.fsq_dim = len(fsq_levels)\n",
    "\n",
    "        # Embeddings (frozen - no point training with FSQ)\n",
    "        self.block_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.block_emb.weight.data.copy_(torch.from_numpy(pretrained_emb))\n",
    "        self.block_emb.weight.requires_grad = False\n",
    "\n",
    "        # Encoder: 32x32x32 -> 8x8x8 x fsq_dim\n",
    "        self.encoder = EncoderV5(emb_dim, hidden_dims, self.fsq_dim, dropout)\n",
    "\n",
    "        # FSQ: quantize to implicit codebook\n",
    "        self.fsq = FSQ(fsq_levels)\n",
    "\n",
    "        # Decoder: 8x8x8 x fsq_dim -> 32x32x32 x vocab_size\n",
    "        # Note: hidden_dims reversed for upsampling\n",
    "        self.decoder = DecoderV5(self.fsq_dim, list(reversed(hidden_dims)), vocab_size, dropout)\n",
    "\n",
    "        # Terrain-weighted loss\n",
    "        self.terrain_loss = TerrainWeightedLoss(terrain_weight, building_weight, air_weight)\n",
    "\n",
    "    def forward(self, block_ids: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        # Embed blocks\n",
    "        x = self.block_emb(block_ids)  # [B, X, Y, Z, emb_dim]\n",
    "        x = x.permute(0, 4, 1, 2, 3).contiguous()  # [B, emb_dim, X, Y, Z]\n",
    "\n",
    "        # Encode\n",
    "        z_e = self.encoder(x)  # [B, fsq_dim, 8, 8, 8]\n",
    "\n",
    "        # Permute for FSQ: [B, 8, 8, 8, fsq_dim]\n",
    "        z_e = z_e.permute(0, 2, 3, 4, 1).contiguous()\n",
    "\n",
    "        # Quantize with FSQ\n",
    "        z_q, indices = self.fsq(z_e)\n",
    "\n",
    "        # Permute back: [B, fsq_dim, 8, 8, 8]\n",
    "        z_q = z_q.permute(0, 4, 1, 2, 3).contiguous()\n",
    "\n",
    "        # Decode\n",
    "        logits = self.decoder(z_q)  # [B, vocab_size, X, Y, Z]\n",
    "\n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'indices': indices,\n",
    "            'z_e': z_e,\n",
    "            'z_q': z_q,\n",
    "        }\n",
    "\n",
    "    def compute_loss(self, block_ids: torch.Tensor,\n",
    "                     air_tokens: torch.Tensor,\n",
    "                     terrain_tokens: torch.Tensor,\n",
    "                     structure_weight: float = 50.0,\n",
    "                     use_terrain_weighting: bool = True) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Compute loss with terrain-aware weighting.\"\"\"\n",
    "\n",
    "        out = self(block_ids)\n",
    "        logits = out['logits']\n",
    "\n",
    "        # Flatten for loss computation\n",
    "        B, C, X, Y, Z = logits.shape\n",
    "        logits_flat = logits.permute(0, 2, 3, 4, 1).reshape(-1, C)\n",
    "        targets_flat = block_ids.view(-1)\n",
    "\n",
    "        device = targets_flat.device\n",
    "        air_dev = air_tokens.to(device)\n",
    "        terrain_dev = terrain_tokens.to(device)\n",
    "\n",
    "        # Masks\n",
    "        is_air = torch.isin(targets_flat, air_dev)\n",
    "        is_terrain = torch.isin(targets_flat, terrain_dev) & ~is_air\n",
    "        is_building = ~is_air & ~is_terrain\n",
    "\n",
    "        # Primary loss: terrain-weighted CE\n",
    "        if use_terrain_weighting:\n",
    "            loss = self.terrain_loss(logits_flat, targets_flat, is_terrain, is_air)\n",
    "        else:\n",
    "            # Fallback: structure-weighted CE\n",
    "            weights = torch.ones_like(targets_flat, dtype=torch.float)\n",
    "            weights[~is_air] = structure_weight\n",
    "            ce = F.cross_entropy(logits_flat, targets_flat, reduction='none')\n",
    "            loss = (weights * ce).sum() / weights.sum()\n",
    "\n",
    "        # Compute metrics\n",
    "        with torch.no_grad():\n",
    "            preds = logits_flat.argmax(dim=1)\n",
    "            is_air_pred = torch.isin(preds, air_dev)\n",
    "\n",
    "            # Overall accuracy\n",
    "            correct = (preds == targets_flat).float()\n",
    "            overall_acc = correct.mean()\n",
    "\n",
    "            # Terrain accuracy\n",
    "            if is_terrain.any():\n",
    "                terrain_acc = correct[is_terrain].mean()\n",
    "            else:\n",
    "                terrain_acc = torch.tensor(0.0, device=device)\n",
    "\n",
    "            # Building accuracy (THE KEY METRIC)\n",
    "            if is_building.any():\n",
    "                building_acc = correct[is_building].mean()\n",
    "\n",
    "                # Building recall\n",
    "                building_preserved = is_building & ~is_air_pred\n",
    "                building_recall = building_preserved.sum().float() / is_building.sum().float()\n",
    "\n",
    "                # Building false air\n",
    "                building_erased = is_building & is_air_pred\n",
    "                building_false_air = building_erased.sum().float() / is_building.sum().float()\n",
    "            else:\n",
    "                building_acc = torch.tensor(0.0, device=device)\n",
    "                building_recall = torch.tensor(0.0, device=device)\n",
    "                building_false_air = torch.tensor(0.0, device=device)\n",
    "\n",
    "            # Structure metrics (terrain + building)\n",
    "            is_struct = ~is_air\n",
    "            if is_struct.any():\n",
    "                struct_acc = correct[is_struct].mean()\n",
    "                struct_preserved = is_struct & ~is_air_pred\n",
    "                struct_recall = struct_preserved.sum().float() / is_struct.sum().float()\n",
    "            else:\n",
    "                struct_acc = torch.tensor(0.0, device=device)\n",
    "                struct_recall = torch.tensor(0.0, device=device)\n",
    "\n",
    "            # Volume ratio\n",
    "            orig_vol = is_struct.sum().float()\n",
    "            pred_vol = (~is_air_pred).sum().float()\n",
    "            vol_ratio = pred_vol / orig_vol if orig_vol > 0 else torch.tensor(1.0, device=device)\n",
    "\n",
    "            # Composition stats\n",
    "            total = targets_flat.numel()\n",
    "            terrain_frac = is_terrain.sum().float() / total\n",
    "            building_frac = is_building.sum().float() / total\n",
    "\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'overall_acc': overall_acc,\n",
    "            'terrain_acc': terrain_acc,\n",
    "            'building_acc': building_acc,  # THE KEY METRIC\n",
    "            'building_recall': building_recall,\n",
    "            'building_false_air': building_false_air,\n",
    "            'struct_acc': struct_acc,\n",
    "            'struct_recall': struct_recall,\n",
    "            'vol_ratio': vol_ratio,\n",
    "            'terrain_frac': terrain_frac,\n",
    "            'building_frac': building_frac,\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"VQ-VAE v5 architecture with FSQ and terrain-awareness defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, scaler, device,\n",
    "                air_tokens, terrain_tokens, structure_weight):\n",
    "    model.train()\n",
    "    model.fsq.reset_usage()\n",
    "\n",
    "    metrics = {k: 0.0 for k in [\n",
    "        'loss', 'overall_acc', 'terrain_acc', 'building_acc',\n",
    "        'building_recall', 'building_false_air', 'struct_acc',\n",
    "        'struct_recall', 'vol_ratio', 'terrain_frac', 'building_frac'\n",
    "    ]}\n",
    "    n = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for batch_idx, batch in enumerate(tqdm(loader, desc=\"Train\", leave=False)):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        with torch.amp.autocast('cuda', enabled=USE_AMP):\n",
    "            out = model.compute_loss(batch, air_tokens, terrain_tokens, structure_weight)\n",
    "            loss = out['loss'] / GRAD_ACCUM_STEPS\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (batch_idx + 1) % GRAD_ACCUM_STEPS == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        for k in metrics:\n",
    "            if k in out:\n",
    "                metrics[k] += out[k].item() if torch.is_tensor(out[k]) else out[k]\n",
    "        n += 1\n",
    "\n",
    "    # FSQ usage stats\n",
    "    usage, perplexity = model.fsq.get_usage_stats()\n",
    "    metrics['fsq_usage'] = usage\n",
    "    metrics['fsq_perplexity'] = perplexity\n",
    "\n",
    "    return {k: v/n if k not in ['fsq_usage', 'fsq_perplexity'] else v for k, v in metrics.items()}\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, device, air_tokens, terrain_tokens, structure_weight):\n",
    "    model.eval()\n",
    "    model.fsq.reset_usage()\n",
    "\n",
    "    metrics = {k: 0.0 for k in [\n",
    "        'loss', 'overall_acc', 'terrain_acc', 'building_acc',\n",
    "        'building_recall', 'building_false_air', 'struct_acc',\n",
    "        'struct_recall', 'vol_ratio', 'terrain_frac', 'building_frac'\n",
    "    ]}\n",
    "    n = 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Val\", leave=False):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        with torch.amp.autocast('cuda', enabled=USE_AMP):\n",
    "            out = model.compute_loss(batch, air_tokens, terrain_tokens, structure_weight)\n",
    "\n",
    "        for k in metrics:\n",
    "            if k in out:\n",
    "                metrics[k] += out[k].item() if torch.is_tensor(out[k]) else out[k]\n",
    "        n += 1\n",
    "\n",
    "    usage, perplexity = model.fsq.get_usage_stats()\n",
    "    metrics['fsq_usage'] = usage\n",
    "    metrics['fsq_perplexity'] = perplexity\n",
    "\n",
    "    return {k: v/n if k not in ['fsq_usage', 'fsq_perplexity'] else v for k, v in metrics.items()}\n",
    "\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Create Model and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Data loaders\n",
    "g = torch.Generator().manual_seed(SEED)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True, generator=g)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "# Create model\n",
    "model = VQVAEv5(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    emb_dim=EMBEDDING_DIM,\n",
    "    hidden_dims=HIDDEN_DIMS,\n",
    "    fsq_levels=FSQ_LEVELS,\n",
    "    pretrained_emb=v3_embeddings,\n",
    "    terrain_weight=TERRAIN_WEIGHT,\n",
    "    building_weight=BUILDING_WEIGHT,\n",
    "    air_weight=AIR_WEIGHT,\n",
    "    dropout=DROPOUT,\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total params: {total_params:,}\")\n",
    "print(f\"Trainable params: {trainable_params:,}\")\n",
    "print(f\"FSQ implicit codebook: {model.fsq.codebook_size:,}\")\n",
    "\n",
    "# Optimizer (no embedding params - they're frozen)\n",
    "optimizer = optim.AdamW(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    lr=BASE_LR,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP)\n",
    "\n",
    "print(f\"\\nOptimizer: AdamW, LR={BASE_LR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"VQ-VAE V5 TRAINING - FSQ + TERRAIN-AWARE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Key Differences from v4:\")\n",
    "print(f\"  - FSQ instead of VQ-VAE (no codebook collapse possible)\")\n",
    "print(f\"  - Terrain-weighted loss (buildings prioritized)\")\n",
    "print(f\"  - Building accuracy as key metric (not inflated by terrain)\")\n",
    "print()\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'train_building_acc': [], 'train_building_recall': [],\n",
    "    'train_terrain_acc': [], 'train_struct_recall': [],\n",
    "    'train_fsq_usage': [], 'train_fsq_perplexity': [],\n",
    "    'val_loss': [], 'val_building_acc': [], 'val_building_recall': [],\n",
    "    'val_terrain_acc': [], 'val_struct_recall': [],\n",
    "    'val_fsq_usage': [], 'val_fsq_perplexity': [],\n",
    "}\n",
    "\n",
    "best_building_acc = 0  # Track building accuracy as key metric\n",
    "best_epoch = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(TOTAL_EPOCHS):\n",
    "    # Train\n",
    "    train_m = train_epoch(model, train_loader, optimizer, scaler, device,\n",
    "                          AIR_TOKENS_TENSOR, TERRAIN_TOKENS_TENSOR, STRUCTURE_WEIGHT)\n",
    "\n",
    "    # Validate\n",
    "    val_m = validate(model, val_loader, device,\n",
    "                     AIR_TOKENS_TENSOR, TERRAIN_TOKENS_TENSOR, STRUCTURE_WEIGHT)\n",
    "\n",
    "    # Record\n",
    "    history['train_loss'].append(train_m['loss'])\n",
    "    history['train_building_acc'].append(train_m['building_acc'])\n",
    "    history['train_building_recall'].append(train_m['building_recall'])\n",
    "    history['train_terrain_acc'].append(train_m['terrain_acc'])\n",
    "    history['train_struct_recall'].append(train_m['struct_recall'])\n",
    "    history['train_fsq_usage'].append(train_m['fsq_usage'])\n",
    "    history['train_fsq_perplexity'].append(train_m['fsq_perplexity'])\n",
    "\n",
    "    history['val_loss'].append(val_m['loss'])\n",
    "    history['val_building_acc'].append(val_m['building_acc'])\n",
    "    history['val_building_recall'].append(val_m['building_recall'])\n",
    "    history['val_terrain_acc'].append(val_m['terrain_acc'])\n",
    "    history['val_struct_recall'].append(val_m['struct_recall'])\n",
    "    history['val_fsq_usage'].append(val_m['fsq_usage'])\n",
    "    history['val_fsq_perplexity'].append(val_m['fsq_perplexity'])\n",
    "\n",
    "    # Best model - track BUILDING ACCURACY as key metric\n",
    "    if val_m['building_acc'] > best_building_acc:\n",
    "        best_building_acc = val_m['building_acc']\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v5_best.pt\")\n",
    "\n",
    "    # Log\n",
    "    print(f\"Epoch {epoch+1:2d} | \"\n",
    "          f\"Building: {train_m['building_acc']:.1%}/{val_m['building_acc']:.1%} | \"\n",
    "          f\"Terrain: {train_m['terrain_acc']:.1%}/{val_m['terrain_acc']:.1%} | \"\n",
    "          f\"Recall: {val_m['building_recall']:.1%} | \"\n",
    "          f\"FSQ: {val_m['fsq_usage']:.0%} ({val_m['fsq_perplexity']:.0f})\")\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "print(f\"\\nTraining complete in {train_time/60:.1f} minutes\")\n",
    "print(f\"Best val building accuracy: {best_building_acc:.1%} at epoch {best_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(20, 8))\n",
    "epochs = range(1, TOTAL_EPOCHS + 1)\n",
    "\n",
    "# Building Accuracy (KEY METRIC)\n",
    "ax = axes[0, 0]\n",
    "ax.plot(epochs, history['train_building_acc'], 'b-', label='Train', linewidth=2)\n",
    "ax.plot(epochs, history['val_building_acc'], 'r--', label='Val', linewidth=2)\n",
    "ax.set_title('Building Accuracy (KEY METRIC)', fontweight='bold')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Building Recall\n",
    "ax = axes[0, 1]\n",
    "ax.plot(epochs, history['train_building_recall'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_building_recall'], 'r--', label='Val')\n",
    "ax.axhline(y=0.9, color='green', linestyle='--', alpha=0.5, label='Target')\n",
    "ax.set_title('Building Recall')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Terrain Accuracy\n",
    "ax = axes[0, 2]\n",
    "ax.plot(epochs, history['train_terrain_acc'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_terrain_acc'], 'r--', label='Val')\n",
    "ax.set_title('Terrain Accuracy (easy)')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Struct Recall (combined)\n",
    "ax = axes[0, 3]\n",
    "ax.plot(epochs, history['train_struct_recall'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_struct_recall'], 'r--', label='Val')\n",
    "ax.set_title('Structure Recall (combined)')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "ax = axes[1, 0]\n",
    "ax.plot(epochs, history['train_loss'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_loss'], 'r--', label='Val')\n",
    "ax.set_title('Loss')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# FSQ Usage\n",
    "ax = axes[1, 1]\n",
    "ax.plot(epochs, history['train_fsq_usage'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_fsq_usage'], 'r--', label='Val')\n",
    "ax.set_title('FSQ Code Usage')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# FSQ Perplexity\n",
    "ax = axes[1, 2]\n",
    "ax.plot(epochs, history['train_fsq_perplexity'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_fsq_perplexity'], 'r--', label='Val')\n",
    "ax.set_title('FSQ Perplexity (effective codes)')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Final metrics comparison\n",
    "ax = axes[1, 3]\n",
    "final = {\n",
    "    'Building\\nAcc': history['val_building_acc'][-1],\n",
    "    'Building\\nRecall': history['val_building_recall'][-1],\n",
    "    'Terrain\\nAcc': history['val_terrain_acc'][-1],\n",
    "    'Struct\\nRecall': history['val_struct_recall'][-1],\n",
    "}\n",
    "colors = ['green', 'orange', 'gray', 'blue']\n",
    "bars = ax.bar(final.keys(), final.values(), color=colors)\n",
    "ax.set_title('Final Metrics')\n",
    "ax.set_ylim(0, 1)\n",
    "for bar, val in zip(bars, final.values()):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "            f'{val:.1%}', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/vqvae_v5_training.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'config': {\n",
    "        'hidden_dims': HIDDEN_DIMS,\n",
    "        'fsq_levels': FSQ_LEVELS,\n",
    "        'fsq_codebook_size': IMPLICIT_CODEBOOK_SIZE,\n",
    "        'total_epochs': TOTAL_EPOCHS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'base_lr': BASE_LR,\n",
    "        'structure_weight': STRUCTURE_WEIGHT,\n",
    "        'terrain_weight': TERRAIN_WEIGHT,\n",
    "        'building_weight': BUILDING_WEIGHT,\n",
    "        'air_weight': AIR_WEIGHT,\n",
    "        'seed': SEED,\n",
    "    },\n",
    "    'results': {\n",
    "        'best_building_acc': float(best_building_acc),\n",
    "        'best_epoch': best_epoch,\n",
    "        'final_building_acc': float(history['val_building_acc'][-1]),\n",
    "        'final_building_recall': float(history['val_building_recall'][-1]),\n",
    "        'final_terrain_acc': float(history['val_terrain_acc'][-1]),\n",
    "        'final_struct_recall': float(history['val_struct_recall'][-1]),\n",
    "        'final_fsq_usage': float(history['val_fsq_usage'][-1]),\n",
    "        'final_fsq_perplexity': float(history['val_fsq_perplexity'][-1]),\n",
    "        'training_time_min': float(train_time / 60),\n",
    "    },\n",
    "    'history': {k: [float(x) for x in v] for k, v in history.items()},\n",
    "}\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/vqvae_v5_results.json\", 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "# Save checkpoint\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': {\n",
    "        'vocab_size': VOCAB_SIZE,\n",
    "        'emb_dim': EMBEDDING_DIM,\n",
    "        'hidden_dims': HIDDEN_DIMS,\n",
    "        'fsq_levels': FSQ_LEVELS,\n",
    "        'terrain_weight': TERRAIN_WEIGHT,\n",
    "        'building_weight': BUILDING_WEIGHT,\n",
    "        'air_weight': AIR_WEIGHT,\n",
    "        'dropout': DROPOUT,\n",
    "    },\n",
    "    'air_tokens': AIR_TOKENS_LIST,\n",
    "    'terrain_tokens': sorted(TERRAIN_TOKENS),\n",
    "    'best_building_acc': float(best_building_acc),\n",
    "    'best_epoch': best_epoch,\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, f\"{OUTPUT_DIR}/vqvae_v5_best_checkpoint.pt\")\n",
    "torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v5_final.pt\")\n",
    "\n",
    "print(\"\\nResults saved:\")\n",
    "print(f\"  - {OUTPUT_DIR}/vqvae_v5_results.json\")\n",
    "print(f\"  - {OUTPUT_DIR}/vqvae_v5_best_checkpoint.pt\")\n",
    "print(f\"  - {OUTPUT_DIR}/vqvae_v5_final.pt\")\n",
    "print(f\"  - {OUTPUT_DIR}/vqvae_v5_training.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS - FSQ + TERRAIN-AWARE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best building accuracy: {best_building_acc:.1%} at epoch {best_epoch}\")\n",
    "print(f\"Final building recall:  {history['val_building_recall'][-1]:.1%}\")\n",
    "print(f\"Final terrain accuracy: {history['val_terrain_acc'][-1]:.1%}\")\n",
    "print(f\"FSQ perplexity:         {history['val_fsq_perplexity'][-1]:.0f} effective codes\")\n",
    "print(f\"Training time:          {train_time/60:.1f} minutes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY INSIGHT\")\n",
    "print(\"=\"*70)\n",
    "print(\"Building Accuracy is the honest metric that matters.\")\n",
    "print(\"It excludes trivial terrain blocks that inflate overall accuracy.\")\n",
    "print(\"If this is high, we're actually reconstructing buildings well.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
