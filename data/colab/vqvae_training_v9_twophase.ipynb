{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQ-VAE v9 Training - Two-Phase Volume Fix\n",
    "\n",
    "## Overview\n",
    "This notebook implements the v9 training strategy to fix the volume ratio problem (stuck at 2.0x in v8).\n",
    "\n",
    "## Key Innovations\n",
    "\n",
    "### 1. Two-Phase Training\n",
    "- **Phase 1 (epochs 1-10)**: Binary air/structure classification only\n",
    "  - Learns correct volume ratio FIRST\n",
    "  - Strong volume penalty (100x weight)\n",
    "  - No frequency weighting\n",
    "- **Phase 2 (epochs 11-40)**: Full vocabulary training\n",
    "  - Starts from Phase 1 checkpoint\n",
    "  - Model already knows air/structure boundary\n",
    "\n",
    "### 2. Asymmetric Focal Loss\n",
    "- Focal loss (gamma=2.0) focuses on hard examples\n",
    "- Air boost (3x) makes air predictions more valuable\n",
    "- Prevents model from \"coasting\" on easy predictions\n",
    "\n",
    "### 3. Volume-Aware Logit Adjustment\n",
    "- Dynamically adjusts air logits based on current volume ratio\n",
    "- If over-predicting: boost air logits to encourage more air predictions\n",
    "\n",
    "### 4. Reduced Frequency Cap\n",
    "- Cap reduced from 5.0x to 2.0x\n",
    "- Reduces incentive to over-predict rare blocks\n",
    "\n",
    "## Expected Results\n",
    "| Metric | v8-B (Failed) | v9 Target |\n",
    "|--------|---------------|----------|\n",
    "| Volume Ratio | 2.0x (stuck) | 0.9-1.1x |\n",
    "| Building Accuracy | 80% (fake) | 45-55% (real) |\n",
    "| Recall | 99.7% | 85-95% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup - Mount Google Drive\n",
    "\n",
    "**What this does (Technical):** Mounts Google Drive filesystem to access training data stored in the cloud. Creates output directory for model checkpoints and results.\n",
    "\n",
    "**What this does (Simple):** Connects to your Google Drive so we can load the Minecraft structure data and save our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "DRIVE_BASE = '/content/drive/MyDrive/minecraft_ai'\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/minecraft_ai/vqvae_v9'\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports\n",
    "\n",
    "**What this does (Technical):** Imports PyTorch for deep learning, numpy for numerical operations, h5py for reading HDF5 structure files, and matplotlib for plotting training curves.\n",
    "\n",
    "**What this does (Simple):** Loads all the software libraries we need to train our AI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Set, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RFSQ Quantization Module\n",
    "\n",
    "**What this does (Technical):** Implements Residual Finite Scalar Quantization (RFSQ) with LayerNorm conditioning. This discretizes continuous latent vectors into a finite set of codes, enabling the model to learn a compressed discrete representation. Uses straight-through estimator for gradient flow.\n",
    "\n",
    "**What this does (Simple):** Converts the AI's internal representation into discrete codes (like converting analog to digital). This compression forces the model to learn the most important features of Minecraft structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSQ(nn.Module):\n",
    "    \"\"\"Finite Scalar Quantization - quantizes each dimension to fixed levels.\"\"\"\n",
    "    def __init__(self, levels: List[int], eps: float = 1e-3):\n",
    "        super().__init__()\n",
    "        self.levels = levels\n",
    "        self.dim = len(levels)\n",
    "        self.eps = eps\n",
    "        self.codebook_size = int(np.prod(levels))\n",
    "        self.register_buffer('_levels', torch.tensor(levels, dtype=torch.float32))\n",
    "        basis = []\n",
    "        acc = 1\n",
    "        for L in reversed(levels):\n",
    "            basis.append(acc)\n",
    "            acc *= L\n",
    "        self.register_buffer('_basis', torch.tensor(list(reversed(basis)), dtype=torch.long))\n",
    "        half_levels = [(L - 1) / 2 for L in levels]\n",
    "        self.register_buffer('_half_levels', torch.tensor(half_levels, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        z_bounded = torch.tanh(z)\n",
    "        z_q = self._quantize(z_bounded)\n",
    "        z_q = z_bounded + (z_q - z_bounded).detach()  # Straight-through\n",
    "        indices = self._to_indices(z_q)\n",
    "        return z_q, indices\n",
    "\n",
    "    def _quantize(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        z_q_list = []\n",
    "        for i in range(self.dim):\n",
    "            half_L = self._half_levels[i]\n",
    "            z_i = z[..., i] * half_L\n",
    "            z_i = torch.round(z_i).clamp(-half_L, half_L) / half_L\n",
    "            z_q_list.append(z_i)\n",
    "        return torch.stack(z_q_list, dim=-1)\n",
    "\n",
    "    def _to_indices(self, z_q: torch.Tensor) -> torch.Tensor:\n",
    "        indices = torch.zeros(z_q.shape[:-1], dtype=torch.long, device=z_q.device)\n",
    "        for i in range(self.dim):\n",
    "            L = self._levels[i].long()\n",
    "            half_L = self._half_levels[i]\n",
    "            level_idx = ((z_q[..., i] * half_L) + half_L).round().long().clamp(0, L - 1)\n",
    "            indices = indices + level_idx * self._basis[i]\n",
    "        return indices\n",
    "\n",
    "    def get_codebook_usage(self, indices: torch.Tensor) -> Tuple[float, float]:\n",
    "        flat = indices.flatten()\n",
    "        counts = torch.bincount(flat, minlength=self.codebook_size).float()\n",
    "        usage = (counts > 0).float().mean().item()\n",
    "        probs = counts / counts.sum()\n",
    "        probs = probs[probs > 0]\n",
    "        entropy = -(probs * torch.log(probs)).sum()\n",
    "        perplexity = torch.exp(entropy).item()\n",
    "        return usage, perplexity\n",
    "\n",
    "\n",
    "class InvertibleLayerNorm(nn.Module):\n",
    "    \"\"\"LayerNorm that stores statistics for inverse transformation.\"\"\"\n",
    "    def __init__(self, num_features: int, eps: float = 1e-5):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(num_features))\n",
    "        self.bias = nn.Parameter(torch.zeros(num_features))\n",
    "        self.register_buffer('stored_mean', None, persistent=False)\n",
    "        self.register_buffer('stored_std', None, persistent=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.stored_mean = x.mean(dim=(1, 2, 3), keepdim=True)\n",
    "        self.stored_std = x.std(dim=(1, 2, 3), keepdim=True) + self.eps\n",
    "        x_norm = (x - self.stored_mean) / self.stored_std\n",
    "        return x_norm * self.weight + self.bias\n",
    "\n",
    "    def inverse(self, x_norm: torch.Tensor) -> torch.Tensor:\n",
    "        x = (x_norm - self.bias) / self.weight\n",
    "        return x * self.stored_std + self.stored_mean\n",
    "\n",
    "\n",
    "class RFSQStage(nn.Module):\n",
    "    \"\"\"Single stage of RFSQ with LayerNorm conditioning.\"\"\"\n",
    "    def __init__(self, levels: List[int]):\n",
    "        super().__init__()\n",
    "        self.fsq = FSQ(levels)\n",
    "        self.layernorm = InvertibleLayerNorm(len(levels))\n",
    "\n",
    "    def forward(self, residual: torch.Tensor):\n",
    "        z_norm = self.layernorm(residual)\n",
    "        z_q_norm, indices = self.fsq(z_norm)\n",
    "        z_q = self.layernorm.inverse(z_q_norm)\n",
    "        new_residual = residual - z_q\n",
    "        return z_q, new_residual, indices\n",
    "\n",
    "\n",
    "class RFSQ(nn.Module):\n",
    "    \"\"\"Residual FSQ with multiple stages.\"\"\"\n",
    "    def __init__(self, levels_per_stage: List[int], num_stages: int = 2):\n",
    "        super().__init__()\n",
    "        self.num_stages = num_stages\n",
    "        self.stages = nn.ModuleList([RFSQStage(levels_per_stage) for _ in range(num_stages)])\n",
    "        self._usage_indices = []\n",
    "\n",
    "    def reset_usage(self):\n",
    "        self._usage_indices = []\n",
    "\n",
    "    def forward(self, z: torch.Tensor):\n",
    "        residual = z\n",
    "        z_q_sum = torch.zeros_like(z)\n",
    "        all_indices = []\n",
    "        for stage in self.stages:\n",
    "            z_q, residual, indices = stage(residual)\n",
    "            z_q_sum = z_q_sum + z_q\n",
    "            all_indices.append(indices)\n",
    "        self._usage_indices.append(all_indices)\n",
    "        return z_q_sum, all_indices\n",
    "\n",
    "    def get_usage_stats(self) -> Dict:\n",
    "        if not self._usage_indices:\n",
    "            return {}\n",
    "        stats = {}\n",
    "        for stage_idx in range(self.num_stages):\n",
    "            all_stage_indices = torch.cat([b[stage_idx].flatten() for b in self._usage_indices])\n",
    "            usage, perplexity = self.stages[stage_idx].fsq.get_codebook_usage(all_stage_indices)\n",
    "            stats[f'stage{stage_idx}'] = (usage, perplexity)\n",
    "        return stats\n",
    "\n",
    "print(\"RFSQ modules defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. VQ-VAE v9 Architecture (8x8x8 Latent)\n",
    "\n",
    "**What this does (Technical):** Defines the encoder-decoder architecture with 8x8x8 latent resolution (reduced from v8's 16x16x16). The encoder compresses 32x32x32 input through convolutional layers to 8x8x8 latent space. The decoder reconstructs back to 32x32x32. Uses residual blocks for stable gradients.\n",
    "\n",
    "**What this does (Simple):** The neural network that learns to compress Minecraft structures into a small code and then expand them back. We use a smaller bottleneck (8x8x8) to force better compression and prevent volume bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock3D(nn.Module):\n",
    "    \"\"\"3D residual block with BatchNorm.\"\"\"\n",
    "    def __init__(self, channels: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(channels, channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(channels)\n",
    "        self.conv2 = nn.Conv3d(channels, channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        return F.relu(out + residual)\n",
    "\n",
    "\n",
    "class EncoderV9(nn.Module):\n",
    "    \"\"\"Encoder: 32x32x32 -> 8x8x8 latent (back to v6 resolution).\"\"\"\n",
    "    def __init__(self, in_channels: int = 40, hidden_dim: int = 128, rfsq_dim: int = 4):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, hidden_dim, 3, padding=1),\n",
    "            nn.BatchNorm3d(hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # 32 -> 16\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv3d(hidden_dim, hidden_dim, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.res1 = ResidualBlock3D(hidden_dim)\n",
    "        # 16 -> 8\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv3d(hidden_dim, hidden_dim, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.res2 = nn.Sequential(*[ResidualBlock3D(hidden_dim) for _ in range(4)])\n",
    "        self.proj = nn.Conv3d(hidden_dim, rfsq_dim, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        x = self.res1(self.down1(x))\n",
    "        x = self.res2(self.down2(x))\n",
    "        return self.proj(x)\n",
    "\n",
    "\n",
    "class DecoderV9(nn.Module):\n",
    "    \"\"\"Decoder: 8x8x8 latent -> 32x32x32 output.\"\"\"\n",
    "    def __init__(self, rfsq_dim: int = 4, hidden_dim: int = 128, num_blocks: int = 3717):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv3d(rfsq_dim, hidden_dim, 3, padding=1),\n",
    "            nn.BatchNorm3d(hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.res1 = nn.Sequential(*[ResidualBlock3D(hidden_dim) for _ in range(4)])\n",
    "        # 8 -> 16\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.ConvTranspose3d(hidden_dim, hidden_dim, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.res2 = ResidualBlock3D(hidden_dim)\n",
    "        # 16 -> 32\n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.ConvTranspose3d(hidden_dim, hidden_dim, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.final = nn.Conv3d(hidden_dim, num_blocks, 3, padding=1)\n",
    "\n",
    "    def forward(self, z_q):\n",
    "        x = self.initial(z_q)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(self.up1(x))\n",
    "        x = self.up2(x)\n",
    "        return self.final(x)\n",
    "\n",
    "\n",
    "class VQVAEv9(nn.Module):\n",
    "    \"\"\"VQ-VAE v9 with 8x8x8 latent and two-phase training support.\"\"\"\n",
    "    def __init__(self, vocab_size: int = 3717, emb_dim: int = 40, hidden_dim: int = 128,\n",
    "                 rfsq_levels: List[int] = None, num_stages: int = 2,\n",
    "                 pretrained_embeddings: torch.Tensor = None):\n",
    "        super().__init__()\n",
    "        if rfsq_levels is None:\n",
    "            rfsq_levels = [5, 5, 5, 5]\n",
    "        self.rfsq_dim = len(rfsq_levels)\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        self.block_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.block_emb.weight.data.copy_(pretrained_embeddings)\n",
    "            self.block_emb.weight.requires_grad = False\n",
    "        \n",
    "        self.encoder = EncoderV9(emb_dim, hidden_dim, self.rfsq_dim)\n",
    "        self.quantizer = RFSQ(rfsq_levels, num_stages)\n",
    "        self.decoder = DecoderV9(self.rfsq_dim, hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, block_ids):\n",
    "        z_e = self.encode(block_ids)\n",
    "        z_q, indices = self.quantize(z_e)\n",
    "        logits = self.decode(z_q)\n",
    "        return logits, z_q, indices\n",
    "\n",
    "    def encode(self, block_ids):\n",
    "        x = self.block_emb(block_ids).permute(0, 4, 1, 2, 3)\n",
    "        z_e = self.encoder(x).permute(0, 2, 3, 4, 1)\n",
    "        return z_e\n",
    "\n",
    "    def quantize(self, z_e):\n",
    "        return self.quantizer(z_e)\n",
    "\n",
    "    def decode(self, z_q):\n",
    "        return self.decoder(z_q.permute(0, 4, 1, 2, 3))\n",
    "\n",
    "print(\"VQ-VAE v9 architecture defined (8x8x8 latent)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Asymmetric Focal Loss with Air Boost\n",
    "\n",
    "**What this does (Technical):** Implements focal loss that down-weights easy examples (gamma=2.0) and up-weights air predictions (air_boost=3.0). This addresses the root cause of volume over-prediction: the model learns to predict more structure blocks because they're \"easy wins\" for the CE loss.\n",
    "\n",
    "**What this does (Simple):** A smarter way to calculate the training error that:\n",
    "1. Focuses more on hard-to-predict blocks (focal loss)\n",
    "2. Makes air predictions 3x more important (air boost)\n",
    "3. This stops the model from cheating by over-predicting structure blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricFocalLoss(nn.Module):\n",
    "    \"\"\"Focal loss with asymmetric air boosting to fix volume over-prediction.\n",
    "    \n",
    "    Key insight: Standard CE loss treats all predictions equally. But we NEED\n",
    "    the model to predict air correctly, otherwise it over-predicts structure.\n",
    "    \n",
    "    Solution:\n",
    "    1. Focal loss: (1-p_t)^gamma * CE - focuses on hard examples\n",
    "    2. Air boost: Multiply loss by air_boost at GT air locations\n",
    "    3. Volume penalty: Strong L2 penalty on volume ratio deviation\n",
    "    \"\"\"\n",
    "    def __init__(self, air_tokens: Set[int], gamma: float = 2.0, air_boost: float = 3.0,\n",
    "                 volume_penalty: float = 100.0, frequency_weights: torch.Tensor = None,\n",
    "                 frequency_cap: float = 2.0):\n",
    "        super().__init__()\n",
    "        self.air_tokens = list(air_tokens)\n",
    "        self.gamma = gamma\n",
    "        self.air_boost = air_boost\n",
    "        self.volume_penalty = volume_penalty\n",
    "        \n",
    "        if frequency_weights is not None:\n",
    "            clamped = frequency_weights.clamp(max=frequency_cap)\n",
    "            self.register_buffer('freq_weights', clamped)\n",
    "        else:\n",
    "            self.freq_weights = None\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, target: torch.Tensor, z_q: torch.Tensor,\n",
    "                phase: int = 2) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Compute loss. phase=1 for binary, phase=2 for full vocab.\"\"\"\n",
    "        device = logits.device\n",
    "        B, C, X, Y, Z = logits.shape\n",
    "        \n",
    "        # Create air mask\n",
    "        air_tensor = torch.tensor(self.air_tokens, device=device, dtype=target.dtype)\n",
    "        gt_is_air = torch.isin(target, air_tensor)\n",
    "        gt_is_struct = ~gt_is_air\n",
    "        \n",
    "        if phase == 1:\n",
    "            # PHASE 1: Binary classification (air vs structure)\n",
    "            return self._phase1_loss(logits, target, gt_is_air, gt_is_struct, device)\n",
    "        else:\n",
    "            # PHASE 2: Full vocabulary with focal loss\n",
    "            return self._phase2_loss(logits, target, gt_is_air, gt_is_struct, z_q, device)\n",
    "\n",
    "    def _phase1_loss(self, logits, target, gt_is_air, gt_is_struct, device):\n",
    "        \"\"\"Binary air/structure loss for Phase 1.\"\"\"\n",
    "        B, C, X, Y, Z = logits.shape\n",
    "        \n",
    "        # Collapse logits to binary: air vs non-air\n",
    "        air_mask = torch.zeros(C, device=device, dtype=torch.bool)\n",
    "        for t in self.air_tokens:\n",
    "            if t < C:\n",
    "                air_mask[t] = True\n",
    "        \n",
    "        # Max air logit and max non-air logit per voxel\n",
    "        air_logits = logits[:, air_mask, :, :, :].max(dim=1)[0] if air_mask.any() else torch.zeros(B, X, Y, Z, device=device)\n",
    "        struct_logits = logits[:, ~air_mask, :, :, :].max(dim=1)[0]\n",
    "        \n",
    "        # Binary logits: [B, 2, X, Y, Z]\n",
    "        binary_logits = torch.stack([air_logits, struct_logits], dim=1)\n",
    "        binary_target = gt_is_struct.long()  # 0=air, 1=structure\n",
    "        \n",
    "        # Binary CE loss\n",
    "        binary_logits_flat = binary_logits.permute(0, 2, 3, 4, 1).reshape(-1, 2)\n",
    "        binary_target_flat = binary_target.reshape(-1)\n",
    "        ce_loss = F.cross_entropy(binary_logits_flat, binary_target_flat, reduction='mean')\n",
    "        \n",
    "        # Strong volume penalty\n",
    "        probs = F.softmax(binary_logits, dim=1)\n",
    "        pred_struct_prob = probs[:, 1, :, :, :]  # Probability of structure\n",
    "        pred_volume = pred_struct_prob.sum()\n",
    "        gt_volume = gt_is_struct.float().sum()\n",
    "        volume_ratio = pred_volume / (gt_volume + 1e-6)\n",
    "        volume_loss = (volume_ratio - 1.0) ** 2\n",
    "        \n",
    "        total_loss = ce_loss + self.volume_penalty * volume_loss\n",
    "        \n",
    "        # Metrics\n",
    "        with torch.no_grad():\n",
    "            pred_binary = binary_logits.argmax(dim=1)  # 0=air, 1=struct\n",
    "            pred_is_struct = pred_binary == 1\n",
    "            correct = (pred_binary == binary_target)\n",
    "            accuracy = correct.float().mean()\n",
    "            vol_ratio_hard = pred_is_struct.float().sum() / (gt_is_struct.float().sum() + 1e-6)\n",
    "            recall = (gt_is_struct & pred_is_struct).float().sum() / (gt_is_struct.float().sum() + 1e-6)\n",
    "            precision = (gt_is_struct & pred_is_struct).float().sum() / (pred_is_struct.float().sum() + 1e-6)\n",
    "        \n",
    "        return {\n",
    "            'loss': total_loss,\n",
    "            'ce_loss': ce_loss.detach(),\n",
    "            'volume_loss': volume_loss.detach(),\n",
    "            'focal_loss': torch.tensor(0.0, device=device),\n",
    "            'volume_ratio': vol_ratio_hard,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'accuracy': accuracy,\n",
    "            'phase': torch.tensor(1.0, device=device),\n",
    "        }\n",
    "\n",
    "    def _phase2_loss(self, logits, target, gt_is_air, gt_is_struct, z_q, device):\n",
    "        \"\"\"Full vocabulary loss with focal loss and air boost.\"\"\"\n",
    "        B, C, X, Y, Z = logits.shape\n",
    "        \n",
    "        logits_flat = logits.permute(0, 2, 3, 4, 1).reshape(-1, C)\n",
    "        target_flat = target.reshape(-1)\n",
    "        gt_is_air_flat = gt_is_air.reshape(-1)\n",
    "        \n",
    "        # Compute probabilities for focal loss\n",
    "        log_probs = F.log_softmax(logits_flat, dim=1)\n",
    "        probs = torch.exp(log_probs)\n",
    "        \n",
    "        # Get probability of correct class\n",
    "        p_t = probs.gather(1, target_flat.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        # Focal loss weight: (1 - p_t)^gamma\n",
    "        focal_weight = (1 - p_t) ** self.gamma\n",
    "        \n",
    "        # CE loss per sample\n",
    "        ce_per_sample = -log_probs.gather(1, target_flat.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        # Apply frequency weights if available\n",
    "        if self.freq_weights is not None:\n",
    "            freq_w = self.freq_weights[target_flat]\n",
    "            ce_per_sample = ce_per_sample * freq_w\n",
    "        \n",
    "        # Apply air boost at GT air locations\n",
    "        air_weight = torch.where(gt_is_air_flat, \n",
    "                                  torch.tensor(self.air_boost, device=device),\n",
    "                                  torch.tensor(1.0, device=device))\n",
    "        \n",
    "        # Focal loss\n",
    "        focal_loss = (focal_weight * ce_per_sample * air_weight).mean()\n",
    "        \n",
    "        # Volume penalty\n",
    "        air_tensor = torch.tensor(self.air_tokens, device=device, dtype=target.dtype)\n",
    "        pred_hard = logits_flat.argmax(dim=1)\n",
    "        pred_is_air = torch.isin(pred_hard, air_tensor)\n",
    "        pred_is_struct = ~pred_is_air\n",
    "        \n",
    "        pred_volume = pred_is_struct.float().sum()\n",
    "        gt_volume = gt_is_struct.float().sum()\n",
    "        volume_ratio = pred_volume / (gt_volume + 1e-6)\n",
    "        volume_loss = (volume_ratio - 1.0) ** 2\n",
    "        \n",
    "        total_loss = focal_loss + self.volume_penalty * volume_loss\n",
    "        \n",
    "        # Metrics\n",
    "        with torch.no_grad():\n",
    "            correct = (pred_hard == target_flat)\n",
    "            accuracy = correct.float().mean()\n",
    "            building_acc = correct[~gt_is_air_flat].float().mean() if (~gt_is_air_flat).any() else torch.tensor(0.0)\n",
    "            air_acc = correct[gt_is_air_flat].float().mean() if gt_is_air_flat.any() else torch.tensor(0.0)\n",
    "            recall = (pred_is_struct & ~gt_is_air_flat).float().sum() / ((~gt_is_air_flat).float().sum() + 1e-6)\n",
    "            precision = (pred_is_struct & ~gt_is_air_flat).float().sum() / (pred_is_struct.float().sum() + 1e-6)\n",
    "            false_air_rate = (pred_is_air & ~gt_is_air_flat).float().sum() / ((~gt_is_air_flat).float().sum() + 1e-6)\n",
    "        \n",
    "        return {\n",
    "            'loss': total_loss,\n",
    "            'ce_loss': focal_loss.detach(),\n",
    "            'focal_loss': focal_loss.detach(),\n",
    "            'volume_loss': volume_loss.detach(),\n",
    "            'volume_ratio': volume_ratio.detach(),\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'accuracy': accuracy,\n",
    "            'building_acc': building_acc,\n",
    "            'air_acc': air_acc,\n",
    "            'false_air_rate': false_air_rate,\n",
    "            'phase': torch.tensor(2.0, device=device),\n",
    "        }\n",
    "\n",
    "print(\"AsymmetricFocalLoss defined\")\n",
    "print(f\"  - Focal gamma: focuses on hard examples\")\n",
    "print(f\"  - Air boost: makes air predictions more important\")\n",
    "print(f\"  - Volume penalty: strong L2 on ratio deviation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Configuration\n",
    "\n",
    "**What this does (Technical):** Defines all hyperparameters for the v9 two-phase training experiment. Key changes from v8:\n",
    "- **Latent resolution**: Reduced to 8x8x8 (from 16x16x16) to force better compression and prevent volume bias encoding\n",
    "- **Frequency cap**: Reduced to 2.0x (from 5.0x) to reduce incentive for over-predicting rare blocks\n",
    "- **Volume penalty**: Increased to 100x (from 10x) for strong volume ratio enforcement\n",
    "- **Focal gamma**: Set to 2.0 to focus training on hard-to-predict examples\n",
    "- **Air boost**: Set to 3.0x to make correct air predictions more valuable\n",
    "\n",
    "**What this does (Simple):** Sets up all the training settings. The key insight is that we train in two phases:\n",
    "1. **Phase 1 (10 epochs)**: Only teaches air vs non-air (binary). This establishes the correct volume ratio FIRST.\n",
    "2. **Phase 2 (10 epochs)**: Teaches specific block types. Since volume is already correct, the model can focus on accuracy.\n",
    "\n",
    "This is like teaching someone to draw outlines before filling in colors - get the shape right first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data Paths ===\n",
    "DATA_DIR = f\"{DRIVE_BASE}/splits/train\"\n",
    "VAL_DIR = f\"{DRIVE_BASE}/splits/val\"\n",
    "VOCAB_PATH = f\"{DRIVE_BASE}/vocabulary/tok2block.json\"\n",
    "V3_EMBEDDINGS_PATH = f\"{DRIVE_BASE}/embeddings/block_embeddings_v3.npy\"\n",
    "\n",
    "# Verify paths\n",
    "print(\"Checking paths...\")\n",
    "for name, path in [('DATA_DIR', DATA_DIR), ('VAL_DIR', VAL_DIR),\n",
    "                   ('VOCAB_PATH', VOCAB_PATH), ('V3_EMBEDDINGS_PATH', V3_EMBEDDINGS_PATH)]:\n",
    "    exists = Path(path).exists()\n",
    "    print(f\"  {name}: {'[OK]' if exists else '[NOT FOUND]'}\")\n",
    "\n",
    "# === V9 Architecture (back to 8x8x8 latent) ===\n",
    "HIDDEN_DIM = 128  # Reduced from v8's 192\n",
    "RFSQ_LEVELS = [5, 5, 5, 5]  # 4 dims x 5 levels = 625 codes per stage\n",
    "NUM_STAGES = 2\n",
    "\n",
    "# === V9 Loss Weights (KEY CHANGES) ===\n",
    "FREQUENCY_CAP = 2.0       # REDUCED from 5.0 - less incentive to over-predict\n",
    "FOCAL_GAMMA = 2.0         # Focus on hard examples\n",
    "AIR_BOOST = 3.0           # Air predictions are 3x more important\n",
    "VOLUME_PENALTY = 100.0    # STRONG volume penalty (was 10.0)\n",
    "\n",
    "# === Two-Phase Training Schedule ===\n",
    "PHASE1_EPOCHS = 10        # Binary air/structure training\n",
    "PHASE2_EPOCHS = 10        # Full vocabulary (increase to 30 later if Phase 1 works)\n",
    "TOTAL_EPOCHS = PHASE1_EPOCHS + PHASE2_EPOCHS\n",
    "\n",
    "# === Training ===\n",
    "BATCH_SIZE = 4            # Increased since 8x8x8 uses less memory\n",
    "BASE_LR = 2e-4\n",
    "USE_AMP = True\n",
    "GRAD_ACCUM_STEPS = 4\n",
    "SEED = 42\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"V9 CONFIGURATION - TWO-PHASE TRAINING\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Latent resolution: 8x8x8 (reduced from v8's 16x16x16)\")\n",
    "print(f\"Hidden dim: {HIDDEN_DIM}\")\n",
    "print(f\"\\nPhase 1: {PHASE1_EPOCHS} epochs - Binary air/structure\")\n",
    "print(f\"  - Learns correct volume ratio FIRST\")\n",
    "print(f\"  - Volume penalty: {VOLUME_PENALTY}x\")\n",
    "print(f\"\\nPhase 2: {PHASE2_EPOCHS} epochs - Full vocabulary\")\n",
    "print(f\"  - Focal gamma: {FOCAL_GAMMA}\")\n",
    "print(f\"  - Air boost: {AIR_BOOST}x\")\n",
    "print(f\"  - Frequency cap: {FREQUENCY_CAP}x (reduced from 5.0)\")\n",
    "print(f\"\\nTotal epochs: {TOTAL_EPOCHS}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load Vocabulary and Embeddings\n",
    "\n",
    "**What this does (Technical):** Loads the block vocabulary mapping (token ID to block name) and pre-trained block embeddings. Identifies air tokens by searching for 'air' in block names.\n",
    "\n",
    "**What this does (Simple):** Loads the dictionary that maps numbers to Minecraft block names, and the pre-learned representations of each block type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VOCAB_PATH, 'r') as f:\n",
    "    tok2block = {int(k): v for k, v in json.load(f).items()}\n",
    "\n",
    "VOCAB_SIZE = len(tok2block)\n",
    "print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
    "\n",
    "# Find air tokens\n",
    "AIR_TOKENS: Set[int] = set()\n",
    "for tok, block in tok2block.items():\n",
    "    if 'air' in block.lower() and 'stair' not in block.lower():\n",
    "        AIR_TOKENS.add(tok)\n",
    "        print(f\"  Air token: {tok} = {block}\")\n",
    "\n",
    "AIR_TOKENS_TENSOR = torch.tensor(sorted(AIR_TOKENS), dtype=torch.long)\n",
    "\n",
    "# Load embeddings\n",
    "v3_embeddings = np.load(V3_EMBEDDINGS_PATH).astype(np.float32)\n",
    "EMBEDDING_DIM = v3_embeddings.shape[1]\n",
    "print(f\"\\nEmbeddings: {v3_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compute Frequency Weights\n",
    "\n",
    "**What this does (Technical):** Scans all training structures to count block frequencies, then computes inverse-frequency weights (rare blocks get higher weights). Capped at 2.0x to prevent extreme over-prediction of rare blocks.\n",
    "\n",
    "**What this does (Simple):** Counts how often each block type appears in the training data. Rare blocks get slightly higher importance, but capped to prevent the model from over-predicting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing block frequencies...\")\n",
    "\n",
    "all_block_ids = []\n",
    "train_files = sorted(Path(DATA_DIR).glob(\"*.h5\"))\n",
    "\n",
    "for h5_file in tqdm(train_files, desc=\"Scanning\"):\n",
    "    with h5py.File(h5_file, 'r') as f:\n",
    "        key = list(f.keys())[0]\n",
    "        structure = f[key][:].flatten()\n",
    "        all_block_ids.append(torch.from_numpy(structure).long())\n",
    "\n",
    "all_block_ids = torch.cat(all_block_ids)\n",
    "print(f\"Total blocks scanned: {len(all_block_ids):,}\")\n",
    "\n",
    "# Compute frequency weights with REDUCED cap\n",
    "counts = torch.bincount(all_block_ids.flatten(), minlength=VOCAB_SIZE).clamp(min=1)\n",
    "total = counts.sum()\n",
    "FREQUENCY_WEIGHTS = ((total.float() / counts.float()) ** 0.5).clamp(max=FREQUENCY_CAP)\n",
    "\n",
    "print(f\"Frequency weights computed (cap={FREQUENCY_CAP}x)\")\n",
    "print(f\"  Max weight: {FREQUENCY_WEIGHTS.max():.2f}\")\n",
    "print(f\"  Min weight: {FREQUENCY_WEIGHTS.min():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Dataset\n",
    "\n",
    "**What this does (Technical):** PyTorch Dataset class that loads Minecraft structures from HDF5 files. Each structure is a 32x32x32 array of block token IDs.\n",
    "\n",
    "**What this does (Simple):** Defines how to load Minecraft structures from files for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAEDataset(Dataset):\n",
    "    def __init__(self, data_dir: str):\n",
    "        self.h5_files = sorted(Path(data_dir).glob(\"*.h5\"))\n",
    "        if not self.h5_files:\n",
    "            raise ValueError(f\"No H5 files in {data_dir}\")\n",
    "        print(f\"Found {len(self.h5_files)} structures\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.h5_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.h5_files[idx], 'r') as f:\n",
    "            structure = f[list(f.keys())[0]][:].astype(np.int64)\n",
    "        return torch.from_numpy(structure).long()\n",
    "\n",
    "train_dataset = VQVAEDataset(DATA_DIR)\n",
    "val_dataset = VQVAEDataset(VAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create Model and Optimizer\n",
    "\n",
    "**What this does (Technical):** Instantiates VQ-VAE v9 model with 8x8x8 latent, creates AsymmetricFocalLoss criterion, AdamW optimizer with weight decay, and cosine annealing LR scheduler.\n",
    "\n",
    "**What this does (Simple):** Creates the neural network and sets up the training optimizer that will adjust the model's parameters to minimize errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "model = VQVAEv9(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    emb_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    rfsq_levels=RFSQ_LEVELS,\n",
    "    num_stages=NUM_STAGES,\n",
    "    pretrained_embeddings=torch.from_numpy(v3_embeddings),\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {total_params:,}\")\n",
    "\n",
    "criterion = AsymmetricFocalLoss(\n",
    "    air_tokens=AIR_TOKENS,\n",
    "    gamma=FOCAL_GAMMA,\n",
    "    air_boost=AIR_BOOST,\n",
    "    volume_penalty=VOLUME_PENALTY,\n",
    "    frequency_weights=FREQUENCY_WEIGHTS,\n",
    "    frequency_cap=FREQUENCY_CAP,\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=TOTAL_EPOCHS, eta_min=1e-5)\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP)\n",
    "\n",
    "print(\"Model, criterion, optimizer created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Data Loaders\n",
    "\n",
    "**What this does (Technical):** Creates PyTorch DataLoaders that batch, shuffle, and parallelize data loading for training efficiency.\n",
    "\n",
    "**What this does (Simple):** Sets up efficient data loading that feeds batches of structures to the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(SEED)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True, generator=g)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Effective batch size: {BATCH_SIZE * GRAD_ACCUM_STEPS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Training Functions\n",
    "\n",
    "**What this does (Technical):** Defines train_epoch() and validate() functions that iterate through data, compute loss, backpropagate gradients, and collect metrics. Supports two-phase training via the `phase` parameter.\n",
    "\n",
    "**What this does (Simple):** The core training logic that:\n",
    "1. Shows structures to the model\n",
    "2. Compares predictions to ground truth\n",
    "3. Adjusts model to reduce errors\n",
    "4. Tracks all important metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, criterion, loader, optimizer, scaler, device, phase: int):\n",
    "    \"\"\"Train one epoch. phase=1 for binary, phase=2 for full vocab.\"\"\"\n",
    "    model.train()\n",
    "    model.quantizer.reset_usage()\n",
    "    \n",
    "    metrics_sum = defaultdict(float)\n",
    "    n = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(tqdm(loader, desc=f\"Train P{phase}\", leave=False)):\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        with torch.amp.autocast('cuda', enabled=USE_AMP):\n",
    "            logits, z_q, indices = model(batch)\n",
    "            loss_dict = criterion(logits, batch, z_q, phase=phase)\n",
    "            loss = loss_dict['loss'] / GRAD_ACCUM_STEPS\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (batch_idx + 1) % GRAD_ACCUM_STEPS == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for k, v in loss_dict.items():\n",
    "                metrics_sum[k] += v.item() if torch.is_tensor(v) else v\n",
    "        n += 1\n",
    "    \n",
    "    metrics = {k: v / n for k, v in metrics_sum.items()}\n",
    "    \n",
    "    # RFSQ usage stats\n",
    "    for name, (usage, perp) in model.quantizer.get_usage_stats().items():\n",
    "        metrics[f'{name}_usage'] = usage\n",
    "        metrics[f'{name}_perplexity'] = perp\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, criterion, loader, device, phase: int):\n",
    "    \"\"\"Validate. phase=1 for binary, phase=2 for full vocab.\"\"\"\n",
    "    model.eval()\n",
    "    model.quantizer.reset_usage()\n",
    "    \n",
    "    metrics_sum = defaultdict(float)\n",
    "    n = 0\n",
    "    \n",
    "    for batch in tqdm(loader, desc=f\"Val P{phase}\", leave=False):\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        with torch.amp.autocast('cuda', enabled=USE_AMP):\n",
    "            logits, z_q, indices = model(batch)\n",
    "            loss_dict = criterion(logits, batch, z_q, phase=phase)\n",
    "        \n",
    "        for k, v in loss_dict.items():\n",
    "            metrics_sum[k] += v.item() if torch.is_tensor(v) else v\n",
    "        n += 1\n",
    "    \n",
    "    metrics = {k: v / n for k, v in metrics_sum.items()}\n",
    "    \n",
    "    for name, (usage, perp) in model.quantizer.get_usage_stats().items():\n",
    "        metrics[f'{name}_usage'] = usage\n",
    "        metrics[f'{name}_perplexity'] = perp\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Two-Phase Training Loop\n",
    "\n",
    "**What this does (Technical):** Executes two-phase training: Phase 1 trains binary air/structure classification with strong volume penalty, Phase 2 continues with full vocabulary and focal loss. Saves checkpoints at phase transitions and every 5 epochs.\n",
    "\n",
    "**What this does (Simple):** The main training loop that:\n",
    "1. **Phase 1**: Teaches the model to distinguish air from non-air (establishes correct volume)\n",
    "2. **Phase 2**: Teaches the model to identify specific block types (improves accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"VQ-VAE V9 TWO-PHASE TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Phase 1 (epochs 1-{PHASE1_EPOCHS}): Binary air/structure\")\n",
    "print(f\"Phase 2 (epochs {PHASE1_EPOCHS+1}-{TOTAL_EPOCHS}): Full vocabulary\")\n",
    "print(f\"Target: volume_ratio ~1.0x, building_acc >45%\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'train_volume_ratio': [], 'val_volume_ratio': [],\n",
    "    'train_recall': [], 'val_recall': [],\n",
    "    'train_precision': [], 'val_precision': [],\n",
    "    'train_accuracy': [], 'val_accuracy': [],\n",
    "    'train_building_acc': [], 'val_building_acc': [],\n",
    "    'train_air_acc': [], 'val_air_acc': [],\n",
    "    'train_false_air_rate': [], 'val_false_air_rate': [],\n",
    "    'train_ce_loss': [], 'val_ce_loss': [],\n",
    "    'train_volume_loss': [], 'val_volume_loss': [],\n",
    "    'train_focal_loss': [], 'val_focal_loss': [],\n",
    "    'train_stage0_perplexity': [], 'val_stage0_perplexity': [],\n",
    "    'learning_rate': [], 'phase': [],\n",
    "}\n",
    "\n",
    "best_metric = 0\n",
    "best_epoch = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(TOTAL_EPOCHS):\n",
    "    # Determine phase\n",
    "    phase = 1 if epoch < PHASE1_EPOCHS else 2\n",
    "    \n",
    "    # Train and validate\n",
    "    train_m = train_epoch(model, criterion, train_loader, optimizer, scaler, device, phase)\n",
    "    val_m = validate(model, criterion, val_loader, device, phase)\n",
    "    scheduler.step()\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    \n",
    "    # Record metrics\n",
    "    for prefix, m in [('train', train_m), ('val', val_m)]:\n",
    "        history[f'{prefix}_loss'].append(m.get('loss', 0))\n",
    "        history[f'{prefix}_volume_ratio'].append(m.get('volume_ratio', 0))\n",
    "        history[f'{prefix}_recall'].append(m.get('recall', 0))\n",
    "        history[f'{prefix}_precision'].append(m.get('precision', 0))\n",
    "        history[f'{prefix}_accuracy'].append(m.get('accuracy', 0))\n",
    "        history[f'{prefix}_building_acc'].append(m.get('building_acc', 0))\n",
    "        history[f'{prefix}_air_acc'].append(m.get('air_acc', 0))\n",
    "        history[f'{prefix}_false_air_rate'].append(m.get('false_air_rate', 0))\n",
    "        history[f'{prefix}_ce_loss'].append(m.get('ce_loss', 0))\n",
    "        history[f'{prefix}_volume_loss'].append(m.get('volume_loss', 0))\n",
    "        history[f'{prefix}_focal_loss'].append(m.get('focal_loss', 0))\n",
    "        history[f'{prefix}_stage0_perplexity'].append(m.get('stage0_perplexity', 0))\n",
    "    history['learning_rate'].append(current_lr)\n",
    "    history['phase'].append(phase)\n",
    "    \n",
    "    # Best model tracking (different metric per phase)\n",
    "    if phase == 1:\n",
    "        current_metric = 1.0 - abs(val_m['volume_ratio'] - 1.0)  # Closer to 1.0 = better\n",
    "    else:\n",
    "        current_metric = val_m.get('building_acc', val_m.get('accuracy', 0))\n",
    "    \n",
    "    if current_metric > best_metric:\n",
    "        best_metric = current_metric\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v9_best.pt\")\n",
    "    \n",
    "    # Save at phase transition\n",
    "    if epoch == PHASE1_EPOCHS - 1:\n",
    "        torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v9_phase1_complete.pt\")\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"PHASE 1 COMPLETE - Transitioning to Phase 2 (full vocabulary)\")\n",
    "        print(f\"Volume ratio at transition: {val_m['volume_ratio']:.3f}x\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Checkpoint every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v9_epoch{epoch+1}.pt\")\n",
    "    \n",
    "    # Print progress\n",
    "    vol_str = f\"{val_m['volume_ratio']:.3f}x\"\n",
    "    vol_color = '' if 0.9 <= val_m['volume_ratio'] <= 1.1 else ' (!!)'\n",
    "    \n",
    "    if phase == 1:\n",
    "        print(f\"E{epoch+1:2d} P1 | Acc: {val_m['accuracy']:.1%} | \"\n",
    "              f\"Vol: {vol_str}{vol_color} | Recall: {val_m['recall']:.1%} | LR: {current_lr:.2e}\")\n",
    "    else:\n",
    "        ba = val_m.get('building_acc', 0)\n",
    "        print(f\"E{epoch+1:2d} P2 | Build: {ba:.1%} | \"\n",
    "              f\"Vol: {vol_str}{vol_color} | Recall: {val_m['recall']:.1%} | LR: {current_lr:.2e}\")\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Time: {train_time/60:.1f} minutes\")\n",
    "print(f\"Best epoch: {best_epoch}\")\n",
    "print(f\"Final volume ratio: {history['val_volume_ratio'][-1]:.3f}x\")\n",
    "print(f\"Final recall: {history['val_recall'][-1]:.1%}\")\n",
    "if history['val_building_acc'][-1] > 0:\n",
    "    print(f\"Final building accuracy: {history['val_building_acc'][-1]:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Plot Training Results\n",
    "\n",
    "**What this does (Technical):** Creates a 3x3 grid of plots showing all key metrics over training epochs, with phase transitions marked and target baselines shown.\n",
    "\n",
    "**What this does (Simple):** Visualizes how well the training went - we want to see volume ratio approaching 1.0 and accuracy improving over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(16, 14))\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "phase_transition = PHASE1_EPOCHS + 0.5\n",
    "\n",
    "# 1. Volume Ratio (MOST IMPORTANT)\n",
    "ax = axes[0, 0]\n",
    "ax.plot(epochs, history['train_volume_ratio'], 'b-', label='Train', linewidth=2)\n",
    "ax.plot(epochs, history['val_volume_ratio'], 'r--', label='Val', linewidth=2)\n",
    "ax.axhline(y=1.0, color='g', linestyle='--', linewidth=2, label='Target (1.0x)')\n",
    "ax.axhline(y=2.0, color='orange', linestyle=':', alpha=0.7, label='v8 stuck (2.0x)')\n",
    "ax.axvline(x=phase_transition, color='purple', linestyle=':', alpha=0.5, label='Phase transition')\n",
    "ax.fill_between(epochs, 0.9, 1.1, alpha=0.2, color='green', label='Target zone')\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Volume Ratio')\n",
    "ax.set_title('Volume Ratio (KEY METRIC)', fontweight='bold', fontsize=12, color='darkred')\n",
    "ax.legend(loc='upper right', fontsize=8); ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, max(2.5, max(history['val_volume_ratio']) * 1.1))\n",
    "\n",
    "# 2. Recall\n",
    "ax = axes[0, 1]\n",
    "ax.plot(epochs, history['train_recall'], 'b-', label='Train', linewidth=2)\n",
    "ax.plot(epochs, history['val_recall'], 'r--', label='Val', linewidth=2)\n",
    "ax.axhline(y=0.90, color='g', linestyle='--', alpha=0.5, label='Target (90%)')\n",
    "ax.axvline(x=phase_transition, color='purple', linestyle=':', alpha=0.5)\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Recall')\n",
    "ax.set_title('Recall (Structure Preservation)', fontweight='bold', fontsize=12)\n",
    "ax.legend(loc='lower right'); ax.grid(True, alpha=0.3); ax.set_ylim(0, 1.05)\n",
    "\n",
    "# 3. Precision\n",
    "ax = axes[0, 2]\n",
    "ax.plot(epochs, history['train_precision'], 'b-', label='Train', linewidth=2)\n",
    "ax.plot(epochs, history['val_precision'], 'r--', label='Val', linewidth=2)\n",
    "ax.axvline(x=phase_transition, color='purple', linestyle=':', alpha=0.5)\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Precision')\n",
    "ax.set_title('Precision', fontweight='bold', fontsize=12)\n",
    "ax.legend(loc='lower right'); ax.grid(True, alpha=0.3); ax.set_ylim(0, 1.05)\n",
    "\n",
    "# 4. Building Accuracy (Phase 2 only)\n",
    "ax = axes[1, 0]\n",
    "ax.plot(epochs, history['train_building_acc'], 'b-', label='Train', linewidth=2)\n",
    "ax.plot(epochs, history['val_building_acc'], 'r--', label='Val', linewidth=2)\n",
    "ax.axhline(y=0.492, color='g', linestyle=':', alpha=0.5, label='v6-freq (49.2%)')\n",
    "ax.axvline(x=phase_transition, color='purple', linestyle=':', alpha=0.5, label='Phase 2 start')\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Building Accuracy', fontweight='bold', fontsize=12)\n",
    "ax.legend(loc='lower right'); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Air Accuracy (Phase 2 only)\n",
    "ax = axes[1, 1]\n",
    "ax.plot(epochs, history['train_air_acc'], 'b-', label='Train', linewidth=2)\n",
    "ax.plot(epochs, history['val_air_acc'], 'r--', label='Val', linewidth=2)\n",
    "ax.axvline(x=phase_transition, color='purple', linestyle=':', alpha=0.5)\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Air Accuracy', fontweight='bold', fontsize=12)\n",
    "ax.legend(loc='lower right'); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. False Air Rate\n",
    "ax = axes[1, 2]\n",
    "ax.plot(epochs, history['train_false_air_rate'], 'b-', label='Train', linewidth=2)\n",
    "ax.plot(epochs, history['val_false_air_rate'], 'r--', label='Val', linewidth=2)\n",
    "ax.axhline(y=0.10, color='orange', linestyle='--', alpha=0.5, label='Max acceptable (10%)')\n",
    "ax.axvline(x=phase_transition, color='purple', linestyle=':', alpha=0.5)\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Rate')\n",
    "ax.set_title('False Air Rate (Erasure)', fontweight='bold', fontsize=12)\n",
    "ax.legend(loc='upper right'); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 7. Loss Components\n",
    "ax = axes[2, 0]\n",
    "ax.plot(epochs, history['val_ce_loss'], 'b-', label='CE/Focal', linewidth=2)\n",
    "ax.plot(epochs, history['val_volume_loss'], 'r-', label='Volume', linewidth=2)\n",
    "ax.axvline(x=phase_transition, color='purple', linestyle=':', alpha=0.5)\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Loss')\n",
    "ax.set_title('Loss Components (Val)', fontweight='bold', fontsize=12)\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 8. Total Loss\n",
    "ax = axes[2, 1]\n",
    "ax.plot(epochs, history['train_loss'], 'b-', label='Train', linewidth=2)\n",
    "ax.plot(epochs, history['val_loss'], 'r--', label='Val', linewidth=2)\n",
    "ax.axvline(x=phase_transition, color='purple', linestyle=':', alpha=0.5)\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Loss')\n",
    "ax.set_title('Total Loss', fontweight='bold', fontsize=12)\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 9. RFSQ Perplexity\n",
    "ax = axes[2, 2]\n",
    "ax.plot(epochs, history['train_stage0_perplexity'], 'b-', label='Train', linewidth=2)\n",
    "ax.plot(epochs, history['val_stage0_perplexity'], 'r--', label='Val', linewidth=2)\n",
    "ax.axvline(x=phase_transition, color='purple', linestyle=':', alpha=0.5)\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Perplexity')\n",
    "ax.set_title('RFSQ Perplexity', fontweight='bold', fontsize=12)\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/vqvae_v9_training.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "final_vol = history['val_volume_ratio'][-1]\n",
    "final_recall = history['val_recall'][-1]\n",
    "final_build = history['val_building_acc'][-1]\n",
    "\n",
    "print(f\"Final volume ratio: {final_vol:.3f}x\")\n",
    "print(f\"Final recall: {final_recall:.1%}\")\n",
    "print(f\"Final building accuracy: {final_build:.1%}\")\n",
    "print()\n",
    "\n",
    "# Success criteria\n",
    "vol_ok = 0.9 <= final_vol <= 1.1\n",
    "recall_ok = final_recall >= 0.85\n",
    "acc_ok = final_build >= 0.45\n",
    "\n",
    "print(\"Success Criteria:\")\n",
    "print(f\"  Volume 0.9-1.1x: {'PASS' if vol_ok else 'FAIL'} ({final_vol:.3f}x)\")\n",
    "print(f\"  Recall >= 85%: {'PASS' if recall_ok else 'FAIL'} ({final_recall:.1%})\")\n",
    "print(f\"  Build acc >= 45%: {'PASS' if acc_ok else 'FAIL'} ({final_build:.1%})\")\n",
    "print()\n",
    "\n",
    "if vol_ok and recall_ok and acc_ok:\n",
    "    print(\"SUCCESS! All targets met.\")\n",
    "elif vol_ok:\n",
    "    print(\"PARTIAL SUCCESS: Volume ratio fixed! May need more Phase 2 epochs for accuracy.\")\n",
    "else:\n",
    "    print(\"NEEDS WORK: Check Phase 1 metrics - volume ratio should be ~1.0 before Phase 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Save Results\n",
    "\n",
    "**What this does (Technical):** Serializes training configuration, final metrics, and full training history to JSON. Saves final model checkpoint.\n",
    "\n",
    "**What this does (Simple):** Saves all training results and the trained model to files so we can use them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'config': {\n",
    "        'version': 'v9-TWO-PHASE',\n",
    "        'latent_resolution': '8x8x8',\n",
    "        'hidden_dim': HIDDEN_DIM,\n",
    "        'phase1_epochs': PHASE1_EPOCHS,\n",
    "        'phase2_epochs': PHASE2_EPOCHS,\n",
    "        'total_epochs': TOTAL_EPOCHS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'base_lr': BASE_LR,\n",
    "        'focal_gamma': FOCAL_GAMMA,\n",
    "        'air_boost': AIR_BOOST,\n",
    "        'volume_penalty': VOLUME_PENALTY,\n",
    "        'frequency_cap': FREQUENCY_CAP,\n",
    "        'seed': SEED,\n",
    "    },\n",
    "    'results': {\n",
    "        'final_volume_ratio': float(history['val_volume_ratio'][-1]),\n",
    "        'final_recall': float(history['val_recall'][-1]),\n",
    "        'final_precision': float(history['val_precision'][-1]),\n",
    "        'final_building_acc': float(history['val_building_acc'][-1]),\n",
    "        'final_air_acc': float(history['val_air_acc'][-1]),\n",
    "        'final_false_air_rate': float(history['val_false_air_rate'][-1]),\n",
    "        'phase1_final_volume_ratio': float(history['val_volume_ratio'][PHASE1_EPOCHS-1]),\n",
    "        'best_epoch': best_epoch,\n",
    "        'training_time_min': float(train_time / 60),\n",
    "        'volume_target_met': bool(0.9 <= history['val_volume_ratio'][-1] <= 1.1),\n",
    "        'recall_target_met': bool(history['val_recall'][-1] >= 0.85),\n",
    "        'accuracy_target_met': bool(history['val_building_acc'][-1] >= 0.45),\n",
    "    },\n",
    "    'history': {k: [float(x) for x in v] for k, v in history.items()},\n",
    "}\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/vqvae_v9_results.json\", 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v9_final.pt\")\n",
    "\n",
    "print(\"Results saved:\")\n",
    "print(f\"  {OUTPUT_DIR}/vqvae_v9_results.json\")\n",
    "print(f\"  {OUTPUT_DIR}/vqvae_v9_best.pt\")\n",
    "print(f\"  {OUTPUT_DIR}/vqvae_v9_phase1_complete.pt\")\n",
    "print(f\"  {OUTPUT_DIR}/vqvae_v9_final.pt\")\n",
    "print(f\"  {OUTPUT_DIR}/vqvae_v9_training.png\")\n",
    "print(\"\\nDone!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
