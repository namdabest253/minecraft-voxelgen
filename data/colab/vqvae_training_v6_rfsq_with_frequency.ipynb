{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VQ-VAE v6-freq Training - RFSQ + Frequency-Based Block Weighting\n",
        "\n",
        "## Changes from v6 (RFSQ-only)\n",
        "\n",
        "| Change | v6 | v6-freq |\n",
        "|--------|-----|--------|\n",
        "| Block weighting | Terrain/Building/Air only | **+ Inverse frequency weights** |\n",
        "| Weight cap | N/A | **10x max for rare blocks** |\n",
        "| Target | General accuracy | **Rare block reconstruction** |\n",
        "\n",
        "## Why Frequency Weighting?\n",
        "\n",
        "v5.1 showed that rare blocks (chests, doors, fences, trapdoors, carpet) **NEVER** reconstruct correctly.\n",
        "These blocks are vastly outnumbered by common blocks (planks, stone, air).\n",
        "\n",
        "Frequency weighting gives rare blocks up to 10x higher loss weight:\n",
        "```python\n",
        "weight = min(10.0, max_count / block_count)\n",
        "```\n",
        "\n",
        "## Goals\n",
        "\n",
        "| Metric | v5.1 Result | v6-freq Target |\n",
        "|--------|-------------|---------------|\n",
        "| Building Accuracy | 45.6% | **>55%** |\n",
        "| Rare Block Recall | ~0% | **>20%** |\n",
        "| Chest Recall | 0% | **>10%** |\n",
        "| Door Recall | 0% | **>10%** |\n",
        "| Fence Recall | 0% | **>10%** |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup - Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create output directory - NOTE: v6_freq not v6!\n",
        "import os\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/minecraft_ai/vqvae_v6_freq'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"Output will be saved to: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 1: Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Any, Set\n",
        "from collections import Counter\n",
        "\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if device == \"cuda\":\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2: Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Data Paths (UPDATE THESE FOR YOUR DRIVE) ===\n",
        "DRIVE_BASE = '/content/drive/MyDrive/minecraft_ai'\n",
        "\n",
        "DATA_DIR = f\"{DRIVE_BASE}/splits/train\"\n",
        "VAL_DIR = f\"{DRIVE_BASE}/splits/val\"\n",
        "VOCAB_PATH = f\"{DRIVE_BASE}/tok2block.json\"\n",
        "V3_EMBEDDINGS_PATH = f\"{DRIVE_BASE}/block_embeddings_v3.npy\"\n",
        "\n",
        "OUTPUT_DIR = f\"{DRIVE_BASE}/vqvae_v6_freq\"  # Different from v6!\n",
        "\n",
        "# === V6-freq RFSQ Configuration ===\n",
        "HIDDEN_DIMS = [96, 192]\n",
        "RFSQ_LEVELS_PER_STAGE = [5, 5, 5, 5]\n",
        "NUM_STAGES = 2\n",
        "DROPOUT = 0.1\n",
        "\n",
        "# === FREQUENCY WEIGHTING (NEW!) ===\n",
        "USE_FREQUENCY_WEIGHTING = True\n",
        "FREQUENCY_WEIGHT_CAP = 10.0  # Max weight for rare blocks\n",
        "\n",
        "# === Structure weights ===\n",
        "STRUCTURE_WEIGHT = 50.0\n",
        "\n",
        "# === TERRAIN SETTINGS ===\n",
        "TERRAIN_WEIGHT = 0.2\n",
        "BUILDING_WEIGHT = 1.0\n",
        "AIR_WEIGHT = 0.1\n",
        "\n",
        "# === Training ===\n",
        "TOTAL_EPOCHS = 25\n",
        "BATCH_SIZE = 4\n",
        "BASE_LR = 3e-4\n",
        "USE_AMP = True\n",
        "GRAD_ACCUM_STEPS = 4\n",
        "\n",
        "SEED = 42\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "CODES_PER_STAGE = int(np.prod(RFSQ_LEVELS_PER_STAGE))\n",
        "TOTAL_IMPLICIT_CODES = CODES_PER_STAGE ** NUM_STAGES\n",
        "\n",
        "print(\"VQ-VAE v6-freq (RFSQ + Frequency Weighting) Configuration:\")\n",
        "print(f\"  RFSQ: {NUM_STAGES} stages Ã— {CODES_PER_STAGE:,} codes\")\n",
        "print(f\"  Total implicit codes: {TOTAL_IMPLICIT_CODES:,}\")\n",
        "print(f\"\\nFREQUENCY WEIGHTING:\")\n",
        "print(f\"  Enabled: {USE_FREQUENCY_WEIGHTING}\")\n",
        "print(f\"  Weight cap: {FREQUENCY_WEIGHT_CAP}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3: Load Vocabulary and Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(VOCAB_PATH, 'r') as f:\n",
        "    tok2block = {int(k): v for k, v in json.load(f).items()}\n",
        "\n",
        "block2tok = {v: k for k, v in tok2block.items()}\n",
        "VOCAB_SIZE = len(tok2block)\n",
        "print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
        "\n",
        "# Find air tokens\n",
        "AIR_TOKENS: Set[int] = set()\n",
        "for tok, block in tok2block.items():\n",
        "    if 'air' in block.lower() and 'stair' not in block.lower():\n",
        "        AIR_TOKENS.add(tok)\n",
        "        print(f\"  Air token: {tok} = {block}\")\n",
        "\n",
        "AIR_TOKENS_LIST = sorted(AIR_TOKENS)\n",
        "AIR_TOKENS_TENSOR = torch.tensor(AIR_TOKENS_LIST, dtype=torch.long)\n",
        "\n",
        "# Load V3 embeddings\n",
        "v3_embeddings = np.load(V3_EMBEDDINGS_PATH).astype(np.float32)\n",
        "EMBEDDING_DIM = v3_embeddings.shape[1]\n",
        "print(f\"V3 embeddings: {v3_embeddings.shape} (dim={EMBEDDING_DIM})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4: Compute Block Frequencies (NEW!)\n",
        "\n",
        "This cell scans all training data to compute block frequencies.\n",
        "Rare blocks get higher weights (up to 10x) in the loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Computing block frequencies from training data...\")\n",
        "print(\"(This may take a few minutes)\")\n",
        "\n",
        "block_counts = Counter()\n",
        "train_files = sorted(Path(DATA_DIR).glob(\"*.h5\"))\n",
        "\n",
        "for h5_file in tqdm(train_files, desc=\"Scanning training data\"):\n",
        "    with h5py.File(h5_file, 'r') as f:\n",
        "        key = list(f.keys())[0]\n",
        "        structure = f[key][:].flatten()\n",
        "        block_counts.update(structure.tolist())\n",
        "\n",
        "total_blocks = sum(block_counts.values())\n",
        "print(f\"\\nTotal blocks scanned: {total_blocks:,}\")\n",
        "print(f\"Unique block types: {len(block_counts)}\")\n",
        "\n",
        "# Compute inverse frequency weights (capped at 10x)\n",
        "max_count = max(block_counts.values())\n",
        "frequency_weights = {}\n",
        "for tok in range(VOCAB_SIZE):\n",
        "    count = block_counts.get(tok, 1)  # Default to 1 if never seen\n",
        "    weight = min(FREQUENCY_WEIGHT_CAP, max_count / count)\n",
        "    frequency_weights[tok] = weight\n",
        "\n",
        "# Create weight tensor\n",
        "FREQUENCY_WEIGHT_TENSOR = torch.tensor(\n",
        "    [frequency_weights[i] for i in range(VOCAB_SIZE)],\n",
        "    dtype=torch.float32\n",
        ")\n",
        "\n",
        "# Show top 10 rarest blocks\n",
        "print(\"\\nTop 10 RAREST blocks (highest weights):\")\n",
        "sorted_by_weight = sorted(frequency_weights.items(), key=lambda x: x[1], reverse=True)\n",
        "for tok, weight in sorted_by_weight[:10]:\n",
        "    block_name = tok2block.get(tok, f\"UNKNOWN_{tok}\")\n",
        "    count = block_counts.get(tok, 0)\n",
        "    print(f\"  {block_name}: weight={weight:.1f}x (count={count:,})\")\n",
        "\n",
        "# Show top 10 most common blocks\n",
        "print(\"\\nTop 10 MOST COMMON blocks (lowest weights):\")\n",
        "sorted_by_weight = sorted(frequency_weights.items(), key=lambda x: x[1])\n",
        "for tok, weight in sorted_by_weight[:10]:\n",
        "    block_name = tok2block.get(tok, f\"UNKNOWN_{tok}\")\n",
        "    count = block_counts.get(tok, 0)\n",
        "    print(f\"  {block_name}: weight={weight:.2f}x (count={count:,})\")\n",
        "\n",
        "# Identify rare block categories for tracking\n",
        "RARE_BLOCK_KEYWORDS = ['chest', 'door', 'fence', 'trapdoor', 'carpet', 'bed', 'button', 'lever']\n",
        "RARE_BLOCK_TOKENS = set()\n",
        "for tok, block in tok2block.items():\n",
        "    for keyword in RARE_BLOCK_KEYWORDS:\n",
        "        if keyword in block.lower():\n",
        "            RARE_BLOCK_TOKENS.add(tok)\n",
        "            break\n",
        "\n",
        "RARE_BLOCK_TOKENS_TENSOR = torch.tensor(sorted(RARE_BLOCK_TOKENS), dtype=torch.long)\n",
        "print(f\"\\nRare block tokens identified: {len(RARE_BLOCK_TOKENS)}\")\n",
        "print(f\"Keywords: {RARE_BLOCK_KEYWORDS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5: Terrain Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TERRAIN_BLOCKS: Set[str] = {\n",
        "    'minecraft:dirt', 'minecraft:grass_block', 'minecraft:coarse_dirt',\n",
        "    'minecraft:podzol', 'minecraft:mycelium', 'minecraft:rooted_dirt',\n",
        "    'minecraft:dirt_path', 'minecraft:farmland', 'minecraft:mud',\n",
        "    'minecraft:stone', 'minecraft:cobblestone', 'minecraft:mossy_cobblestone',\n",
        "    'minecraft:bedrock', 'minecraft:deepslate', 'minecraft:tuff',\n",
        "    'minecraft:granite', 'minecraft:diorite', 'minecraft:andesite',\n",
        "    'minecraft:sand', 'minecraft:red_sand', 'minecraft:gravel', 'minecraft:clay',\n",
        "    'minecraft:water', 'minecraft:lava',\n",
        "    'minecraft:terracotta', 'minecraft:white_terracotta', 'minecraft:orange_terracotta',\n",
        "    'minecraft:brown_terracotta', 'minecraft:red_terracotta',\n",
        "    'minecraft:netherrack', 'minecraft:soul_sand', 'minecraft:soul_soil',\n",
        "    'minecraft:end_stone',\n",
        "    'minecraft:snow_block', 'minecraft:ice', 'minecraft:packed_ice',\n",
        "}\n",
        "\n",
        "TERRAIN_TOKENS: Set[int] = set()\n",
        "for tok, block in tok2block.items():\n",
        "    base_name = block.split('[')[0] if '[' in block else block\n",
        "    if base_name in TERRAIN_BLOCKS:\n",
        "        TERRAIN_TOKENS.add(tok)\n",
        "\n",
        "TERRAIN_TOKENS_TENSOR = torch.tensor(sorted(TERRAIN_TOKENS), dtype=torch.long)\n",
        "print(f\"Terrain tokens: {len(TERRAIN_TOKENS)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 6: Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class VQVAEDataset(Dataset):\n",
        "    def __init__(self, data_dir: str):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.h5_files = sorted(self.data_dir.glob(\"*.h5\"))\n",
        "        if not self.h5_files:\n",
        "            raise ValueError(f\"No H5 files in {data_dir}\")\n",
        "        print(f\"Found {len(self.h5_files)} structures in {data_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.h5_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        with h5py.File(self.h5_files[idx], 'r') as f:\n",
        "            key = list(f.keys())[0]\n",
        "            structure = f[key][:].astype(np.int64)\n",
        "        return torch.from_numpy(structure).long()\n",
        "\n",
        "train_dataset = VQVAEDataset(DATA_DIR)\n",
        "val_dataset = VQVAEDataset(VAL_DIR)\n",
        "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 7: FSQ Base Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FSQ(nn.Module):\n",
        "    def __init__(self, levels: List[int], eps: float = 1e-3):\n",
        "        super().__init__()\n",
        "        self.levels = levels\n",
        "        self.dim = len(levels)\n",
        "        self.eps = eps\n",
        "        self.codebook_size = int(np.prod(levels))\n",
        "\n",
        "        self.register_buffer('_levels', torch.tensor(levels, dtype=torch.float32))\n",
        "        basis = []\n",
        "        acc = 1\n",
        "        for L in reversed(levels):\n",
        "            basis.append(acc)\n",
        "            acc *= L\n",
        "        self.register_buffer('_basis', torch.tensor(list(reversed(basis)), dtype=torch.long))\n",
        "        half_levels = [(L - 1) / 2 for L in levels]\n",
        "        self.register_buffer('_half_levels', torch.tensor(half_levels, dtype=torch.float32))\n",
        "        self.register_buffer('_usage', torch.zeros(self.codebook_size))\n",
        "\n",
        "    def reset_usage(self):\n",
        "        self._usage.zero_()\n",
        "\n",
        "    def get_usage_stats(self) -> Tuple[float, float]:\n",
        "        usage = (self._usage > 0).float().mean().item()\n",
        "        if self._usage.sum() == 0:\n",
        "            return usage, 0.0\n",
        "        probs = self._usage / self._usage.sum()\n",
        "        probs = probs[probs > 0]\n",
        "        entropy = -(probs * probs.log()).sum()\n",
        "        perplexity = entropy.exp().item()\n",
        "        return usage, perplexity\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        z_bounded = torch.tanh(z)\n",
        "        z_q_list = []\n",
        "        for i in range(self.dim):\n",
        "            L = self._levels[i]\n",
        "            half_L = self._half_levels[i]\n",
        "            z_i = z_bounded[..., i]\n",
        "            z_i = z_i * half_L\n",
        "            z_i = torch.round(z_i)\n",
        "            z_i = torch.clamp(z_i, -half_L, half_L)\n",
        "            z_i = z_i / half_L\n",
        "            z_q_list.append(z_i)\n",
        "        z_q = torch.stack(z_q_list, dim=-1)\n",
        "        z_q = z_bounded + (z_q - z_bounded).detach()\n",
        "        indices = torch.zeros(z_q.shape[:-1], dtype=torch.long, device=z_q.device)\n",
        "        for i in range(self.dim):\n",
        "            L = self._levels[i].long()\n",
        "            half_L = self._half_levels[i]\n",
        "            z_i = z_q[..., i]\n",
        "            level_idx = ((z_i * half_L) + half_L).round().long()\n",
        "            level_idx = torch.clamp(level_idx, 0, L - 1)\n",
        "            indices = indices + level_idx * self._basis[i]\n",
        "        with torch.no_grad():\n",
        "            for idx in indices.unique():\n",
        "                if idx < self.codebook_size:\n",
        "                    self._usage[idx] += (indices == idx).sum()\n",
        "        return z_q, indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 8: RFSQ Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class InvertibleLayerNorm(nn.Module):\n",
        "    def __init__(self, num_features: int, eps: float = 1e-5):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(num_features))\n",
        "        self.bias = nn.Parameter(torch.zeros(num_features))\n",
        "        self.stored_mean = None\n",
        "        self.stored_std = None\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        self.stored_mean = x.mean(dim=(1, 2, 3), keepdim=True)\n",
        "        self.stored_std = x.std(dim=(1, 2, 3), keepdim=True) + self.eps\n",
        "        x_norm = (x - self.stored_mean) / self.stored_std\n",
        "        return x_norm * self.weight + self.bias\n",
        "\n",
        "    def inverse(self, x_norm: torch.Tensor) -> torch.Tensor:\n",
        "        x = (x_norm - self.bias) / self.weight\n",
        "        return x * self.stored_std + self.stored_mean\n",
        "\n",
        "\n",
        "class RFSQStage(nn.Module):\n",
        "    def __init__(self, levels: List[int]):\n",
        "        super().__init__()\n",
        "        self.fsq = FSQ(levels)\n",
        "        self.layernorm = InvertibleLayerNorm(len(levels))\n",
        "\n",
        "    @property\n",
        "    def codebook_size(self) -> int:\n",
        "        return self.fsq.codebook_size\n",
        "\n",
        "    def reset_usage(self):\n",
        "        self.fsq.reset_usage()\n",
        "\n",
        "    def get_usage_stats(self):\n",
        "        return self.fsq.get_usage_stats()\n",
        "\n",
        "    def forward(self, residual):\n",
        "        z_norm = self.layernorm(residual)\n",
        "        z_q_norm, indices = self.fsq(z_norm)\n",
        "        z_q = self.layernorm.inverse(z_q_norm)\n",
        "        new_residual = residual - z_q\n",
        "        return z_q, new_residual, indices\n",
        "\n",
        "\n",
        "class RFSQ(nn.Module):\n",
        "    def __init__(self, levels_per_stage: List[int], num_stages: int = 2):\n",
        "        super().__init__()\n",
        "        self.num_stages = num_stages\n",
        "        self.dim = len(levels_per_stage)\n",
        "        self.stages = nn.ModuleList([RFSQStage(levels_per_stage) for _ in range(num_stages)])\n",
        "        codes_per_stage = int(np.prod(levels_per_stage))\n",
        "        self.codebook_size = codes_per_stage ** num_stages\n",
        "        self.codes_per_stage = codes_per_stage\n",
        "\n",
        "    def reset_usage(self):\n",
        "        for stage in self.stages:\n",
        "            stage.reset_usage()\n",
        "\n",
        "    def get_usage_stats(self):\n",
        "        return {f'stage{i}': stage.get_usage_stats() for i, stage in enumerate(self.stages)}\n",
        "\n",
        "    def forward(self, z):\n",
        "        residual = z\n",
        "        z_q_sum = torch.zeros_like(z)\n",
        "        all_indices = []\n",
        "        for stage in self.stages:\n",
        "            z_q, residual, indices = stage(residual)\n",
        "            z_q_sum = z_q_sum + z_q\n",
        "            all_indices.append(indices)\n",
        "        return z_q_sum, all_indices\n",
        "\n",
        "    def forward_with_norms(self, z):\n",
        "        residual = z\n",
        "        z_q_sum = torch.zeros_like(z)\n",
        "        all_indices = []\n",
        "        residual_norms = []\n",
        "        for stage in self.stages:\n",
        "            residual_norms.append(residual.norm().item())\n",
        "            z_q, residual, indices = stage(residual)\n",
        "            z_q_sum = z_q_sum + z_q\n",
        "            all_indices.append(indices)\n",
        "        residual_norms.append(residual.norm().item())\n",
        "        return z_q_sum, all_indices, residual_norms\n",
        "\n",
        "print(f\"RFSQ module defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 9: VQ-VAE v6-freq Architecture with Frequency-Weighted Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResidualBlock3D(nn.Module):\n",
        "    def __init__(self, channels: int):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv3d(channels, channels, 3, padding=1)\n",
        "        self.conv2 = nn.Conv3d(channels, channels, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm3d(channels)\n",
        "        self.bn2 = nn.BatchNorm3d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        return F.relu(x + residual)\n",
        "\n",
        "\n",
        "class EncoderV6(nn.Module):\n",
        "    def __init__(self, in_channels: int, hidden_dims: List[int], rfsq_dim: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        current = in_channels\n",
        "        for h in hidden_dims:\n",
        "            layers.extend([\n",
        "                nn.Conv3d(current, h, 4, stride=2, padding=1),\n",
        "                nn.BatchNorm3d(h), nn.ReLU(inplace=True),\n",
        "                nn.Dropout3d(dropout), ResidualBlock3D(h),\n",
        "            ])\n",
        "            current = h\n",
        "        layers.extend([ResidualBlock3D(current), ResidualBlock3D(current),\n",
        "                       nn.Conv3d(current, rfsq_dim, 3, padding=1)])\n",
        "        self.encoder = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "\n",
        "class DecoderV6(nn.Module):\n",
        "    def __init__(self, rfsq_dim: int, hidden_dims: List[int], num_blocks: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        layers = [\n",
        "            nn.Conv3d(rfsq_dim, hidden_dims[0], 3, padding=1),\n",
        "            nn.BatchNorm3d(hidden_dims[0]), nn.ReLU(inplace=True),\n",
        "            ResidualBlock3D(hidden_dims[0]), ResidualBlock3D(hidden_dims[0]),\n",
        "        ]\n",
        "        current = hidden_dims[0]\n",
        "        for h in hidden_dims[1:]:\n",
        "            layers.extend([\n",
        "                ResidualBlock3D(current),\n",
        "                nn.ConvTranspose3d(current, h, 4, stride=2, padding=1),\n",
        "                nn.BatchNorm3d(h), nn.ReLU(inplace=True), nn.Dropout3d(dropout),\n",
        "            ])\n",
        "            current = h\n",
        "        layers.extend([\n",
        "            ResidualBlock3D(current),\n",
        "            nn.ConvTranspose3d(current, current, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm3d(current), nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(current, num_blocks, 3, padding=1),\n",
        "        ])\n",
        "        self.decoder = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, z_q):\n",
        "        return self.decoder(z_q)\n",
        "\n",
        "\n",
        "class FrequencyWeightedLoss(nn.Module):\n",
        "    \"\"\"Cross-entropy with terrain weighting AND per-block frequency weighting.\"\"\"\n",
        "\n",
        "    def __init__(self, frequency_weights: torch.Tensor,\n",
        "                 terrain_weight: float = 0.2, building_weight: float = 1.0, air_weight: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.register_buffer('frequency_weights', frequency_weights)\n",
        "        self.terrain_weight = terrain_weight\n",
        "        self.building_weight = building_weight\n",
        "        self.air_weight = air_weight\n",
        "\n",
        "    def forward(self, logits: torch.Tensor, targets: torch.Tensor,\n",
        "                terrain_mask: torch.Tensor, air_mask: torch.Tensor) -> torch.Tensor:\n",
        "        # Per-voxel cross-entropy\n",
        "        ce_loss = F.cross_entropy(logits, targets, reduction='none')\n",
        "\n",
        "        # Base weights: terrain/building/air\n",
        "        base_weights = torch.full_like(ce_loss, self.building_weight)\n",
        "        base_weights[terrain_mask] = self.terrain_weight\n",
        "        base_weights[air_mask] = self.air_weight\n",
        "\n",
        "        # Frequency weights: look up per-block weight based on TARGET\n",
        "        freq_weights = self.frequency_weights[targets]\n",
        "\n",
        "        # Combined weight = base_weight * freq_weight\n",
        "        combined_weights = base_weights * freq_weights\n",
        "\n",
        "        return (ce_loss * combined_weights).sum() / combined_weights.sum()\n",
        "\n",
        "\n",
        "class VQVAEv6Freq(nn.Module):\n",
        "    \"\"\"VQ-VAE v6-freq with RFSQ + Frequency-Weighted Loss.\"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size: int, emb_dim: int, hidden_dims: List[int],\n",
        "                 rfsq_levels: List[int], num_stages: int, pretrained_emb: np.ndarray,\n",
        "                 frequency_weights: torch.Tensor,\n",
        "                 terrain_weight: float = 0.2, building_weight: float = 1.0,\n",
        "                 air_weight: float = 0.1, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.rfsq_dim = len(rfsq_levels)\n",
        "        self.num_stages = num_stages\n",
        "\n",
        "        self.block_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.block_emb.weight.data.copy_(torch.from_numpy(pretrained_emb))\n",
        "        self.block_emb.weight.requires_grad = False\n",
        "\n",
        "        self.encoder = EncoderV6(emb_dim, hidden_dims, self.rfsq_dim, dropout)\n",
        "        self.rfsq = RFSQ(rfsq_levels, num_stages)\n",
        "        self.decoder = DecoderV6(self.rfsq_dim, list(reversed(hidden_dims)), vocab_size, dropout)\n",
        "\n",
        "        # Frequency-weighted loss (KEY DIFFERENCE from v6)\n",
        "        self.loss_fn = FrequencyWeightedLoss(frequency_weights, terrain_weight, building_weight, air_weight)\n",
        "\n",
        "    def forward(self, block_ids, return_norms=False):\n",
        "        x = self.block_emb(block_ids)\n",
        "        x = x.permute(0, 4, 1, 2, 3).contiguous()\n",
        "        z_e = self.encoder(x)\n",
        "        z_e = z_e.permute(0, 2, 3, 4, 1).contiguous()\n",
        "        if return_norms:\n",
        "            z_q, all_indices, residual_norms = self.rfsq.forward_with_norms(z_e)\n",
        "        else:\n",
        "            z_q, all_indices = self.rfsq(z_e)\n",
        "            residual_norms = None\n",
        "        z_q = z_q.permute(0, 4, 1, 2, 3).contiguous()\n",
        "        logits = self.decoder(z_q)\n",
        "        result = {'logits': logits, 'all_indices': all_indices, 'z_e': z_e, 'z_q': z_q}\n",
        "        if residual_norms:\n",
        "            result['residual_norms'] = residual_norms\n",
        "        return result\n",
        "\n",
        "    def compute_loss(self, block_ids, air_tokens, terrain_tokens, rare_tokens,\n",
        "                     structure_weight=50.0, return_norms=False):\n",
        "        out = self(block_ids, return_norms=return_norms)\n",
        "        logits = out['logits']\n",
        "\n",
        "        B, C, X, Y, Z = logits.shape\n",
        "        logits_flat = logits.permute(0, 2, 3, 4, 1).reshape(-1, C)\n",
        "        targets_flat = block_ids.view(-1)\n",
        "\n",
        "        device = targets_flat.device\n",
        "        air_dev = air_tokens.to(device)\n",
        "        terrain_dev = terrain_tokens.to(device)\n",
        "        rare_dev = rare_tokens.to(device)\n",
        "\n",
        "        is_air = torch.isin(targets_flat, air_dev)\n",
        "        is_terrain = torch.isin(targets_flat, terrain_dev) & ~is_air\n",
        "        is_building = ~is_air & ~is_terrain\n",
        "        is_rare = torch.isin(targets_flat, rare_dev)\n",
        "\n",
        "        # Frequency-weighted loss\n",
        "        loss = self.loss_fn(logits_flat, targets_flat, is_terrain, is_air)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = logits_flat.argmax(dim=1)\n",
        "            is_air_pred = torch.isin(preds, air_dev)\n",
        "            correct = (preds == targets_flat).float()\n",
        "\n",
        "            overall_acc = correct.mean()\n",
        "            terrain_acc = correct[is_terrain].mean() if is_terrain.any() else torch.tensor(0.0, device=device)\n",
        "\n",
        "            if is_building.any():\n",
        "                building_acc = correct[is_building].mean()\n",
        "                building_recall = (is_building & ~is_air_pred).sum().float() / is_building.sum()\n",
        "                building_false_air = (is_building & is_air_pred).sum().float() / is_building.sum()\n",
        "            else:\n",
        "                building_acc = building_recall = building_false_air = torch.tensor(0.0, device=device)\n",
        "\n",
        "            # RARE BLOCK METRICS (KEY FOR v6-freq)\n",
        "            if is_rare.any():\n",
        "                rare_acc = correct[is_rare].mean()\n",
        "                rare_recall = (is_rare & ~is_air_pred).sum().float() / is_rare.sum()\n",
        "            else:\n",
        "                rare_acc = rare_recall = torch.tensor(0.0, device=device)\n",
        "\n",
        "            is_struct = ~is_air\n",
        "            struct_recall = (is_struct & ~is_air_pred).sum().float() / is_struct.sum() if is_struct.any() else torch.tensor(0.0, device=device)\n",
        "\n",
        "            orig_vol = is_struct.sum().float()\n",
        "            pred_vol = (~is_air_pred).sum().float()\n",
        "            vol_ratio = pred_vol / orig_vol if orig_vol > 0 else torch.tensor(1.0, device=device)\n",
        "\n",
        "            wrong_building = is_building & (preds != targets_flat)\n",
        "            if wrong_building.any():\n",
        "                error_similarity = F.cosine_similarity(\n",
        "                    self.block_emb.weight[preds[wrong_building]],\n",
        "                    self.block_emb.weight[targets_flat[wrong_building]], dim=-1).mean()\n",
        "            else:\n",
        "                error_similarity = torch.tensor(0.0, device=device)\n",
        "\n",
        "        result = {\n",
        "            'loss': loss, 'overall_acc': overall_acc, 'terrain_acc': terrain_acc,\n",
        "            'building_acc': building_acc, 'building_recall': building_recall,\n",
        "            'building_false_air': building_false_air, 'struct_recall': struct_recall,\n",
        "            'vol_ratio': vol_ratio, 'error_similarity': error_similarity,\n",
        "            'rare_acc': rare_acc, 'rare_recall': rare_recall,  # NEW!\n",
        "        }\n",
        "        if 'residual_norms' in out:\n",
        "            result['residual_norms'] = out['residual_norms']\n",
        "        return result\n",
        "\n",
        "\n",
        "print(\"VQ-VAE v6-freq architecture defined!\")\n",
        "print(\"KEY: FrequencyWeightedLoss with per-block weights\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 10: Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, optimizer, scaler, device,\n",
        "                air_tokens, terrain_tokens, rare_tokens, structure_weight):\n",
        "    model.train()\n",
        "    model.rfsq.reset_usage()\n",
        "\n",
        "    metrics = {k: 0.0 for k in [\n",
        "        'loss', 'overall_acc', 'terrain_acc', 'building_acc',\n",
        "        'building_recall', 'building_false_air', 'struct_recall',\n",
        "        'vol_ratio', 'error_similarity', 'rare_acc', 'rare_recall',\n",
        "    ]}\n",
        "    grad_norms = []\n",
        "    all_residual_norms = []\n",
        "    n = 0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for batch_idx, batch in enumerate(tqdm(loader, desc=\"Train\", leave=False)):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        with torch.amp.autocast('cuda', enabled=USE_AMP):\n",
        "            return_norms = (batch_idx % 100 == 0)\n",
        "            out = model.compute_loss(batch, air_tokens, terrain_tokens, rare_tokens,\n",
        "                                    structure_weight, return_norms=return_norms)\n",
        "            loss = out['loss'] / GRAD_ACCUM_STEPS\n",
        "\n",
        "        if return_norms and 'residual_norms' in out:\n",
        "            all_residual_norms.append(out['residual_norms'])\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (batch_idx + 1) % GRAD_ACCUM_STEPS == 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            grad_norms.append(grad_norm.item())\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        for k in metrics:\n",
        "            if k in out:\n",
        "                metrics[k] += out[k].item() if torch.is_tensor(out[k]) else out[k]\n",
        "        n += 1\n",
        "\n",
        "    stage_stats = model.rfsq.get_usage_stats()\n",
        "    for stage_name, (usage, perp) in stage_stats.items():\n",
        "        metrics[f'{stage_name}_usage'] = usage\n",
        "        metrics[f'{stage_name}_perplexity'] = perp\n",
        "\n",
        "    metrics['grad_norm'] = sum(grad_norms) / len(grad_norms) if grad_norms else 0.0\n",
        "\n",
        "    if all_residual_norms:\n",
        "        avg_norms = np.mean(all_residual_norms, axis=0)\n",
        "        metrics['residual_decay'] = avg_norms[-1] / avg_norms[0] if avg_norms[0] > 0 else 1.0\n",
        "    else:\n",
        "        metrics['residual_decay'] = 1.0\n",
        "\n",
        "    skip_avg = ['stage0_usage', 'stage0_perplexity', 'stage1_usage', 'stage1_perplexity', 'grad_norm', 'residual_decay']\n",
        "    return {k: v/n if k not in skip_avg else v for k, v in metrics.items()}\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, loader, device, air_tokens, terrain_tokens, rare_tokens, structure_weight):\n",
        "    model.eval()\n",
        "    model.rfsq.reset_usage()\n",
        "\n",
        "    metrics = {k: 0.0 for k in [\n",
        "        'loss', 'overall_acc', 'terrain_acc', 'building_acc',\n",
        "        'building_recall', 'building_false_air', 'struct_recall',\n",
        "        'vol_ratio', 'error_similarity', 'rare_acc', 'rare_recall',\n",
        "    ]}\n",
        "    all_residual_norms = []\n",
        "    n = 0\n",
        "\n",
        "    for batch_idx, batch in enumerate(tqdm(loader, desc=\"Val\", leave=False)):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        with torch.amp.autocast('cuda', enabled=USE_AMP):\n",
        "            return_norms = (batch_idx % 50 == 0)\n",
        "            out = model.compute_loss(batch, air_tokens, terrain_tokens, rare_tokens,\n",
        "                                    structure_weight, return_norms=return_norms)\n",
        "\n",
        "        if return_norms and 'residual_norms' in out:\n",
        "            all_residual_norms.append(out['residual_norms'])\n",
        "\n",
        "        for k in metrics:\n",
        "            if k in out:\n",
        "                metrics[k] += out[k].item() if torch.is_tensor(out[k]) else out[k]\n",
        "        n += 1\n",
        "\n",
        "    stage_stats = model.rfsq.get_usage_stats()\n",
        "    for stage_name, (usage, perp) in stage_stats.items():\n",
        "        metrics[f'{stage_name}_usage'] = usage\n",
        "        metrics[f'{stage_name}_perplexity'] = perp\n",
        "\n",
        "    if all_residual_norms:\n",
        "        avg_norms = np.mean(all_residual_norms, axis=0)\n",
        "        metrics['residual_decay'] = avg_norms[-1] / avg_norms[0] if avg_norms[0] > 0 else 1.0\n",
        "    else:\n",
        "        metrics['residual_decay'] = 1.0\n",
        "\n",
        "    skip_avg = ['stage0_usage', 'stage0_perplexity', 'stage1_usage', 'stage1_perplexity', 'residual_decay']\n",
        "    return {k: v/n if k not in skip_avg else v for k, v in metrics.items()}\n",
        "\n",
        "\n",
        "print(\"Training functions defined with RARE BLOCK metrics!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 11: Create Model and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "g = torch.Generator().manual_seed(SEED)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True, generator=g)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                        num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "model = VQVAEv6Freq(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    emb_dim=EMBEDDING_DIM,\n",
        "    hidden_dims=HIDDEN_DIMS,\n",
        "    rfsq_levels=RFSQ_LEVELS_PER_STAGE,\n",
        "    num_stages=NUM_STAGES,\n",
        "    pretrained_emb=v3_embeddings,\n",
        "    frequency_weights=FREQUENCY_WEIGHT_TENSOR,\n",
        "    terrain_weight=TERRAIN_WEIGHT,\n",
        "    building_weight=BUILDING_WEIGHT,\n",
        "    air_weight=AIR_WEIGHT,\n",
        "    dropout=DROPOUT,\n",
        ").to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total params: {total_params:,}\")\n",
        "print(f\"Trainable params: {trainable_params:,}\")\n",
        "print(f\"RFSQ total codes: {model.rfsq.codebook_size:,}\")\n",
        "\n",
        "optimizer = optim.AdamW([p for p in model.parameters() if p.requires_grad], lr=BASE_LR, weight_decay=1e-5)\n",
        "scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP)\n",
        "print(f\"\\nOptimizer: AdamW, LR={BASE_LR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 12: Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"VQ-VAE V6-FREQ TRAINING - RFSQ + FREQUENCY WEIGHTING\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Key features:\")\n",
        "print(f\"  - RFSQ: {NUM_STAGES}-stage residual quantization\")\n",
        "print(f\"  - Frequency weighting: up to {FREQUENCY_WEIGHT_CAP}x for rare blocks\")\n",
        "print(f\"  - Tracking: rare_acc, rare_recall\")\n",
        "print()\n",
        "\n",
        "history = {\n",
        "    'train_loss': [], 'train_building_acc': [], 'train_building_recall': [],\n",
        "    'train_terrain_acc': [], 'train_struct_recall': [],\n",
        "    'val_loss': [], 'val_building_acc': [], 'val_building_recall': [],\n",
        "    'val_terrain_acc': [], 'val_struct_recall': [],\n",
        "    'train_stage0_usage': [], 'train_stage0_perplexity': [],\n",
        "    'train_stage1_usage': [], 'train_stage1_perplexity': [],\n",
        "    'val_stage0_usage': [], 'val_stage0_perplexity': [],\n",
        "    'val_stage1_usage': [], 'val_stage1_perplexity': [],\n",
        "    'train_building_false_air': [], 'val_building_false_air': [],\n",
        "    'train_vol_ratio': [], 'val_vol_ratio': [],\n",
        "    'train_error_similarity': [], 'val_error_similarity': [],\n",
        "    'train_grad_norm': [],\n",
        "    'train_residual_decay': [], 'val_residual_decay': [],\n",
        "    # NEW: Rare block metrics\n",
        "    'train_rare_acc': [], 'val_rare_acc': [],\n",
        "    'train_rare_recall': [], 'val_rare_recall': [],\n",
        "}\n",
        "\n",
        "best_building_acc = 0\n",
        "best_epoch = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(TOTAL_EPOCHS):\n",
        "    train_m = train_epoch(model, train_loader, optimizer, scaler, device,\n",
        "                          AIR_TOKENS_TENSOR, TERRAIN_TOKENS_TENSOR, RARE_BLOCK_TOKENS_TENSOR, STRUCTURE_WEIGHT)\n",
        "    val_m = validate(model, val_loader, device,\n",
        "                     AIR_TOKENS_TENSOR, TERRAIN_TOKENS_TENSOR, RARE_BLOCK_TOKENS_TENSOR, STRUCTURE_WEIGHT)\n",
        "\n",
        "    # Record all metrics\n",
        "    for key in history:\n",
        "        if key.startswith('train_'):\n",
        "            metric_name = key[6:]  # Remove 'train_'\n",
        "            history[key].append(train_m.get(metric_name, 0))\n",
        "        elif key.startswith('val_'):\n",
        "            metric_name = key[4:]  # Remove 'val_'\n",
        "            history[key].append(val_m.get(metric_name, 0))\n",
        "\n",
        "    if val_m['building_acc'] > best_building_acc:\n",
        "        best_building_acc = val_m['building_acc']\n",
        "        best_epoch = epoch + 1\n",
        "        torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v6_freq_best.pt\")\n",
        "\n",
        "    print(f\"Epoch {epoch+1:2d} | \"\n",
        "          f\"Build: {train_m['building_acc']:.1%}/{val_m['building_acc']:.1%} | \"\n",
        "          f\"Rare: {train_m['rare_acc']:.1%}/{val_m['rare_acc']:.1%} | \"\n",
        "          f\"RareRecall: {val_m['rare_recall']:.1%} | \"\n",
        "          f\"S0: {val_m.get('stage0_perplexity', 0):.0f}\")\n",
        "\n",
        "train_time = time.time() - start_time\n",
        "print(f\"\\nTraining complete in {train_time/60:.1f} minutes\")\n",
        "print(f\"Best val building accuracy: {best_building_acc:.1%} at epoch {best_epoch}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 13: Plot Training Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(4, 4, figsize=(20, 16))\n",
        "epochs = range(1, TOTAL_EPOCHS + 1)\n",
        "\n",
        "# Row 1: Core metrics\n",
        "ax = axes[0, 0]\n",
        "ax.plot(epochs, history['train_building_acc'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_building_acc'], 'r--', label='Val')\n",
        "ax.set_title('Building Accuracy', fontweight='bold')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[0, 1]\n",
        "ax.plot(epochs, history['train_rare_acc'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_rare_acc'], 'r--', label='Val')\n",
        "ax.set_title('RARE Block Accuracy (KEY!)', fontweight='bold', color='green')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[0, 2]\n",
        "ax.plot(epochs, history['train_rare_recall'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_rare_recall'], 'r--', label='Val')\n",
        "ax.axhline(y=0.2, color='g', linestyle='--', alpha=0.5, label='Target 20%')\n",
        "ax.set_title('RARE Block Recall (KEY!)', fontweight='bold', color='green')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[0, 3]\n",
        "ax.plot(epochs, history['train_building_recall'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_building_recall'], 'r--', label='Val')\n",
        "ax.set_title('Building Recall')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Row 2: RFSQ metrics\n",
        "ax = axes[1, 0]\n",
        "ax.plot(epochs, history['train_stage0_perplexity'], 'b-', label='Train S0')\n",
        "ax.plot(epochs, history['val_stage0_perplexity'], 'r--', label='Val S0')\n",
        "ax.set_title('Stage 0 Perplexity')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[1, 1]\n",
        "ax.plot(epochs, history['train_stage1_perplexity'], 'b-', label='Train S1')\n",
        "ax.plot(epochs, history['val_stage1_perplexity'], 'r--', label='Val S1')\n",
        "ax.set_title('Stage 1 Perplexity')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[1, 2]\n",
        "ax.plot(epochs, history['train_residual_decay'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_residual_decay'], 'r--', label='Val')\n",
        "ax.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5)\n",
        "ax.set_title('Residual Decay')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[1, 3]\n",
        "ax.plot(epochs, history['train_terrain_acc'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_terrain_acc'], 'r--', label='Val')\n",
        "ax.set_title('Terrain Accuracy')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Row 3: Loss and diagnostics\n",
        "ax = axes[2, 0]\n",
        "ax.plot(epochs, history['train_loss'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_loss'], 'r--', label='Val')\n",
        "ax.set_title('Loss')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[2, 1]\n",
        "ax.plot(epochs, history['train_building_false_air'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_building_false_air'], 'r--', label='Val')\n",
        "ax.set_title('Building False Air')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[2, 2]\n",
        "ax.plot(epochs, history['train_struct_recall'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_struct_recall'], 'r--', label='Val')\n",
        "ax.set_title('Structure Recall')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[2, 3]\n",
        "ax.plot(epochs, history['train_grad_norm'], 'g-')\n",
        "ax.axhline(y=1.0, color='r', linestyle='--', alpha=0.5)\n",
        "ax.set_title('Gradient Norm')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Row 4: Comparisons and summary\n",
        "ax = axes[3, 0]\n",
        "ax.plot(epochs, history['val_error_similarity'], 'b-')\n",
        "ax.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5)\n",
        "ax.set_title('Error Similarity (Val)')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# v5.1 vs v6-freq comparison\n",
        "ax = axes[3, 1]\n",
        "v51_baseline = {'Build\\nAcc': 0.456, 'Build\\nRecall': 0.847, 'Rare\\nAcc': 0.0, 'Rare\\nRecall': 0.0}\n",
        "v6_freq = {\n",
        "    'Build\\nAcc': history['val_building_acc'][-1],\n",
        "    'Build\\nRecall': history['val_building_recall'][-1],\n",
        "    'Rare\\nAcc': history['val_rare_acc'][-1],\n",
        "    'Rare\\nRecall': history['val_rare_recall'][-1],\n",
        "}\n",
        "x = np.arange(len(v51_baseline))\n",
        "width = 0.35\n",
        "ax.bar(x - width/2, list(v51_baseline.values()), width, label='v5.1', color='gray')\n",
        "ax.bar(x + width/2, list(v6_freq.values()), width, label='v6-freq', color='green')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(v51_baseline.keys())\n",
        "ax.set_title('v5.1 vs v6-freq')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Final metrics\n",
        "ax = axes[3, 2]\n",
        "final = {\n",
        "    'Build\\nAcc': history['val_building_acc'][-1],\n",
        "    'Rare\\nAcc': history['val_rare_acc'][-1],\n",
        "    'Rare\\nRecall': history['val_rare_recall'][-1],\n",
        "    'S0\\nUsage': history['val_stage0_usage'][-1] if history['val_stage0_usage'] else 0,\n",
        "}\n",
        "colors = ['green', 'blue', 'purple', 'orange']\n",
        "bars = ax.bar(final.keys(), final.values(), color=colors)\n",
        "ax.set_title('Final Val Metrics')\n",
        "ax.set_ylim(0, 1)\n",
        "for bar, val in zip(bars, final.values()):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "            f'{val:.2f}', ha='center', fontsize=9)\n",
        "\n",
        "# Summary\n",
        "ax = axes[3, 3]\n",
        "ax.axis('off')\n",
        "summary = f\"\"\"VQ-VAE v6-freq Results\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "Best Building Acc: {best_building_acc:.1%} (epoch {best_epoch})\n",
        "\n",
        "RARE BLOCK METRICS:\n",
        "  Rare Accuracy: {history['val_rare_acc'][-1]:.1%}\n",
        "  Rare Recall: {history['val_rare_recall'][-1]:.1%}\n",
        "  (Target: >20%)\n",
        "\n",
        "Frequency Weighting:\n",
        "  Cap: {FREQUENCY_WEIGHT_CAP}x\n",
        "\n",
        "Training Time: {train_time/60:.1f} min\"\"\"\n",
        "ax.text(0.1, 0.9, summary, transform=ax.transAxes, fontsize=11,\n",
        "        verticalalignment='top', fontfamily='monospace')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUTPUT_DIR}/vqvae_v6_freq_training.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RARE BLOCK ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Rare block accuracy: {history['val_rare_acc'][-1]:.1%}\")\n",
        "print(f\"Rare block recall: {history['val_rare_recall'][-1]:.1%}\")\n",
        "if history['val_rare_recall'][-1] > 0.2:\n",
        "    print(\"  SUCCESS: Rare blocks are being reconstructed!\")\n",
        "elif history['val_rare_recall'][-1] > 0.1:\n",
        "    print(\"  PARTIAL: Some improvement over v5.1's 0%\")\n",
        "else:\n",
        "    print(\"  NEEDS MORE: Rare blocks still struggling\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 14: Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = {\n",
        "    'config': {\n",
        "        'version': 'v6-freq',\n",
        "        'changes_from_v6': ['Frequency-based block weighting', f'Weight cap: {FREQUENCY_WEIGHT_CAP}x'],\n",
        "        'hidden_dims': HIDDEN_DIMS,\n",
        "        'rfsq_levels_per_stage': RFSQ_LEVELS_PER_STAGE,\n",
        "        'num_stages': NUM_STAGES,\n",
        "        'frequency_weight_cap': FREQUENCY_WEIGHT_CAP,\n",
        "        'total_epochs': TOTAL_EPOCHS,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'seed': SEED,\n",
        "    },\n",
        "    'results': {\n",
        "        'best_building_acc': float(best_building_acc),\n",
        "        'best_epoch': best_epoch,\n",
        "        'final_building_acc': float(history['val_building_acc'][-1]),\n",
        "        'final_building_recall': float(history['val_building_recall'][-1]),\n",
        "        'final_rare_acc': float(history['val_rare_acc'][-1]),\n",
        "        'final_rare_recall': float(history['val_rare_recall'][-1]),\n",
        "        'final_stage0_perplexity': float(history['val_stage0_perplexity'][-1]) if history['val_stage0_perplexity'] else 0,\n",
        "        'final_stage1_perplexity': float(history['val_stage1_perplexity'][-1]) if history['val_stage1_perplexity'] else 0,\n",
        "        'training_time_min': float(train_time / 60),\n",
        "    },\n",
        "    'history': {k: [float(x) for x in v] for k, v in history.items()},\n",
        "}\n",
        "\n",
        "with open(f\"{OUTPUT_DIR}/vqvae_v6_freq_results.json\", 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "checkpoint = {\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'config': {\n",
        "        'version': 'v6-freq',\n",
        "        'vocab_size': VOCAB_SIZE,\n",
        "        'emb_dim': EMBEDDING_DIM,\n",
        "        'hidden_dims': HIDDEN_DIMS,\n",
        "        'rfsq_levels': RFSQ_LEVELS_PER_STAGE,\n",
        "        'num_stages': NUM_STAGES,\n",
        "        'frequency_weight_cap': FREQUENCY_WEIGHT_CAP,\n",
        "    },\n",
        "    'air_tokens': AIR_TOKENS_LIST,\n",
        "    'terrain_tokens': sorted(TERRAIN_TOKENS),\n",
        "    'rare_tokens': sorted(RARE_BLOCK_TOKENS),\n",
        "    'best_building_acc': float(best_building_acc),\n",
        "    'best_epoch': best_epoch,\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, f\"{OUTPUT_DIR}/vqvae_v6_freq_best_checkpoint.pt\")\n",
        "torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v6_freq_final.pt\")\n",
        "\n",
        "print(\"\\nResults saved:\")\n",
        "print(f\"  - {OUTPUT_DIR}/vqvae_v6_freq_results.json\")\n",
        "print(f\"  - {OUTPUT_DIR}/vqvae_v6_freq_best_checkpoint.pt\")\n",
        "print(f\"  - {OUTPUT_DIR}/vqvae_v6_freq_final.pt\")\n",
        "print(f\"  - {OUTPUT_DIR}/vqvae_v6_freq_training.png\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL RESULTS - VQ-VAE v6-freq (RFSQ + Frequency Weighting)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Best building accuracy: {best_building_acc:.1%} at epoch {best_epoch}\")\n",
        "print(f\"\\nRARE BLOCK PERFORMANCE:\")\n",
        "print(f\"  Rare accuracy: {history['val_rare_acc'][-1]:.1%}\")\n",
        "print(f\"  Rare recall: {history['val_rare_recall'][-1]:.1%}\")\n",
        "print(f\"  (v5.1 baseline: ~0%)\")\n",
        "print(f\"\\nTraining time: {train_time/60:.1f} minutes\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {"gpuType": "T4", "provenance": []},
    "kernelspec": {"display_name": "Python 3", "name": "python3"},
    "language_info": {"name": "python"}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}