{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQ-VAE v8-B Training - 16Ãƒâ€”16Ãƒâ€”16 Latent Resolution Upgrade\n",
    "\n",
    "## Changes from v6-freq\n",
    "\n",
    "| Change | v6-freq | v8-B |\n",
    "|--------|---------|------|\n",
    "| Latent resolution | 8Ãƒâ€”8Ãƒâ€”8 (512 positions) | **16Ãƒâ€”16Ãƒâ€”16 (4,096 positions)** |\n",
    "| Compression ratio | 64:1 | **8:1** |\n",
    "| Downsampling stages | 2 (32Ã¢â€ â€™16Ã¢â€ â€™8) | **1 (32Ã¢â€ â€™16)** |\n",
    "| ResBlocks at latent | 2 | **6 (more capacity)** |\n",
    "| Batch size | 4 | **2 (larger model)** |\n",
    "| Gradient checkpointing | No | **Yes (required for memory)** |\n",
    "| Volume penalty | No | **Yes (fixes 1.68x over-prediction)** |\n",
    "| Perceptual loss | No | **Yes (spatial smoothness)** |\n",
    "| Training epochs | 25 | **35** |\n",
    "\n",
    "## Why 16Ãƒâ€”16Ãƒâ€”16 Latent?\n",
    "\n",
    "v6-freq's 8Ãƒâ€”8Ãƒâ€”8 latent (512 spatial positions) is the primary bottleneck:\n",
    "- 64:1 compression ratio loses fine structural detail\n",
    "- Only 512 positions to represent entire 32Ã‚Â³ structure\n",
    "\n",
    "v8-B upgrades to 16Ãƒâ€”16Ãƒâ€”16 (4,096 positions):\n",
    "- 8:1 compression ratio preserves more structure\n",
    "- 8x more spatial positions\n",
    "- Matches MaskGIT's approach for image generation (16:1 ratio for 256px images)\n",
    "\n",
    "## Goals\n",
    "\n",
    "| Metric | v6-freq | v8-B Target |\n",
    "|--------|---------|-------------|\n",
    "| Building Accuracy | 49.2% | **60-65%** |\n",
    "| Building Recall | 97.0% | 92-95% |\n",
    "| Volume Ratio | 1.68x | **1.1-1.2x** |\n",
    "| False Air Rate | 3.0% | 4-6% |\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "Encoder: 32Ã‚Â³ Ã¢â€ â€™ conv(4,2) Ã¢â€ â€™ 16Ã‚Â³ Ã¢â€ â€™ ResBlocks(6) Ã¢â€ â€™ latent[4,16,16,16]\n",
    "RFSQ: [5,5,5,5] levels Ãƒâ€” 2 stages (same as v6-freq)\n",
    "Decoder: latent[4,16,16,16] Ã¢â€ â€™ ResBlocks(6) Ã¢â€ â€™ convT(4,2) Ã¢â€ â€™ 32Ã‚Â³ Ã¢â€ â€™ logits\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Mount Google Drive (if using Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if using Google Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect environment and set paths\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    # Google Colab\n",
    "    OUTPUT_DIR = '/content/drive/MyDrive/minecraft_ai/vqvae_v8b'\n",
    "    DRIVE_BASE = '/content/drive/MyDrive/minecraft_ai'\n",
    "    # Try Drive first (where data is), then /content\n",
    "    drive_root = Path('/content/drive/MyDrive/minecraft_ai')\n",
    "    if (drive_root / 'src' / 'models' / 'vqvae.py').exists():\n",
    "        PROJECT_ROOT = drive_root\n",
    "        print(f\"Using repository from Drive: {PROJECT_ROOT}\")\n",
    "    else:\n",
    "        PROJECT_ROOT = Path('/content/minecraft_ai')  # Will be cloned here\n",
    "        print(f\"Using repository from /content: {PROJECT_ROOT}\")\n",
    "    \n",
    "    # Add project root to Python path for Colab\n",
    "    if str(PROJECT_ROOT) not in sys.path:\n",
    "        sys.path.insert(0, str(PROJECT_ROOT))\n",
    "        print(f\"Added {PROJECT_ROOT} to Python path\")\n",
    "    \n",
    "    # Check if repository needs to be cloned\n",
    "    if not (PROJECT_ROOT / 'src' / 'models' / 'vqvae.py').exists():\n",
    "        print(f\"WARNING: Repository not found at {PROJECT_ROOT}\")\n",
    "        print(\"Please clone the repository first:\")\n",
    "        print(\"  !git clone <your-repo-url> /content/minecraft_ai\")\n",
    "        print(\"Or if using Drive:\")\n",
    "        print(\"  PROJECT_ROOT = Path('/content/drive/MyDrive/minecraft_ai')\")\n",
    "else:\n",
    "    # Local - find project root\n",
    "    current = Path.cwd()\n",
    "    # Look for marker files to find project root\n",
    "    while current != current.parent:\n",
    "        if (current / 'src' / 'models' / 'vqvae.py').exists():\n",
    "            PROJECT_ROOT = current\n",
    "            break\n",
    "        current = current.parent\n",
    "    else:\n",
    "        # Fallback: assume we're in minecraft_ai directory\n",
    "        PROJECT_ROOT = Path.cwd()\n",
    "    \n",
    "    OUTPUT_DIR = str(PROJECT_ROOT / 'data' / 'output' / 'vqvae' / 'v8b')\n",
    "    DRIVE_BASE = str(PROJECT_ROOT / 'data')\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Python path includes project root: {str(PROJECT_ROOT) in sys.path}\")\n",
    "print(f\"src/models/vqvae.py exists: {(PROJECT_ROOT / 'src' / 'models' / 'vqvae.py').exists()}\")\n",
    "print(f\"Output will be saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any, Set\n",
    "from collections import Counter\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Ensure PROJECT_ROOT is set and add to path\n",
    "if 'PROJECT_ROOT' not in globals():\n",
    "    # If running in Colab, set default path\n",
    "    if 'COLAB_GPU' in os.environ:\n",
    "        PROJECT_ROOT = Path('/content/minecraft_ai')\n",
    "    else:\n",
    "        # Find project root locally\n",
    "        current = Path.cwd()\n",
    "        while current != current.parent:\n",
    "            if (current / 'src' / 'models' / 'vqvae.py').exists():\n",
    "                PROJECT_ROOT = current\n",
    "                break\n",
    "            current = current.parent\n",
    "        else:\n",
    "            PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "# Add project root to path\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "    print(f\"Added to path: {PROJECT_ROOT}\")\n",
    "\n",
    "# Verify the module exists\n",
    "vqvae_path = PROJECT_ROOT / 'src' / 'models' / 'vqvae.py'\n",
    "if not vqvae_path.exists():\n",
    "    if 'COLAB_GPU' in os.environ:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Repository not found at {PROJECT_ROOT}\\\\n\"\n",
    "            f\"Please clone the repository first:\\\\n\"\n",
    "            f\"  !git clone <your-repo-url> /content/minecraft_ai\\\\n\"\n",
    "            f\"Or if using Google Drive:\\\\n\"\n",
    "            f\"  PROJECT_ROOT = Path('/content/drive/MyDrive/minecraft_ai')\"\n",
    "        )\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Could not find vqvae.py at {vqvae_path}\\\\n\"\n",
    "            f\"Project root: {PROJECT_ROOT}\\\\n\"\n",
    "            f\"Current directory: {Path.cwd()}\"\n",
    "        )\n",
    "\n",
    "# Import v8-B model and loss from src\n",
    "from src.models.vqvae import VQVAEv8B, ResidualBlock3D\n",
    "from src.models.losses import FrequencyWeightedLoss, compute_frequency_weights\n",
    "from src.models.rfsq import RFSQ\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data Paths ===\n",
    "DATA_DIR = f\"{DRIVE_BASE}/splits/train\"\n",
    "VAL_DIR = f\"{DRIVE_BASE}/splits/val\"\n",
    "VOCAB_PATH = f\"{DRIVE_BASE}/vocabulary/tok2block.json\"\n",
    "V3_EMBEDDINGS_PATH = f\"{DRIVE_BASE}/vocabulary/block_embeddings_v3.npy\"\n",
    "\n",
    "# Verify paths exist\n",
    "print(f\"Checking paths...\")\n",
    "for name, path in [('DATA_DIR', DATA_DIR), ('VAL_DIR', VAL_DIR), \n",
    "                    ('VOCAB_PATH', VOCAB_PATH), ('V3_EMBEDDINGS_PATH', V3_EMBEDDINGS_PATH)]:\n",
    "    exists = Path(path).exists() if not path.endswith('.h5') else Path(path).parent.exists()\n",
    "    print(f\"  {name}: {path} {'[OK]' if exists else '[NOT FOUND]'}\")\n",
    "\n",
    "# === V8-B Architecture Configuration ===\n",
    "HIDDEN_DIM = 192  # Single hidden dim (simpler than [96, 192])\n",
    "RFSQ_LEVELS_PER_STAGE = [5, 5, 5, 5]  # Same as v6-freq\n",
    "NUM_STAGES = 2\n",
    "DROPOUT = 0.1\n",
    "NUM_RESBLOCKS_PER_STAGE = 2\n",
    "NUM_RESBLOCKS_LATENT = 6  # More capacity at latent resolution\n",
    "\n",
    "# === Frequency Weighting (from v6-freq) ===\n",
    "USE_FREQUENCY_WEIGHTING = True\n",
    "FREQUENCY_WEIGHT_CAP = 5.0  # Reduced from 10.0 for better balance\n",
    "\n",
    "# === NEW: Volume Penalty and Perceptual Loss ===\n",
    "VOLUME_PENALTY_WEIGHT = 1.0  # NEW: Fixes 1.68x over-prediction\n",
    "PERCEPTUAL_WEIGHT = 0.1      # NEW: Spatial smoothness\n",
    "\n",
    "# === Terrain Settings ===\n",
    "TERRAIN_WEIGHT = 0.2\n",
    "BUILDING_WEIGHT = 1.0\n",
    "AIR_WEIGHT = 0.1\n",
    "\n",
    "# === Training Configuration ===\n",
    "TOTAL_EPOCHS = 35  # Increased from 25\n",
    "BATCH_SIZE = 2  # Reduced from 4 (larger model)\n",
    "BASE_LR = 2e-4  # Slightly lower than v6-freq's 3e-4\n",
    "USE_AMP = True\n",
    "GRAD_ACCUM_STEPS = 8  # Effective batch = 16\n",
    "USE_GRADIENT_CHECKPOINTING = True  # NEW: Required for T4 memory\n",
    "\n",
    "SEED = 42\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "CODES_PER_STAGE = int(np.prod(RFSQ_LEVELS_PER_STAGE))\n",
    "TOTAL_IMPLICIT_CODES = CODES_PER_STAGE ** NUM_STAGES\n",
    "\n",
    "print(\"\\nVQ-VAE v8-B (16x16x16 Latent) Configuration:\")\n",
    "print(f\"  Latent resolution: 16x16x16 = 4,096 spatial positions\")\n",
    "print(f\"  Compression ratio: 8:1 (vs v6-freq's 64:1)\")\n",
    "print(f\"  Hidden dim: {HIDDEN_DIM}\")\n",
    "print(f\"  ResBlocks at latent: {NUM_RESBLOCKS_LATENT}\")\n",
    "print(f\"  RFSQ: {NUM_STAGES} stages x {CODES_PER_STAGE:,} codes\")\n",
    "print(f\"  Total implicit codes: {TOTAL_IMPLICIT_CODES:,}\")\n",
    "print(f\"\\nNEW FEATURES:\")\n",
    "print(f\"  Gradient checkpointing: {USE_GRADIENT_CHECKPOINTING}\")\n",
    "print(f\"  Volume penalty weight: {VOLUME_PENALTY_WEIGHT}\")\n",
    "print(f\"  Perceptual weight: {PERCEPTUAL_WEIGHT}\")\n",
    "print(f\"  Frequency weight cap: {FREQUENCY_WEIGHT_CAP}x (reduced from 10x)\")\n",
    "print(f\"\\nTRAINING:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE} (effective: {BATCH_SIZE * GRAD_ACCUM_STEPS})\")\n",
    "print(f\"  Epochs: {TOTAL_EPOCHS}\")\n",
    "print(f\"  Learning rate: {BASE_LR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Load Vocabulary and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VOCAB_PATH, 'r') as f:\n",
    "    tok2block = {int(k): v for k, v in json.load(f).items()}\n",
    "\n",
    "block2tok = {v: k for k, v in tok2block.items()}\n",
    "VOCAB_SIZE = len(tok2block)\n",
    "print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
    "\n",
    "# Find air tokens\n",
    "AIR_TOKENS: Set[int] = set()\n",
    "for tok, block in tok2block.items():\n",
    "    if 'air' in block.lower() and 'stair' not in block.lower():\n",
    "        AIR_TOKENS.add(tok)\n",
    "        print(f\"  Air token: {tok} = {block}\")\n",
    "\n",
    "AIR_TOKENS_LIST = sorted(AIR_TOKENS)\n",
    "\n",
    "# Load V3 embeddings\n",
    "v3_embeddings = np.load(V3_EMBEDDINGS_PATH).astype(np.float32)\n",
    "EMBEDDING_DIM = v3_embeddings.shape[1]\n",
    "print(f\"V3 embeddings: {v3_embeddings.shape} (dim={EMBEDDING_DIM})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Compute Block Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing block frequencies from training data...\")\n",
    "print(\"(This may take a few minutes)\")\n",
    "\n",
    "# Scan all training data\n",
    "all_block_ids = []\n",
    "train_files = sorted(Path(DATA_DIR).glob(\"*.h5\"))\n",
    "\n",
    "for h5_file in tqdm(train_files, desc=\"Scanning training data\"):\n",
    "    with h5py.File(h5_file, 'r') as f:\n",
    "        key = list(f.keys())[0]\n",
    "        structure = f[key][:].flatten()\n",
    "        all_block_ids.append(torch.from_numpy(structure).long())\n",
    "\n",
    "all_block_ids = torch.cat(all_block_ids)\n",
    "print(f\"\\nTotal blocks scanned: {len(all_block_ids):,}\")\n",
    "\n",
    "# Compute frequency weights using helper function\n",
    "FREQUENCY_WEIGHT_TENSOR = compute_frequency_weights(\n",
    "    all_block_ids,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    smoothing=0.5  # sqrt weighting\n",
    ")\n",
    "\n",
    "# Cap at max weight\n",
    "FREQUENCY_WEIGHT_TENSOR = FREQUENCY_WEIGHT_TENSOR.clamp(max=FREQUENCY_WEIGHT_CAP)\n",
    "\n",
    "# Show top 10 rarest blocks\n",
    "print(\"\\nTop 10 RAREST blocks (highest weights):\")\n",
    "top_indices = torch.argsort(FREQUENCY_WEIGHT_TENSOR, descending=True)[:10]\n",
    "for idx in top_indices:\n",
    "    tok = idx.item()\n",
    "    weight = FREQUENCY_WEIGHT_TENSOR[tok].item()\n",
    "    block_name = tok2block.get(tok, f\"UNKNOWN_{tok}\")\n",
    "    count = (all_block_ids == tok).sum().item()\n",
    "    print(f\"  {block_name}: weight={weight:.1f}x (count={count:,})\")\n",
    "\n",
    "# Show top 10 most common blocks\n",
    "print(\"\\nTop 10 MOST COMMON blocks (lowest weights):\")\n",
    "bottom_indices = torch.argsort(FREQUENCY_WEIGHT_TENSOR)[:10]\n",
    "for idx in bottom_indices:\n",
    "    tok = idx.item()\n",
    "    weight = FREQUENCY_WEIGHT_TENSOR[tok].item()\n",
    "    block_name = tok2block.get(tok, f\"UNKNOWN_{tok}\")\n",
    "    count = (all_block_ids == tok).sum().item()\n",
    "    print(f\"  {block_name}: weight={weight:.2f}x (count={count:,})\")\n",
    "\n",
    "# Identify rare block categories for tracking\n",
    "RARE_BLOCK_KEYWORDS = ['chest', 'door', 'fence', 'trapdoor', 'carpet', 'bed', 'button', 'lever']\n",
    "RARE_BLOCK_TOKENS = set()\n",
    "for tok, block in tok2block.items():\n",
    "    for keyword in RARE_BLOCK_KEYWORDS:\n",
    "        if keyword in block.lower():\n",
    "            RARE_BLOCK_TOKENS.add(tok)\n",
    "            break\n",
    "\n",
    "RARE_BLOCK_TOKENS_TENSOR = torch.tensor(sorted(RARE_BLOCK_TOKENS), dtype=torch.long)\n",
    "print(f\"\\nRare block tokens identified: {len(RARE_BLOCK_TOKENS)}\")\n",
    "print(f\"Keywords: {RARE_BLOCK_KEYWORDS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Terrain Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TERRAIN_BLOCKS: Set[str] = {\n",
    "    'minecraft:dirt', 'minecraft:grass_block', 'minecraft:coarse_dirt',\n",
    "    'minecraft:podzol', 'minecraft:mycelium', 'minecraft:rooted_dirt',\n",
    "    'minecraft:dirt_path', 'minecraft:farmland', 'minecraft:mud',\n",
    "    'minecraft:stone', 'minecraft:cobblestone', 'minecraft:mossy_cobblestone',\n",
    "    'minecraft:bedrock', 'minecraft:deepslate', 'minecraft:tuff',\n",
    "    'minecraft:granite', 'minecraft:diorite', 'minecraft:andesite',\n",
    "    'minecraft:sand', 'minecraft:red_sand', 'minecraft:gravel', 'minecraft:clay',\n",
    "    'minecraft:water', 'minecraft:lava',\n",
    "    'minecraft:terracotta', 'minecraft:white_terracotta', 'minecraft:orange_terracotta',\n",
    "    'minecraft:brown_terracotta', 'minecraft:red_terracotta',\n",
    "    'minecraft:netherrack', 'minecraft:soul_sand', 'minecraft:soul_soil',\n",
    "    'minecraft:end_stone',\n",
    "    'minecraft:snow_block', 'minecraft:ice', 'minecraft:packed_ice',\n",
    "}\n",
    "\n",
    "TERRAIN_TOKENS: Set[int] = set()\n",
    "for tok, block in tok2block.items():\n",
    "    base_name = block.split('[')[0] if '[' in block else block\n",
    "    if base_name in TERRAIN_BLOCKS:\n",
    "        TERRAIN_TOKENS.add(tok)\n",
    "\n",
    "TERRAIN_TOKENS_TENSOR = torch.tensor(sorted(TERRAIN_TOKENS), dtype=torch.long)\n",
    "print(f\"Terrain tokens: {len(TERRAIN_TOKENS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAEDataset(Dataset):\n",
    "    def __init__(self, data_dir: str):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.h5_files = sorted(self.data_dir.glob(\"*.h5\"))\n",
    "        if not self.h5_files:\n",
    "            raise ValueError(f\"No H5 files in {data_dir}\")\n",
    "        print(f\"Found {len(self.h5_files)} structures in {data_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.h5_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.h5_files[idx], 'r') as f:\n",
    "            key = list(f.keys())[0]\n",
    "            structure = f[key][:].astype(np.int64)\n",
    "        return torch.from_numpy(structure).long()\n",
    "\n",
    "train_dataset = VQVAEDataset(DATA_DIR)\n",
    "val_dataset = VQVAEDataset(VAL_DIR)\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Create model\n",
    "model = VQVAEv8B(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    emb_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    rfsq_levels=RFSQ_LEVELS_PER_STAGE,\n",
    "    num_stages=NUM_STAGES,\n",
    "    dropout=DROPOUT,\n",
    "    pretrained_embeddings=torch.from_numpy(v3_embeddings),\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel Statistics:\")\n",
    "print(f\"  Total params: {total_params:,}\")\n",
    "print(f\"  Trainable params: {trainable_params:,}\")\n",
    "print(f\"  RFSQ total codes: {model.quantizer.codebook_size:,}\")\n",
    "print(f\"  Latent shape: [B, {model.rfsq_dim}, 16, 16, 16]\")\n",
    "\n",
    "# Create loss function\n",
    "criterion = FrequencyWeightedLoss(\n",
    "    frequency_weights=FREQUENCY_WEIGHT_TENSOR,\n",
    "    frequency_cap=FREQUENCY_WEIGHT_CAP,\n",
    "    terrain_weight=TERRAIN_WEIGHT,\n",
    "    building_weight=BUILDING_WEIGHT,\n",
    "    air_weight=AIR_WEIGHT,\n",
    "    volume_penalty_weight=VOLUME_PENALTY_WEIGHT,\n",
    "    perceptual_weight=PERCEPTUAL_WEIGHT,\n",
    "    air_tokens=AIR_TOKENS,\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\nLoss Function:\")\n",
    "print(f\"  Frequency weighting: {USE_FREQUENCY_WEIGHTING} (cap={FREQUENCY_WEIGHT_CAP}x)\")\n",
    "print(f\"  Volume penalty: {VOLUME_PENALTY_WEIGHT}\")\n",
    "print(f\"  Perceptual loss: {PERCEPTUAL_WEIGHT}\")\n",
    "\n",
    "# Create optimizer and scheduler\n",
    "optimizer = optim.AdamW(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    lr=BASE_LR,\n",
    "    weight_decay=1e-4,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=TOTAL_EPOCHS,\n",
    "    eta_min=1e-5\n",
    ")\n",
    "\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP)\n",
    "\n",
    "print(f\"\\nOptimizer: AdamW\")\n",
    "print(f\"  LR: {BASE_LR}\")\n",
    "print(f\"  Weight decay: 1e-4\")\n",
    "print(f\"  Scheduler: CosineAnnealingLR\")\n",
    "print(f\"  Mixed precision: {USE_AMP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(SEED)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    generator=g\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Data loaders created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Compute Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(logits, targets, air_tokens, terrain_tokens, rare_tokens, block_embeddings):\n",
    "    \"\"\"Compute ALL training metrics (complete checklist from CLAUDE.md).\"\"\"\n",
    "    device = logits.device\n",
    "    B, C, X, Y, Z = logits.shape\n",
    "    \n",
    "    logits_flat = logits.permute(0, 2, 3, 4, 1).reshape(-1, C)\n",
    "    targets_flat = targets.view(-1)\n",
    "    \n",
    "    air_dev = air_tokens.to(device)\n",
    "    terrain_dev = terrain_tokens.to(device)\n",
    "    rare_dev = rare_tokens.to(device)\n",
    "    \n",
    "    is_air = torch.isin(targets_flat, air_dev)\n",
    "    is_terrain = torch.isin(targets_flat, terrain_dev) & ~is_air\n",
    "    is_building = ~is_air & ~is_terrain\n",
    "    is_rare = torch.isin(targets_flat, rare_dev)\n",
    "    \n",
    "    preds = logits_flat.argmax(dim=1)\n",
    "    is_air_pred = torch.isin(preds, air_dev)\n",
    "    correct = (preds == targets_flat).float()\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    # === CORE METRICS ===\n",
    "    metrics['overall_acc'] = correct.mean()\n",
    "    metrics['terrain_acc'] = correct[is_terrain].mean() if is_terrain.any() else torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # === BUILDING METRICS ===\n",
    "    if is_building.any():\n",
    "        metrics['building_acc'] = correct[is_building].mean()\n",
    "        metrics['building_recall'] = (is_building & ~is_air_pred).sum().float() / is_building.sum()\n",
    "        metrics['building_false_air'] = (is_building & is_air_pred).sum().float() / is_building.sum()\n",
    "        \n",
    "        # Building precision\n",
    "        pred_building = ~is_air_pred\n",
    "        if pred_building.sum() > 0:\n",
    "            metrics['building_precision'] = (pred_building & is_building & correct).sum().float() / pred_building.sum()\n",
    "        else:\n",
    "            metrics['building_precision'] = torch.tensor(0.0, device=device)\n",
    "        \n",
    "        # Building F1 (NEW)\n",
    "        if metrics['building_precision'] + metrics['building_recall'] > 0:\n",
    "            metrics['building_f1'] = 2 * (metrics['building_precision'] * metrics['building_recall']) / \\\n",
    "                                     (metrics['building_precision'] + metrics['building_recall'])\n",
    "        else:\n",
    "            metrics['building_f1'] = torch.tensor(0.0, device=device)\n",
    "    else:\n",
    "        metrics['building_acc'] = torch.tensor(0.0, device=device)\n",
    "        metrics['building_recall'] = torch.tensor(0.0, device=device)\n",
    "        metrics['building_false_air'] = torch.tensor(0.0, device=device)\n",
    "        metrics['building_precision'] = torch.tensor(0.0, device=device)\n",
    "        metrics['building_f1'] = torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # === AIR METRICS (COMPLETE) ===\n",
    "    if is_air.any():\n",
    "        metrics['air_acc'] = correct[is_air].mean()\n",
    "        \n",
    "        # Air precision (NEW)\n",
    "        if is_air_pred.sum() > 0:\n",
    "            metrics['air_precision'] = (is_air_pred & is_air & correct).sum().float() / is_air_pred.sum()\n",
    "        else:\n",
    "            metrics['air_precision'] = torch.tensor(0.0, device=device)\n",
    "        \n",
    "        # False block rate (NEW) - air incorrectly predicted as building\n",
    "        metrics['false_block_rate'] = (is_air & ~is_air_pred).sum().float() / is_air.sum()\n",
    "    else:\n",
    "        metrics['air_acc'] = torch.tensor(0.0, device=device)\n",
    "        metrics['air_precision'] = torch.tensor(0.0, device=device)\n",
    "        metrics['false_block_rate'] = torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # === RARE BLOCK METRICS ===\n",
    "    if is_rare.any():\n",
    "        metrics['rare_acc'] = correct[is_rare].mean()\n",
    "        metrics['rare_recall'] = (is_rare & ~is_air_pred).sum().float() / is_rare.sum()\n",
    "        \n",
    "        # Rare precision (NEW)\n",
    "        pred_rare = torch.isin(preds, rare_dev)\n",
    "        if pred_rare.sum() > 0:\n",
    "            metrics['rare_precision'] = (pred_rare & is_rare & correct).sum().float() / pred_rare.sum()\n",
    "        else:\n",
    "            metrics['rare_precision'] = torch.tensor(0.0, device=device)\n",
    "    else:\n",
    "        metrics['rare_acc'] = torch.tensor(0.0, device=device)\n",
    "        metrics['rare_recall'] = torch.tensor(0.0, device=device)\n",
    "        metrics['rare_precision'] = torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # === STRUCTURE RECALL ===\n",
    "    is_struct = ~is_air\n",
    "    metrics['struct_recall'] = (is_struct & ~is_air_pred).sum().float() / is_struct.sum() if is_struct.any() else torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # === VOLUME METRICS ===\n",
    "    # Building volume ratio\n",
    "    pred_building = ~is_air_pred\n",
    "    orig_vol = is_struct.sum().float()\n",
    "    pred_vol = pred_building.sum().float()\n",
    "    metrics['vol_ratio'] = pred_vol / orig_vol if orig_vol > 0 else torch.tensor(1.0, device=device)\n",
    "    \n",
    "    # Air ratio (NEW)\n",
    "    orig_air_vol = is_air.sum().float()\n",
    "    pred_air_vol = is_air_pred.sum().float()\n",
    "    metrics['air_ratio'] = pred_air_vol / orig_air_vol if orig_air_vol > 0 else torch.tensor(1.0, device=device)\n",
    "    \n",
    "    # === ERROR SIMILARITY (CRITICAL FOR v9 ANALYSIS) ===\n",
    "    wrong_mask = preds != targets_flat\n",
    "    \n",
    "    # Overall error similarity\n",
    "    if wrong_mask.any():\n",
    "        pred_emb = block_embeddings[preds[wrong_mask]]\n",
    "        gt_emb = block_embeddings[targets_flat[wrong_mask]]\n",
    "        metrics['error_similarity'] = F.cosine_similarity(pred_emb, gt_emb, dim=-1).mean()\n",
    "    else:\n",
    "        metrics['error_similarity'] = torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # Terrain error similarity (NEW)\n",
    "    terrain_wrong = is_terrain & wrong_mask\n",
    "    if terrain_wrong.any():\n",
    "        pred_emb = block_embeddings[preds[terrain_wrong]]\n",
    "        gt_emb = block_embeddings[targets_flat[terrain_wrong]]\n",
    "        metrics['terrain_error_similarity'] = F.cosine_similarity(pred_emb, gt_emb, dim=-1).mean()\n",
    "    else:\n",
    "        metrics['terrain_error_similarity'] = torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # Building error similarity (NEW)\n",
    "    building_wrong = is_building & wrong_mask\n",
    "    if building_wrong.any():\n",
    "        pred_emb = block_embeddings[preds[building_wrong]]\n",
    "        gt_emb = block_embeddings[targets_flat[building_wrong]]\n",
    "        metrics['building_error_similarity'] = F.cosine_similarity(pred_emb, gt_emb, dim=-1).mean()\n",
    "    else:\n",
    "        metrics['building_error_similarity'] = torch.tensor(0.0, device=device)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"Metrics computation function defined (COMPLETE - all metrics from CLAUDE.md)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, criterion, loader, optimizer, scaler, device, air_tokens, terrain_tokens, rare_tokens, block_embeddings):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    model.quantizer.reset_usage()\n",
    "    \n",
    "    metrics_sum = {\n",
    "        'loss': 0.0, 'ce_loss': 0.0, 'volume_loss': 0.0, 'perceptual_loss': 0.0,\n",
    "        'overall_acc': 0.0, 'terrain_acc': 0.0, 'building_acc': 0.0,\n",
    "        'building_recall': 0.0, 'building_false_air': 0.0, 'building_precision': 0.0,\n",
    "        'building_f1': 0.0,  # NEW\n",
    "        'struct_recall': 0.0, 'vol_ratio': 0.0, 'air_ratio': 0.0,  # air_ratio NEW\n",
    "        'air_acc': 0.0, 'air_precision': 0.0, 'false_block_rate': 0.0,  # air_precision, false_block_rate NEW\n",
    "        'rare_acc': 0.0, 'rare_recall': 0.0, 'rare_precision': 0.0,  # rare_precision NEW\n",
    "        'error_similarity': 0.0, 'terrain_error_similarity': 0.0, 'building_error_similarity': 0.0,  # NEW\n",
    "    }\n",
    "    grad_norms = []\n",
    "    all_residual_norms = []  # NEW: Track residual norms\n",
    "    n = 0\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(tqdm(loader, desc=\"Train\", leave=False)):\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        with torch.amp.autocast('cuda', enabled=USE_AMP):\n",
    "            logits, z_q, indices = model(batch)\n",
    "            loss_dict = criterion(logits, batch, z_q)\n",
    "            loss = loss_dict['loss'] / GRAD_ACCUM_STEPS\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # Track residual norms every 100 batches\n",
    "        if batch_idx % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                # Re-encode to get residual norms\n",
    "                z_e = model.encode(batch)\n",
    "                residual = z_e\n",
    "                norms = []\n",
    "                for stage in model.quantizer.stages:\n",
    "                    norms.append(residual.norm().item())\n",
    "                    z_norm = stage.layernorm(residual)\n",
    "                    z_q_norm, _ = stage.fsq(z_norm)\n",
    "                    z_q_stage = stage.layernorm.inverse(z_q_norm)\n",
    "                    residual = residual - z_q_stage\n",
    "                norms.append(residual.norm().item())  # Final residual\n",
    "                all_residual_norms.append(norms)\n",
    "        \n",
    "        if (batch_idx + 1) % GRAD_ACCUM_STEPS == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            grad_norms.append(grad_norm.item())\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Accumulate loss components\n",
    "        with torch.no_grad():\n",
    "            metrics_sum['loss'] += loss_dict['loss'].item()\n",
    "            metrics_sum['ce_loss'] += loss_dict['ce_loss'].item()\n",
    "            metrics_sum['volume_loss'] += loss_dict['volume_loss'].item()\n",
    "            metrics_sum['perceptual_loss'] += loss_dict['perceptual_loss'].item()\n",
    "            metrics_sum['vol_ratio'] += loss_dict['volume_ratio'].item()\n",
    "            \n",
    "            # Compute batch metrics (with embeddings for error similarity)\n",
    "            batch_metrics = compute_metrics(logits, batch, air_tokens, terrain_tokens, rare_tokens, block_embeddings)\n",
    "            for k, v in batch_metrics.items():\n",
    "                metrics_sum[k] += v.item()\n",
    "        \n",
    "        n += 1\n",
    "    \n",
    "    # Average all metrics\n",
    "    metrics = {k: v / n for k, v in metrics_sum.items()}\n",
    "    \n",
    "    # Add RFSQ stats\n",
    "    stage_stats = model.quantizer.get_usage_stats()\n",
    "    for stage_name, (usage, perp) in stage_stats.items():\n",
    "        metrics[f'{stage_name}_usage'] = usage\n",
    "        metrics[f'{stage_name}_perplexity'] = perp\n",
    "    \n",
    "    metrics['grad_norm'] = sum(grad_norms) / len(grad_norms) if grad_norms else 0.0\n",
    "    \n",
    "    # Residual decay (NEW - CRITICAL RFSQ DIAGNOSTIC)\n",
    "    if all_residual_norms:\n",
    "        avg_norms = [sum(x) / len(all_residual_norms) for x in zip(*all_residual_norms)]\n",
    "        metrics['residual_decay'] = avg_norms[-1] / avg_norms[0] if avg_norms[0] > 0 else 1.0\n",
    "    else:\n",
    "        metrics['residual_decay'] = 1.0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, criterion, loader, device, air_tokens, terrain_tokens, rare_tokens, block_embeddings):\n",
    "    \"\"\"Validate on validation set.\"\"\"\n",
    "    model.eval()\n",
    "    model.quantizer.reset_usage()\n",
    "    \n",
    "    metrics_sum = {\n",
    "        'loss': 0.0, 'ce_loss': 0.0, 'volume_loss': 0.0, 'perceptual_loss': 0.0,\n",
    "        'overall_acc': 0.0, 'terrain_acc': 0.0, 'building_acc': 0.0,\n",
    "        'building_recall': 0.0, 'building_false_air': 0.0, 'building_precision': 0.0,\n",
    "        'building_f1': 0.0,\n",
    "        'struct_recall': 0.0, 'vol_ratio': 0.0, 'air_ratio': 0.0,\n",
    "        'air_acc': 0.0, 'air_precision': 0.0, 'false_block_rate': 0.0,\n",
    "        'rare_acc': 0.0, 'rare_recall': 0.0, 'rare_precision': 0.0,\n",
    "        'error_similarity': 0.0, 'terrain_error_similarity': 0.0, 'building_error_similarity': 0.0,\n",
    "    }\n",
    "    all_residual_norms = []\n",
    "    n = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(tqdm(loader, desc=\"Val\", leave=False)):\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        with torch.amp.autocast('cuda', enabled=USE_AMP):\n",
    "            logits, z_q, indices = model(batch)\n",
    "            loss_dict = criterion(logits, batch, z_q)\n",
    "        \n",
    "        # Track residual norms every 50 batches\n",
    "        if batch_idx % 50 == 0:\n",
    "            z_e = model.encode(batch)\n",
    "            residual = z_e\n",
    "            norms = []\n",
    "            for stage in model.quantizer.stages:\n",
    "                norms.append(residual.norm().item())\n",
    "                z_norm = stage.layernorm(residual)\n",
    "                z_q_norm, _ = stage.fsq(z_norm)\n",
    "                z_q_stage = stage.layernorm.inverse(z_q_norm)\n",
    "                residual = residual - z_q_stage\n",
    "            norms.append(residual.norm().item())\n",
    "            all_residual_norms.append(norms)\n",
    "        \n",
    "        metrics_sum['loss'] += loss_dict['loss'].item()\n",
    "        metrics_sum['ce_loss'] += loss_dict['ce_loss'].item()\n",
    "        metrics_sum['volume_loss'] += loss_dict['volume_loss'].item()\n",
    "        metrics_sum['perceptual_loss'] += loss_dict['perceptual_loss'].item()\n",
    "        metrics_sum['vol_ratio'] += loss_dict['volume_ratio'].item()\n",
    "        \n",
    "        batch_metrics = compute_metrics(logits, batch, air_tokens, terrain_tokens, rare_tokens, block_embeddings)\n",
    "        for k, v in batch_metrics.items():\n",
    "            metrics_sum[k] += v.item()\n",
    "        \n",
    "        n += 1\n",
    "    \n",
    "    metrics = {k: v / n for k, v in metrics_sum.items()}\n",
    "    \n",
    "    stage_stats = model.quantizer.get_usage_stats()\n",
    "    for stage_name, (usage, perp) in stage_stats.items():\n",
    "        metrics[f'{stage_name}_usage'] = usage\n",
    "        metrics[f'{stage_name}_perplexity'] = perp\n",
    "    \n",
    "    # Residual decay\n",
    "    if all_residual_norms:\n",
    "        avg_norms = [sum(x) / len(all_residual_norms) for x in zip(*all_residual_norms)]\n",
    "        metrics['residual_decay'] = avg_norms[-1] / avg_norms[0] if avg_norms[0] > 0 else 1.0\n",
    "    else:\n",
    "        metrics['residual_decay'] = 1.0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"Training functions defined (with ALL metrics)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"VQ-VAE V8-B TRAINING - 16×16×16 LATENT RESOLUTION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Key improvements over v6-freq:\")\n",
    "print(f\"  - 8x more spatial positions (4,096 vs 512)\")\n",
    "print(f\"  - 8:1 compression ratio (vs 64:1)\")\n",
    "print(f\"  - Volume penalty (fixes 1.68x over-prediction)\")\n",
    "print(f\"  - Perceptual loss (spatial smoothness)\")\n",
    "print(f\"\\nNEW METRICS TRACKED:\")\n",
    "print(f\"  - building_f1, air_precision, air_ratio\")\n",
    "print(f\"  - false_block_rate, rare_precision\")\n",
    "print(f\"  - error_similarity (overall + terrain + building)\")\n",
    "print(f\"  - residual_decay (RFSQ diagnostic)\")\n",
    "print()\n",
    "\n",
    "# Get block embeddings for error similarity computation\n",
    "block_embeddings_tensor = model.block_emb.weight.data.to(device)\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'train_ce_loss': [], 'train_volume_loss': [], 'train_perceptual_loss': [],\n",
    "    'train_building_acc': [], 'train_building_recall': [], 'train_building_precision': [], 'train_building_f1': [],\n",
    "    'train_terrain_acc': [], 'train_struct_recall': [],\n",
    "    'train_air_acc': [], 'train_air_precision': [], 'train_air_ratio': [], 'train_false_block_rate': [],\n",
    "    'train_volume_ratio': [],\n",
    "    'train_rare_acc': [], 'train_rare_recall': [], 'train_rare_precision': [],\n",
    "    'train_error_similarity': [], 'train_terrain_error_similarity': [], 'train_building_error_similarity': [],\n",
    "    'val_loss': [], 'val_ce_loss': [], 'val_volume_loss': [], 'val_perceptual_loss': [],\n",
    "    'val_building_acc': [], 'val_building_recall': [], 'val_building_precision': [], 'val_building_f1': [],\n",
    "    'val_terrain_acc': [], 'val_struct_recall': [],\n",
    "    'val_air_acc': [], 'val_air_precision': [], 'val_air_ratio': [], 'val_false_block_rate': [],\n",
    "    'val_volume_ratio': [],\n",
    "    'val_rare_acc': [], 'val_rare_recall': [], 'val_rare_precision': [],\n",
    "    'val_error_similarity': [], 'val_terrain_error_similarity': [], 'val_building_error_similarity': [],\n",
    "    'train_stage0_usage': [], 'train_stage0_perplexity': [],\n",
    "    'train_stage1_usage': [], 'train_stage1_perplexity': [],\n",
    "    'val_stage0_usage': [], 'val_stage0_perplexity': [],\n",
    "    'val_stage1_usage': [], 'val_stage1_perplexity': [],\n",
    "    'train_grad_norm': [], 'train_residual_decay': [], 'val_residual_decay': [],\n",
    "    'learning_rate': [],\n",
    "}\n",
    "\n",
    "best_building_acc = 0\n",
    "best_epoch = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(TOTAL_EPOCHS):\n",
    "    train_m = train_epoch(model, criterion, train_loader, optimizer, scaler, device,\n",
    "                          AIR_TOKENS_TENSOR, TERRAIN_TOKENS_TENSOR, RARE_BLOCK_TOKENS_TENSOR, block_embeddings_tensor)\n",
    "    val_m = validate(model, criterion, val_loader, device,\n",
    "                     AIR_TOKENS_TENSOR, TERRAIN_TOKENS_TENSOR, RARE_BLOCK_TOKENS_TENSOR, block_embeddings_tensor)\n",
    "    \n",
    "    # Step scheduler\n",
    "    scheduler.step()\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    \n",
    "    # Record all metrics\n",
    "    for key in history:\n",
    "        if key.startswith('train_'):\n",
    "            metric_name = key[6:]\n",
    "            history[key].append(train_m.get(metric_name, 0))\n",
    "        elif key.startswith('val_'):\n",
    "            metric_name = key[4:]\n",
    "            history[key].append(val_m.get(metric_name, 0))\n",
    "        elif key == 'learning_rate':\n",
    "            history[key].append(current_lr)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_m['building_acc'] > best_building_acc:\n",
    "        best_building_acc = val_m['building_acc']\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_building_acc': best_building_acc,\n",
    "        }, f\"{OUTPUT_DIR}/vqvae_v8b_best.pt\")\n",
    "    \n",
    "    # Save checkpoint every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v8b_epoch{epoch+1}.pt\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:2d} | \"\n",
    "          f\"Build: {train_m['building_acc']:.1%}/{val_m['building_acc']:.1%} | \"\n",
    "          f\"Vol: {val_m['vol_ratio']:.2f}x | \"\n",
    "          f\"ErrSim: {val_m['error_similarity']:.2f} | \"\n",
    "          f\"Decay: {val_m['residual_decay']:.2f} | \"\n",
    "          f\"LR: {current_lr:.2e}\")\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "print(f\"\\nTraining complete in {train_time/60:.1f} minutes\")\n",
    "print(f\"Best val building accuracy: {best_building_acc:.1%} at epoch {best_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 4, figsize=(24, 20))\n",
    "epochs = range(1, TOTAL_EPOCHS + 1)\n",
    "\n",
    "# === ROW 1: Core Building Metrics ===\n",
    "ax = axes[0, 0]\n",
    "ax.plot(epochs, history['train_building_acc'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_building_acc'], 'r--', label='Val')\n",
    "ax.axhline(y=0.492, color='g', linestyle=':', alpha=0.5, label='v6-freq (49.2%)')\n",
    "ax.axhline(y=0.60, color='orange', linestyle='--', alpha=0.5, label='Target (60%)')\n",
    "ax.set_title('Building Accuracy', fontweight='bold')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[0, 1]\n",
    "ax.plot(epochs, history['train_building_f1'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_building_f1'], 'r--', label='Val')\n",
    "ax.set_title('Building F1 Score (NEW)', fontweight='bold', color='blue')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[0, 2]\n",
    "ax.plot(epochs, history['train_building_precision'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_building_precision'], 'r--', label='Val')\n",
    "ax.set_title('Building Precision', fontweight='bold')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[0, 3]\n",
    "ax.plot(epochs, history['train_building_recall'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_building_recall'], 'r--', label='Val')\n",
    "ax.set_title('Building Recall')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# === ROW 2: Volume & Air Metrics ===\n",
    "ax = axes[1, 0]\n",
    "ax.plot(epochs, history['train_volume_ratio'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_volume_ratio'], 'r--', label='Val')\n",
    "ax.axhline(y=1.0, color='g', linestyle='--', alpha=0.5, label='Target (1.0x)')\n",
    "ax.axhline(y=1.68, color='orange', linestyle=':', alpha=0.5, label='v6-freq (1.68x)')\n",
    "ax.set_title('Volume Ratio (Building)', fontweight='bold', color='red')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[1, 1]\n",
    "ax.plot(epochs, history['train_air_ratio'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_air_ratio'], 'r--', label='Val')\n",
    "ax.axhline(y=1.0, color='g', linestyle='--', alpha=0.5, label='Target (1.0x)')\n",
    "ax.set_title('Air Ratio (NEW)', fontweight='bold', color='blue')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[1, 2]\n",
    "ax.plot(epochs, history['train_air_acc'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_air_acc'], 'r--', label='Val')\n",
    "ax.set_title('Air Accuracy')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[1, 3]\n",
    "ax.plot(epochs, history['train_air_precision'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_air_precision'], 'r--', label='Val')\n",
    "ax.set_title('Air Precision (NEW)', fontweight='bold', color='blue')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# === ROW 3: Error Analysis (CRITICAL FOR v9) ===\n",
    "ax = axes[2, 0]\n",
    "ax.plot(epochs, history['train_error_similarity'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_error_similarity'], 'r--', label='Val')\n",
    "ax.axhline(y=0.3, color='orange', linestyle='--', alpha=0.5, label='Random (0.3)')\n",
    "ax.axhline(y=0.5, color='g', linestyle=':', alpha=0.5, label='Systematic (0.5)')\n",
    "ax.set_title('Error Similarity (CRITICAL)', fontweight='bold', color='red')\n",
    "ax.text(0.5, 0.95, 'Low=random errors\\nHigh=similar blocks', transform=ax.transAxes,\n",
    "        ha='center', va='top', fontsize=8, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[2, 1]\n",
    "ax.plot(epochs, history['train_terrain_error_similarity'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_terrain_error_similarity'], 'r--', label='Val')\n",
    "ax.axhline(y=0.3, color='orange', linestyle='--', alpha=0.5)\n",
    "ax.set_title('Terrain Error Similarity (NEW)', fontweight='bold', color='blue')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[2, 2]\n",
    "ax.plot(epochs, history['train_building_error_similarity'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_building_error_similarity'], 'r--', label='Val')\n",
    "ax.axhline(y=0.3, color='orange', linestyle='--', alpha=0.5)\n",
    "ax.set_title('Building Error Similarity (NEW)', fontweight='bold', color='blue')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[2, 3]\n",
    "ax.plot(epochs, history['train_false_block_rate'], 'b-', label='Train (air→block)')\n",
    "ax.plot(epochs, history['val_false_block_rate'], 'r--', label='Val (air→block)')\n",
    "ax.plot(epochs, history['train_building_false_air'], 'g-', label='Train (block→air)')\n",
    "ax.plot(epochs, history['val_building_false_air'], 'orange', linestyle='--', label='Val (block→air)')\n",
    "ax.set_title('False Prediction Rates', fontweight='bold')\n",
    "ax.legend(fontsize=7); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# === ROW 4: Loss Components & RFSQ ===\n",
    "ax = axes[3, 0]\n",
    "ax.plot(epochs, history['train_ce_loss'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_ce_loss'], 'r--', label='Val')\n",
    "ax.set_title('CE Loss')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[3, 1]\n",
    "ax.plot(epochs, history['train_volume_loss'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_volume_loss'], 'r--', label='Val')\n",
    "ax.set_title('Volume Loss (NEW)')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[3, 2]\n",
    "ax.plot(epochs, history['train_perceptual_loss'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_perceptual_loss'], 'r--', label='Val')\n",
    "ax.set_title('Perceptual Loss (NEW)')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[3, 3]\n",
    "ax.plot(epochs, history['train_residual_decay'], 'b-', label='Train')\n",
    "ax.plot(epochs, history['val_residual_decay'], 'r--', label='Val')\n",
    "ax.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='Target (<0.5)')\n",
    "ax.axhline(y=0.12, color='g', linestyle=':', alpha=0.5, label='v6-freq (0.12)')\n",
    "ax.set_title('Residual Decay (RFSQ)', fontweight='bold', color='red')\n",
    "ax.text(0.5, 0.95, 'LayerNorm working if <0.5', transform=ax.transAxes,\n",
    "        ha='center', va='top', fontsize=8, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# === ROW 5: Comparisons & Summary ===\n",
    "ax = axes[4, 0]\n",
    "ax.plot(epochs, history['train_stage0_perplexity'], 'b-', label='Train S0')\n",
    "ax.plot(epochs, history['val_stage0_perplexity'], 'r--', label='Val S0')\n",
    "ax.set_title('Stage 0 Perplexity')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[4, 1]\n",
    "ax.plot(epochs, history['train_stage1_perplexity'], 'b-', label='Train S1')\n",
    "ax.plot(epochs, history['val_stage1_perplexity'], 'r--', label='Val S1')\n",
    "ax.set_title('Stage 1 Perplexity')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# v6-freq comparison\n",
    "ax = axes[4, 2]\n",
    "v6_freq = {'Build\\nAcc': 0.492, 'Vol\\nRatio': 1.68, 'Err\\nSim': 0.31, 'Decay': 0.12}\n",
    "v8b = {\n",
    "    'Build\\nAcc': history['val_building_acc'][-1],\n",
    "    'Vol\\nRatio': history['val_volume_ratio'][-1],\n",
    "    'Err\\nSim': history['val_error_similarity'][-1],\n",
    "    'Decay': history['val_residual_decay'][-1],\n",
    "}\n",
    "x = np.arange(len(v6_freq))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, list(v6_freq.values()), width, label='v6-freq', color='gray')\n",
    "ax.bar(x + width/2, list(v8b.values()), width, label='v8-B', color='green')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(v6_freq.keys())\n",
    "ax.set_title('v6-freq vs v8-B', fontweight='bold')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Summary text\n",
    "ax = axes[4, 3]\n",
    "ax.axis('off')\n",
    "target_met = '[OK]' if history['val_building_acc'][-1] >= 0.60 else '[X]'\n",
    "vol_fixed = '[OK]' if history['val_volume_ratio'][-1] <= 1.3 else '[X]'\n",
    "err_random = '[!]' if history['val_error_similarity'][-1] < 0.3 else '[OK]'\n",
    "rfsq_ok = '[OK]' if history['val_residual_decay'][-1] < 0.5 else '[X]'\n",
    "summary = f'''VQ-VAE v8-B Results\n",
    "──────────────────────\n",
    "Best: {best_building_acc:.1%} (ep {best_epoch})\n",
    "\n",
    "TARGETS:\n",
    "{target_met} Build ≥60%: {history['val_building_acc'][-1]:.1%}\n",
    "{vol_fixed} Vol ≤1.3x: {history['val_volume_ratio'][-1]:.2f}x\n",
    "\n",
    "DIAGNOSTICS:\n",
    "{err_random} Err Sim: {history['val_error_similarity'][-1]:.2f}\n",
    "  (<0.3 = random errors)\n",
    "{rfsq_ok} Decay: {history['val_residual_decay'][-1]:.2f}\n",
    "  (<0.5 = RFSQ working)\n",
    "\n",
    "NEW METRICS:\n",
    "  F1: {history['val_building_f1'][-1]:.1%}\n",
    "  Air Prec: {history['val_air_precision'][-1]:.1%}\n",
    "  Rare Prec: {history['val_rare_precision'][-1]:.1%}\n",
    "\n",
    "Time: {train_time/60:.0f} min'''\n",
    "ax.text(0.1, 0.9, summary, transform=ax.transAxes, fontsize=10,\n",
    "        verticalalignment='top', fontfamily='monospace')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/vqvae_v8b_training.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPREHENSIVE RESULTS ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nCORE METRICS:\")\n",
    "print(f\"  Building accuracy: {history['val_building_acc'][-1]:.1%} (target: ≥60%)\")\n",
    "print(f\"  Building F1: {history['val_building_f1'][-1]:.1%}\")\n",
    "print(f\"  Building precision: {history['val_building_precision'][-1]:.1%}\")\n",
    "print(f\"  Building recall: {history['val_building_recall'][-1]:.1%}\")\n",
    "print(f\"\\nVOLUME METRICS:\")\n",
    "print(f\"  Volume ratio: {history['val_volume_ratio'][-1]:.2f}x (target: ≤1.3x)\")\n",
    "print(f\"  Air ratio: {history['val_air_ratio'][-1]:.2f}x\")\n",
    "print(f\"\\nAIR METRICS:\")\n",
    "print(f\"  Air accuracy: {history['val_air_acc'][-1]:.1%}\")\n",
    "print(f\"  Air precision: {history['val_air_precision'][-1]:.1%}\")\n",
    "print(f\"  False block rate: {history['val_false_block_rate'][-1]:.1%}\")\n",
    "print(f\"  False air rate: {history['val_building_false_air'][-1]:.1%}\")\n",
    "print(f\"\\nERROR ANALYSIS (CRITICAL FOR v9):\")\n",
    "print(f\"  Overall error similarity: {history['val_error_similarity'][-1]:.3f}\")\n",
    "if history['val_error_similarity'][-1] < 0.3:\n",
    "    print(f\"    -> RANDOM errors (like v5.1) - architecture needs fundamental change for v9\")\n",
    "elif history['val_error_similarity'][-1] < 0.5:\n",
    "    print(f\"    -> Moderately systematic - v9 could improve with better loss weights\")\n",
    "else:\n",
    "    print(f\"    -> Systematic errors - v9 can use material similarity loss\")\n",
    "print(f\"  Terrain error similarity: {history['val_terrain_error_similarity'][-1]:.3f}\")\n",
    "print(f\"  Building error similarity: {history['val_building_error_similarity'][-1]:.3f}\")\n",
    "print(f\"\\nRFSQ DIAGNOSTICS:\")\n",
    "print(f\"  Residual decay: {history['val_residual_decay'][-1]:.3f} (v6-freq: 0.12)\")\n",
    "if history['val_residual_decay'][-1] > 0.5:\n",
    "    print(f\"    -> WARNING: LayerNorm may not be working correctly!\")\n",
    "else:\n",
    "    print(f\"    -> RFSQ working correctly\")\n",
    "print(f\"  Stage 0 perplexity: {history['val_stage0_perplexity'][-1]:.0f}\")\n",
    "print(f\"  Stage 1 perplexity: {history['val_stage1_perplexity'][-1]:.0f}\")\n",
    "print(f\"\\nRARE BLOCKS:\")\n",
    "print(f\"  Rare accuracy: {history['val_rare_acc'][-1]:.1%}\")\n",
    "print(f\"  Rare recall: {history['val_rare_recall'][-1]:.1%}\")\n",
    "print(f\"  Rare precision: {history['val_rare_precision'][-1]:.1%}\")\n",
    "print()\n",
    "if history['val_building_acc'][-1] >= 0.60 and history['val_volume_ratio'][-1] <= 1.3:\n",
    "    print(\"[SUCCESS] Stage 1 targets met! Ready for Stage 2 (v8-C with attention)\")\n",
    "elif history['val_building_acc'][-1] >= 0.55:\n",
    "    print(\"[PARTIAL] Close to target, consider Stage 2 with caution\")\n",
    "else:\n",
    "    print(\"[BELOW TARGET] Analyze error patterns before Stage 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 13: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'config': {\n",
    "        'version': 'v8-B',\n",
    "        'changes_from_v6freq': [\n",
    "            '16×16×16 latent (vs 8×8×8)',\n",
    "            '8:1 compression ratio (vs 64:1)',\n",
    "            'Volume penalty loss',\n",
    "            'Perceptual loss',\n",
    "            f'Frequency cap: {FREQUENCY_WEIGHT_CAP}x (reduced from 10x)',\n",
    "            'COMPLETE metrics tracking (all CLAUDE.md requirements)',\n",
    "        ],\n",
    "        'hidden_dim': HIDDEN_DIM,\n",
    "        'rfsq_levels_per_stage': RFSQ_LEVELS_PER_STAGE,\n",
    "        'num_stages': NUM_STAGES,\n",
    "        'total_epochs': TOTAL_EPOCHS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'base_lr': BASE_LR,\n",
    "        'volume_penalty_weight': VOLUME_PENALTY_WEIGHT,\n",
    "        'perceptual_weight': PERCEPTUAL_WEIGHT,\n",
    "        'seed': SEED,\n",
    "    },\n",
    "    'results': {\n",
    "        # Core\n",
    "        'best_building_acc': float(best_building_acc),\n",
    "        'best_epoch': best_epoch,\n",
    "        'final_building_acc': float(history['val_building_acc'][-1]),\n",
    "        'final_building_f1': float(history['val_building_f1'][-1]),\n",
    "        'final_building_precision': float(history['val_building_precision'][-1]),\n",
    "        'final_building_recall': float(history['val_building_recall'][-1]),\n",
    "        'final_terrain_acc': float(history['val_terrain_acc'][-1]),\n",
    "        # Volume\n",
    "        'final_volume_ratio': float(history['val_volume_ratio'][-1]),\n",
    "        'final_air_ratio': float(history['val_air_ratio'][-1]),\n",
    "        # Air\n",
    "        'final_air_acc': float(history['val_air_acc'][-1]),\n",
    "        'final_air_precision': float(history['val_air_precision'][-1]),\n",
    "        'final_false_block_rate': float(history['val_false_block_rate'][-1]),\n",
    "        'final_building_false_air': float(history['val_building_false_air'][-1]),\n",
    "        # Rare\n",
    "        'final_rare_acc': float(history['val_rare_acc'][-1]),\n",
    "        'final_rare_recall': float(history['val_rare_recall'][-1]),\n",
    "        'final_rare_precision': float(history['val_rare_precision'][-1]),\n",
    "        # Error analysis (CRITICAL FOR v9)\n",
    "        'final_error_similarity': float(history['val_error_similarity'][-1]),\n",
    "        'final_terrain_error_similarity': float(history['val_terrain_error_similarity'][-1]),\n",
    "        'final_building_error_similarity': float(history['val_building_error_similarity'][-1]),\n",
    "        'error_type': 'random' if history['val_error_similarity'][-1] < 0.3 else 'systematic',\n",
    "        # RFSQ diagnostics\n",
    "        'final_residual_decay': float(history['val_residual_decay'][-1]),\n",
    "        'rfsq_working': bool(history['val_residual_decay'][-1] < 0.5),\n",
    "        'final_stage0_perplexity': float(history['val_stage0_perplexity'][-1]),\n",
    "        'final_stage1_perplexity': float(history['val_stage1_perplexity'][-1]),\n",
    "        # Meta\n",
    "        'training_time_min': float(train_time / 60),\n",
    "        'target_60pct_met': bool(history['val_building_acc'][-1] >= 0.60),\n",
    "        'volume_target_met': bool(history['val_volume_ratio'][-1] <= 1.3),\n",
    "    },\n",
    "    'history': {k: [float(x) for x in v] for k, v in history.items()},\n",
    "    'v9_recommendations': {\n",
    "        'error_analysis': 'random' if history['val_error_similarity'][-1] < 0.3 else 'systematic',\n",
    "        'rfsq_status': 'working' if history['val_residual_decay'][-1] < 0.5 else 'broken',\n",
    "        'volume_status': 'fixed' if history['val_volume_ratio'][-1] <= 1.3 else 'needs_work',\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/vqvae_v8b_results.json\", 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v8b_final.pt\")\n",
    "\n",
    "print(\"\\nResults saved:\")\n",
    "print(f\"  - {OUTPUT_DIR}/vqvae_v8b_results.json\")\n",
    "print(f\"  - {OUTPUT_DIR}/vqvae_v8b_best.pt\")\n",
    "print(f\"  - {OUTPUT_DIR}/vqvae_v8b_final.pt\")\n",
    "print(f\"  - {OUTPUT_DIR}/vqvae_v8b_training.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY - VQ-VAE v8-B (COMPLETE METRICS)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best building accuracy: {best_building_acc:.1%} at epoch {best_epoch}\")\n",
    "print(f\"Final volume ratio: {history['val_volume_ratio'][-1]:.2f}x\")\n",
    "print(f\"Error similarity: {history['val_error_similarity'][-1]:.3f} ({'random' if history['val_error_similarity'][-1] < 0.3 else 'systematic'})\")\n",
    "print(f\"RFSQ residual decay: {history['val_residual_decay'][-1]:.3f} ({'OK' if history['val_residual_decay'][-1] < 0.5 else 'WARNING'})\")\n",
    "print(f\"Training time: {train_time/60:.1f} minutes\")\n",
    "print()\n",
    "if results['results']['target_60pct_met'] and results['results']['volume_target_met']:\n",
    "    print(\"[SUCCESS] Stage 1 complete: Proceed to Stage 2 (v8-C with attention)\")\n",
    "elif results['results']['target_60pct_met']:\n",
    "    print(\"[PARTIAL] Building acc met, but volume needs work\")\n",
    "elif history['val_building_acc'][-1] >= 0.55:\n",
    "    print(\"[CLOSE] Consider Stage 2 with caution\")\n",
    "else:\n",
    "    print(\"[BELOW TARGET] Analyze error patterns - may need v9 instead of Stage 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}