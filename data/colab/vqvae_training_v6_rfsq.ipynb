{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VQ-VAE v6 Training - Robust Residual FSQ (RFSQ)\n",
        "\n",
        "## Changes from v5.1\n",
        "\n",
        "| Change | v5.1 | v6 |\n",
        "|--------|------|----|\n",
        "| Quantization | Single-stage FSQ (8 dims) | **RFSQ: 2-stage residual FSQ (4 dims)** |\n",
        "| Conditioning | None | **LayerNorm (prevents residual decay)** |\n",
        "| Implicit codes | 390,625 | 390,625 (625 × 625) |\n",
        "| New metrics | error_similarity | **per-stage usage, residual norms** |\n",
        "\n",
        "## Why RFSQ?\n",
        "\n",
        "v5.1 achieved 45.6% building accuracy with random errors (not material confusion).\n",
        "RFSQ offers:\n",
        "1. **Multi-stage residual quantization**: Stage 1 captures coarse structure, Stage 2 refines details\n",
        "2. **LayerNorm conditioning**: Prevents residual magnitude decay across stages\n",
        "3. **Finer granularity**: More effective code usage\n",
        "\n",
        "## Reference\n",
        "- Paper: \"Improving Finite Scalar Quantization via Progressive Training\"\n",
        "- GitHub: https://github.com/zhuxiaoxuhit/robust_rfsq\n",
        "\n",
        "## Goals\n",
        "\n",
        "| Metric | v5.1 Result | v6 Target |\n",
        "|--------|-------------|----------|\n",
        "| Building Accuracy | 45.6% | **>55%** |\n",
        "| Building Recall | 84.7% | >85% |\n",
        "| Rare Block Recall | ~0% | **>20%** |\n",
        "| Stage 1 Usage | N/A | >30% |\n",
        "| Stage 2 Usage | N/A | >30% |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup - Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create output directory\n",
        "import os\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/minecraft_ai/vqvae_v6'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"Output will be saved to: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 1: Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Any, Set\n",
        "from collections import Counter\n",
        "\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if device == \"cuda\":\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2: Configuration\n",
        "\n",
        "**IMPORTANT**: Update the data paths below to match your Google Drive structure!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Data Paths (UPDATE THESE FOR YOUR DRIVE) ===\n",
        "DRIVE_BASE = '/content/drive/MyDrive/minecraft_ai'\n",
        "\n",
        "DATA_DIR = f\"{DRIVE_BASE}/splits/train\"      # Training H5 files\n",
        "VAL_DIR = f\"{DRIVE_BASE}/splits/val\"         # Validation H5 files\n",
        "VOCAB_PATH = f\"{DRIVE_BASE}/vocabulary/tok2block.json\"  # Token to block mapping\n",
        "V3_EMBEDDINGS_PATH = f\"{DRIVE_BASE}/embeddings/block_embeddings_v3.npy\"  # V3 embeddings\n",
        "\n",
        "OUTPUT_DIR = f\"{DRIVE_BASE}/vqvae_v6\"        # Output directory (v6)\n",
        "\n",
        "# === V6 RFSQ Configuration (CHANGED from v5.1) ===\n",
        "HIDDEN_DIMS = [96, 192]  # 2 stages for 32->8 (same as v5.1)\n",
        "RFSQ_LEVELS_PER_STAGE = [5, 5, 5, 5]  # 4 dims × 5 levels = 625 codes per stage\n",
        "NUM_STAGES = 2  # 2 residual stages -> 625 × 625 = 390,625 total codes\n",
        "DROPOUT = 0.1\n",
        "\n",
        "# === Structure weights (unchanged) ===\n",
        "STRUCTURE_WEIGHT = 50.0\n",
        "FALSE_AIR_WEIGHT = 5.0\n",
        "VOLUME_WEIGHT = 2.0\n",
        "STRUCTURE_TO_AIR_WEIGHT = 10.0\n",
        "USE_SHAPE_LOSS = True\n",
        "USE_ASYMMETRIC_LOSS = True\n",
        "\n",
        "# === TERRAIN SETTINGS (unchanged) ===\n",
        "TERRAIN_WEIGHT = 0.2  # Lower weight for terrain blocks\n",
        "BUILDING_WEIGHT = 1.0  # Full weight for building blocks\n",
        "AIR_WEIGHT = 0.1  # Very low weight for air\n",
        "\n",
        "# === Training ===\n",
        "TOTAL_EPOCHS = 25\n",
        "BATCH_SIZE = 4\n",
        "BASE_LR = 3e-4\n",
        "USE_AMP = True\n",
        "GRAD_ACCUM_STEPS = 4\n",
        "\n",
        "SEED = 42\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# Calculate implicit codebook size\n",
        "CODES_PER_STAGE = int(np.prod(RFSQ_LEVELS_PER_STAGE))\n",
        "TOTAL_IMPLICIT_CODES = CODES_PER_STAGE ** NUM_STAGES\n",
        "\n",
        "print(\"VQ-VAE v6 (RFSQ) Configuration:\")\n",
        "print(f\"  Latent grid: 8x8x8\")\n",
        "print(f\"  RFSQ levels per stage: {RFSQ_LEVELS_PER_STAGE}\")\n",
        "print(f\"  Number of stages: {NUM_STAGES}\")\n",
        "print(f\"  Codes per stage: {CODES_PER_STAGE:,}\")\n",
        "print(f\"  Total implicit codes: {TOTAL_IMPLICIT_CODES:,}\")\n",
        "print(f\"  Hidden dims: {HIDDEN_DIMS}\")\n",
        "print(f\"  Epochs: {TOTAL_EPOCHS}\")\n",
        "print(f\"\\nTerrain-Aware Training:\")\n",
        "print(f\"  Terrain weight: {TERRAIN_WEIGHT}\")\n",
        "print(f\"  Building weight: {BUILDING_WEIGHT}\")\n",
        "print(f\"  Air weight: {AIR_WEIGHT}\")\n",
        "print(f\"\\nKEY CHANGE: RFSQ with LayerNorm conditioning!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3: Load Vocabulary and Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(VOCAB_PATH, 'r') as f:\n",
        "    tok2block = {int(k): v for k, v in json.load(f).items()}\n",
        "\n",
        "block2tok = {v: k for k, v in tok2block.items()}\n",
        "VOCAB_SIZE = len(tok2block)\n",
        "print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
        "\n",
        "# Find air tokens\n",
        "AIR_TOKENS: Set[int] = set()\n",
        "for tok, block in tok2block.items():\n",
        "    if 'air' in block.lower() and 'stair' not in block.lower():\n",
        "        AIR_TOKENS.add(tok)\n",
        "        print(f\"  Air token: {tok} = {block}\")\n",
        "\n",
        "AIR_TOKENS_LIST = sorted(AIR_TOKENS)\n",
        "AIR_TOKENS_TENSOR = torch.tensor(AIR_TOKENS_LIST, dtype=torch.long)\n",
        "\n",
        "# Load V3 embeddings\n",
        "v3_embeddings = np.load(V3_EMBEDDINGS_PATH).astype(np.float32)\n",
        "EMBEDDING_DIM = v3_embeddings.shape[1]\n",
        "print(f\"V3 embeddings: {v3_embeddings.shape} (dim={EMBEDDING_DIM})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4: Terrain Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TERRAIN_BLOCKS: Set[str] = {\n",
        "    # Dirt family\n",
        "    'minecraft:dirt', 'minecraft:grass_block', 'minecraft:coarse_dirt',\n",
        "    'minecraft:podzol', 'minecraft:mycelium', 'minecraft:rooted_dirt',\n",
        "    'minecraft:dirt_path', 'minecraft:farmland', 'minecraft:mud',\n",
        "\n",
        "    # Stone family\n",
        "    'minecraft:stone', 'minecraft:cobblestone', 'minecraft:mossy_cobblestone',\n",
        "    'minecraft:bedrock', 'minecraft:deepslate', 'minecraft:tuff',\n",
        "    'minecraft:granite', 'minecraft:diorite', 'minecraft:andesite',\n",
        "\n",
        "    # Sand family\n",
        "    'minecraft:sand', 'minecraft:red_sand', 'minecraft:gravel', 'minecraft:clay',\n",
        "\n",
        "    # Water\n",
        "    'minecraft:water', 'minecraft:lava',\n",
        "\n",
        "    # Terracotta\n",
        "    'minecraft:terracotta', 'minecraft:white_terracotta', 'minecraft:orange_terracotta',\n",
        "    'minecraft:brown_terracotta', 'minecraft:red_terracotta',\n",
        "\n",
        "    # Netherrack\n",
        "    'minecraft:netherrack', 'minecraft:soul_sand', 'minecraft:soul_soil',\n",
        "\n",
        "    # End\n",
        "    'minecraft:end_stone',\n",
        "\n",
        "    # Snow/Ice\n",
        "    'minecraft:snow_block', 'minecraft:ice', 'minecraft:packed_ice',\n",
        "}\n",
        "\n",
        "# Build terrain token set\n",
        "TERRAIN_TOKENS: Set[int] = set()\n",
        "for tok, block in tok2block.items():\n",
        "    base_name = block.split('[')[0] if '[' in block else block\n",
        "    if base_name in TERRAIN_BLOCKS:\n",
        "        TERRAIN_TOKENS.add(tok)\n",
        "\n",
        "TERRAIN_TOKENS_TENSOR = torch.tensor(sorted(TERRAIN_TOKENS), dtype=torch.long)\n",
        "print(f\"Terrain tokens: {len(TERRAIN_TOKENS)}\")\n",
        "\n",
        "def detect_terrain(block_ids: torch.Tensor, device: torch.device) -> torch.Tensor:\n",
        "    \"\"\"Return mask where True = terrain block (excludes air).\"\"\"\n",
        "    terrain_tensor = TERRAIN_TOKENS_TENSOR.to(device)\n",
        "    air_tensor = AIR_TOKENS_TENSOR.to(device)\n",
        "\n",
        "    is_terrain = torch.isin(block_ids, terrain_tensor)\n",
        "    is_air = torch.isin(block_ids, air_tensor)\n",
        "\n",
        "    return is_terrain & ~is_air"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5: Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class VQVAEDataset(Dataset):\n",
        "    def __init__(self, data_dir: str):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.h5_files = sorted(self.data_dir.glob(\"*.h5\"))\n",
        "        if not self.h5_files:\n",
        "            raise ValueError(f\"No H5 files in {data_dir}\")\n",
        "        print(f\"Found {len(self.h5_files)} structures in {data_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.h5_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        with h5py.File(self.h5_files[idx], 'r') as f:\n",
        "            key = list(f.keys())[0]\n",
        "            structure = f[key][:].astype(np.int64)\n",
        "        return torch.from_numpy(structure).long()\n",
        "\n",
        "train_dataset = VQVAEDataset(DATA_DIR)\n",
        "val_dataset = VQVAEDataset(VAL_DIR)\n",
        "\n",
        "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 6: FSQ Base Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FSQ(nn.Module):\n",
        "    \"\"\"\n",
        "    Finite Scalar Quantization - base module used by each RFSQ stage.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, levels: List[int], eps: float = 1e-3):\n",
        "        super().__init__()\n",
        "        self.levels = levels\n",
        "        self.dim = len(levels)\n",
        "        self.eps = eps\n",
        "        self.codebook_size = int(np.prod(levels))\n",
        "\n",
        "        self.register_buffer('_levels', torch.tensor(levels, dtype=torch.float32))\n",
        "\n",
        "        # Precompute for index calculation\n",
        "        basis = []\n",
        "        acc = 1\n",
        "        for L in reversed(levels):\n",
        "            basis.append(acc)\n",
        "            acc *= L\n",
        "        self.register_buffer('_basis', torch.tensor(list(reversed(basis)), dtype=torch.long))\n",
        "\n",
        "        half_levels = [(L - 1) / 2 for L in levels]\n",
        "        self.register_buffer('_half_levels', torch.tensor(half_levels, dtype=torch.float32))\n",
        "\n",
        "        # Track usage for metrics\n",
        "        self.register_buffer('_usage', torch.zeros(self.codebook_size))\n",
        "\n",
        "    def reset_usage(self):\n",
        "        self._usage.zero_()\n",
        "\n",
        "    def get_usage_stats(self) -> Tuple[float, float]:\n",
        "        \"\"\"Return (usage_fraction, perplexity).\"\"\"\n",
        "        usage = (self._usage > 0).float().mean().item()\n",
        "\n",
        "        if self._usage.sum() == 0:\n",
        "            return usage, 0.0\n",
        "\n",
        "        probs = self._usage / self._usage.sum()\n",
        "        probs = probs[probs > 0]\n",
        "        entropy = -(probs * probs.log()).sum()\n",
        "        perplexity = entropy.exp().item()\n",
        "\n",
        "        return usage, perplexity\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Quantize latent vectors.\n",
        "\n",
        "        Args:\n",
        "            z: Shape [..., dim] continuous latent vectors\n",
        "\n",
        "        Returns:\n",
        "            z_q: Quantized vectors, same shape\n",
        "            indices: Integer indices [...], each in [0, codebook_size)\n",
        "        \"\"\"\n",
        "        # Bound to (-1, 1)\n",
        "        z_bounded = torch.tanh(z)\n",
        "\n",
        "        # Quantize each dimension\n",
        "        z_q_list = []\n",
        "        for i in range(self.dim):\n",
        "            L = self._levels[i]\n",
        "            half_L = self._half_levels[i]\n",
        "\n",
        "            z_i = z_bounded[..., i]\n",
        "            z_i = z_i * half_L\n",
        "            z_i = torch.round(z_i)\n",
        "            z_i = torch.clamp(z_i, -half_L, half_L)\n",
        "            z_i = z_i / half_L\n",
        "\n",
        "            z_q_list.append(z_i)\n",
        "\n",
        "        z_q = torch.stack(z_q_list, dim=-1)\n",
        "\n",
        "        # Straight-through estimator\n",
        "        z_q = z_bounded + (z_q - z_bounded).detach()\n",
        "\n",
        "        # Compute indices\n",
        "        indices = torch.zeros(z_q.shape[:-1], dtype=torch.long, device=z_q.device)\n",
        "        for i in range(self.dim):\n",
        "            L = self._levels[i].long()\n",
        "            half_L = self._half_levels[i]\n",
        "            z_i = z_q[..., i]\n",
        "            level_idx = ((z_i * half_L) + half_L).round().long()\n",
        "            level_idx = torch.clamp(level_idx, 0, L - 1)\n",
        "            indices = indices + level_idx * self._basis[i]\n",
        "\n",
        "        # Track usage\n",
        "        with torch.no_grad():\n",
        "            for idx in indices.unique():\n",
        "                if idx < self.codebook_size:\n",
        "                    self._usage[idx] += (indices == idx).sum()\n",
        "\n",
        "        return z_q, indices\n",
        "\n",
        "print(f\"FSQ base module defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 7: RFSQ Module (Robust Residual FSQ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class InvertibleLayerNorm(nn.Module):\n",
        "    \"\"\"\n",
        "    LayerNorm that stores statistics for exact inverse transformation.\n",
        "    \n",
        "    Critical for RFSQ: normalizes before quantization, then inverse-transforms\n",
        "    after to preserve original scale of residuals. Without this, residual\n",
        "    magnitudes decay exponentially across stages.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_features: int, eps: float = 1e-5):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "\n",
        "        # Learnable affine parameters\n",
        "        self.weight = nn.Parameter(torch.ones(num_features))\n",
        "        self.bias = nn.Parameter(torch.zeros(num_features))\n",
        "\n",
        "        # Stored during forward for inverse\n",
        "        self.stored_mean = None\n",
        "        self.stored_std = None\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Normalize input and store statistics for inverse.\n",
        "        \n",
        "        Args:\n",
        "            x: Input tensor [B, X, Y, Z, C] (channels last)\n",
        "        \"\"\"\n",
        "        # Normalize over spatial dims (X, Y, Z)\n",
        "        self.stored_mean = x.mean(dim=(1, 2, 3), keepdim=True)\n",
        "        self.stored_std = x.std(dim=(1, 2, 3), keepdim=True) + self.eps\n",
        "        x_norm = (x - self.stored_mean) / self.stored_std\n",
        "        return x_norm * self.weight + self.bias\n",
        "\n",
        "    def inverse(self, x_norm: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Inverse transform using stored statistics.\"\"\"\n",
        "        if self.stored_mean is None:\n",
        "            raise RuntimeError(\"Must call forward() before inverse()\")\n",
        "        x = (x_norm - self.bias) / self.weight\n",
        "        return x * self.stored_std + self.stored_mean\n",
        "\n",
        "\n",
        "class RFSQStage(nn.Module):\n",
        "    \"\"\"Single stage of Residual FSQ with LayerNorm conditioning.\"\"\"\n",
        "\n",
        "    def __init__(self, levels: List[int]):\n",
        "        super().__init__()\n",
        "        self.levels = levels\n",
        "        self.fsq = FSQ(levels)\n",
        "        self.layernorm = InvertibleLayerNorm(len(levels))\n",
        "\n",
        "    @property\n",
        "    def codebook_size(self) -> int:\n",
        "        return self.fsq.codebook_size\n",
        "\n",
        "    def reset_usage(self):\n",
        "        self.fsq.reset_usage()\n",
        "\n",
        "    def get_usage_stats(self) -> Tuple[float, float]:\n",
        "        return self.fsq.get_usage_stats()\n",
        "\n",
        "    def forward(self, residual: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Quantize residual with LayerNorm conditioning.\n",
        "        \n",
        "        Returns:\n",
        "            z_q: Quantized (in original scale)\n",
        "            new_residual: residual - z_q\n",
        "            indices: FSQ indices\n",
        "        \"\"\"\n",
        "        # 1. Normalize residual\n",
        "        z_norm = self.layernorm(residual)\n",
        "\n",
        "        # 2. Quantize in normalized space\n",
        "        z_q_norm, indices = self.fsq(z_norm)\n",
        "\n",
        "        # 3. Inverse transform back to original scale\n",
        "        z_q = self.layernorm.inverse(z_q_norm)\n",
        "\n",
        "        # 4. Compute new residual\n",
        "        new_residual = residual - z_q\n",
        "\n",
        "        return z_q, new_residual, indices\n",
        "\n",
        "\n",
        "class RFSQ(nn.Module):\n",
        "    \"\"\"Robust Residual FSQ with multiple stages.\"\"\"\n",
        "\n",
        "    def __init__(self, levels_per_stage: List[int], num_stages: int = 2):\n",
        "        super().__init__()\n",
        "        self.levels_per_stage = levels_per_stage\n",
        "        self.num_stages = num_stages\n",
        "        self.dim = len(levels_per_stage)\n",
        "\n",
        "        self.stages = nn.ModuleList([\n",
        "            RFSQStage(levels_per_stage) for _ in range(num_stages)\n",
        "        ])\n",
        "\n",
        "        codes_per_stage = int(np.prod(levels_per_stage))\n",
        "        self.codebook_size = codes_per_stage ** num_stages\n",
        "        self.codes_per_stage = codes_per_stage\n",
        "\n",
        "    def reset_usage(self):\n",
        "        for stage in self.stages:\n",
        "            stage.reset_usage()\n",
        "\n",
        "    def get_usage_stats(self) -> Dict[str, Tuple[float, float]]:\n",
        "        \"\"\"Return per-stage (usage, perplexity).\"\"\"\n",
        "        return {f'stage{i}': stage.get_usage_stats() \n",
        "                for i, stage in enumerate(self.stages)}\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
        "        \"\"\"\n",
        "        Multi-stage residual quantization.\n",
        "        \n",
        "        Args:\n",
        "            z: Encoder output [B, X, Y, Z, C]\n",
        "            \n",
        "        Returns:\n",
        "            z_q: Quantized sum of all stages\n",
        "            all_indices: List of indices from each stage\n",
        "        \"\"\"\n",
        "        residual = z\n",
        "        z_q_sum = torch.zeros_like(z)\n",
        "        all_indices = []\n",
        "\n",
        "        for stage in self.stages:\n",
        "            z_q, residual, indices = stage(residual)\n",
        "            z_q_sum = z_q_sum + z_q\n",
        "            all_indices.append(indices)\n",
        "\n",
        "        return z_q_sum, all_indices\n",
        "\n",
        "    def forward_with_norms(self, z: torch.Tensor) -> Tuple[torch.Tensor, List[torch.Tensor], List[float]]:\n",
        "        \"\"\"Forward that also returns residual norms for monitoring.\"\"\"\n",
        "        residual = z\n",
        "        z_q_sum = torch.zeros_like(z)\n",
        "        all_indices = []\n",
        "        residual_norms = []\n",
        "\n",
        "        for stage in self.stages:\n",
        "            residual_norms.append(residual.norm().item())\n",
        "            z_q, residual, indices = stage(residual)\n",
        "            z_q_sum = z_q_sum + z_q\n",
        "            all_indices.append(indices)\n",
        "\n",
        "        residual_norms.append(residual.norm().item())  # Final residual\n",
        "        return z_q_sum, all_indices, residual_norms\n",
        "\n",
        "\n",
        "print(f\"RFSQ module defined: {NUM_STAGES} stages × {CODES_PER_STAGE:,} codes = {TOTAL_IMPLICIT_CODES:,} total\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 8: VQ-VAE v6 Architecture with RFSQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResidualBlock3D(nn.Module):\n",
        "    def __init__(self, channels: int):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv3d(channels, channels, 3, padding=1)\n",
        "        self.conv2 = nn.Conv3d(channels, channels, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm3d(channels)\n",
        "        self.bn2 = nn.BatchNorm3d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        return F.relu(x + residual)\n",
        "\n",
        "\n",
        "class EncoderV6(nn.Module):\n",
        "    \"\"\"32x32x32 -> 8x8x8 encoder, outputs RFSQ dimension (4 instead of 8).\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels: int, hidden_dims: List[int], rfsq_dim: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        current = in_channels\n",
        "\n",
        "        for h in hidden_dims:\n",
        "            layers.extend([\n",
        "                nn.Conv3d(current, h, 4, stride=2, padding=1),\n",
        "                nn.BatchNorm3d(h),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout3d(dropout),\n",
        "                ResidualBlock3D(h),\n",
        "            ])\n",
        "            current = h\n",
        "\n",
        "        layers.extend([\n",
        "            ResidualBlock3D(current),\n",
        "            ResidualBlock3D(current),\n",
        "            nn.Conv3d(current, rfsq_dim, 3, padding=1),  # Output RFSQ dim\n",
        "        ])\n",
        "\n",
        "        self.encoder = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "\n",
        "class DecoderV6(nn.Module):\n",
        "    \"\"\"8x8x8 -> 32x32x32 decoder, takes RFSQ dimension as input.\"\"\"\n",
        "\n",
        "    def __init__(self, rfsq_dim: int, hidden_dims: List[int], num_blocks: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = [\n",
        "            nn.Conv3d(rfsq_dim, hidden_dims[0], 3, padding=1),\n",
        "            nn.BatchNorm3d(hidden_dims[0]),\n",
        "            nn.ReLU(inplace=True),\n",
        "            ResidualBlock3D(hidden_dims[0]),\n",
        "            ResidualBlock3D(hidden_dims[0]),\n",
        "        ]\n",
        "\n",
        "        current = hidden_dims[0]\n",
        "        for h in hidden_dims[1:]:\n",
        "            layers.extend([\n",
        "                ResidualBlock3D(current),\n",
        "                nn.ConvTranspose3d(current, h, 4, stride=2, padding=1),\n",
        "                nn.BatchNorm3d(h),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout3d(dropout),\n",
        "            ])\n",
        "            current = h\n",
        "\n",
        "        layers.extend([\n",
        "            ResidualBlock3D(current),\n",
        "            nn.ConvTranspose3d(current, current, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm3d(current),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(current, num_blocks, 3, padding=1),\n",
        "        ])\n",
        "\n",
        "        self.decoder = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, z_q):\n",
        "        return self.decoder(z_q)\n",
        "\n",
        "\n",
        "class TerrainWeightedLoss(nn.Module):\n",
        "    \"\"\"Cross-entropy with lower weight for terrain blocks.\"\"\"\n",
        "\n",
        "    def __init__(self, terrain_weight: float = 0.2, building_weight: float = 1.0, air_weight: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.terrain_weight = terrain_weight\n",
        "        self.building_weight = building_weight\n",
        "        self.air_weight = air_weight\n",
        "\n",
        "    def forward(self, logits: torch.Tensor, targets: torch.Tensor,\n",
        "                terrain_mask: torch.Tensor, air_mask: torch.Tensor) -> torch.Tensor:\n",
        "        ce_loss = F.cross_entropy(logits, targets, reduction='none')\n",
        "\n",
        "        weights = torch.full_like(ce_loss, self.building_weight)\n",
        "        weights[terrain_mask] = self.terrain_weight\n",
        "        weights[air_mask] = self.air_weight\n",
        "\n",
        "        return (ce_loss * weights).sum() / weights.sum()\n",
        "\n",
        "\n",
        "class VQVAEv6(nn.Module):\n",
        "    \"\"\"VQ-VAE v6 with Robust Residual FSQ.\"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size: int, emb_dim: int, hidden_dims: List[int],\n",
        "                 rfsq_levels: List[int], num_stages: int, pretrained_emb: np.ndarray,\n",
        "                 terrain_weight: float = 0.2, building_weight: float = 1.0,\n",
        "                 air_weight: float = 0.1, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "        self.rfsq_dim = len(rfsq_levels)\n",
        "        self.num_stages = num_stages\n",
        "\n",
        "        # Embeddings (frozen)\n",
        "        self.block_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.block_emb.weight.data.copy_(torch.from_numpy(pretrained_emb))\n",
        "        self.block_emb.weight.requires_grad = False\n",
        "\n",
        "        # Encoder: 32x32x32 -> 8x8x8 x rfsq_dim\n",
        "        self.encoder = EncoderV6(emb_dim, hidden_dims, self.rfsq_dim, dropout)\n",
        "\n",
        "        # RFSQ: multi-stage residual quantization\n",
        "        self.rfsq = RFSQ(rfsq_levels, num_stages)\n",
        "\n",
        "        # Decoder: 8x8x8 x rfsq_dim -> 32x32x32 x vocab_size\n",
        "        self.decoder = DecoderV6(self.rfsq_dim, list(reversed(hidden_dims)), vocab_size, dropout)\n",
        "\n",
        "        # Loss\n",
        "        self.terrain_loss = TerrainWeightedLoss(terrain_weight, building_weight, air_weight)\n",
        "\n",
        "    def forward(self, block_ids: torch.Tensor, return_norms: bool = False) -> Dict[str, Any]:\n",
        "        # Embed blocks\n",
        "        x = self.block_emb(block_ids)  # [B, X, Y, Z, emb_dim]\n",
        "        x = x.permute(0, 4, 1, 2, 3).contiguous()  # [B, emb_dim, X, Y, Z]\n",
        "\n",
        "        # Encode\n",
        "        z_e = self.encoder(x)  # [B, rfsq_dim, 8, 8, 8]\n",
        "\n",
        "        # Permute for RFSQ: [B, 8, 8, 8, rfsq_dim]\n",
        "        z_e = z_e.permute(0, 2, 3, 4, 1).contiguous()\n",
        "\n",
        "        # Quantize with RFSQ\n",
        "        if return_norms:\n",
        "            z_q, all_indices, residual_norms = self.rfsq.forward_with_norms(z_e)\n",
        "        else:\n",
        "            z_q, all_indices = self.rfsq(z_e)\n",
        "            residual_norms = None\n",
        "\n",
        "        # Permute back: [B, rfsq_dim, 8, 8, 8]\n",
        "        z_q = z_q.permute(0, 4, 1, 2, 3).contiguous()\n",
        "\n",
        "        # Decode\n",
        "        logits = self.decoder(z_q)  # [B, vocab_size, X, Y, Z]\n",
        "\n",
        "        result = {\n",
        "            'logits': logits,\n",
        "            'all_indices': all_indices,\n",
        "            'z_e': z_e,\n",
        "            'z_q': z_q,\n",
        "        }\n",
        "        if residual_norms is not None:\n",
        "            result['residual_norms'] = residual_norms\n",
        "        return result\n",
        "\n",
        "    def compute_loss(self, block_ids: torch.Tensor,\n",
        "                     air_tokens: torch.Tensor,\n",
        "                     terrain_tokens: torch.Tensor,\n",
        "                     structure_weight: float = 50.0,\n",
        "                     return_norms: bool = False) -> Dict[str, Any]:\n",
        "        \"\"\"Compute loss with terrain-aware weighting.\"\"\"\n",
        "\n",
        "        out = self(block_ids, return_norms=return_norms)\n",
        "        logits = out['logits']\n",
        "\n",
        "        # Flatten for loss\n",
        "        B, C, X, Y, Z = logits.shape\n",
        "        logits_flat = logits.permute(0, 2, 3, 4, 1).reshape(-1, C)\n",
        "        targets_flat = block_ids.view(-1)\n",
        "\n",
        "        device = targets_flat.device\n",
        "        air_dev = air_tokens.to(device)\n",
        "        terrain_dev = terrain_tokens.to(device)\n",
        "\n",
        "        # Masks\n",
        "        is_air = torch.isin(targets_flat, air_dev)\n",
        "        is_terrain = torch.isin(targets_flat, terrain_dev) & ~is_air\n",
        "        is_building = ~is_air & ~is_terrain\n",
        "\n",
        "        # Primary loss\n",
        "        loss = self.terrain_loss(logits_flat, targets_flat, is_terrain, is_air)\n",
        "\n",
        "        # Metrics\n",
        "        with torch.no_grad():\n",
        "            preds = logits_flat.argmax(dim=1)\n",
        "            is_air_pred = torch.isin(preds, air_dev)\n",
        "\n",
        "            correct = (preds == targets_flat).float()\n",
        "            overall_acc = correct.mean()\n",
        "\n",
        "            terrain_acc = correct[is_terrain].mean() if is_terrain.any() else torch.tensor(0.0, device=device)\n",
        "\n",
        "            if is_building.any():\n",
        "                building_acc = correct[is_building].mean()\n",
        "                building_preserved = is_building & ~is_air_pred\n",
        "                building_recall = building_preserved.sum().float() / is_building.sum().float()\n",
        "                building_erased = is_building & is_air_pred\n",
        "                building_false_air = building_erased.sum().float() / is_building.sum().float()\n",
        "            else:\n",
        "                building_acc = torch.tensor(0.0, device=device)\n",
        "                building_recall = torch.tensor(0.0, device=device)\n",
        "                building_false_air = torch.tensor(0.0, device=device)\n",
        "\n",
        "            is_struct = ~is_air\n",
        "            if is_struct.any():\n",
        "                struct_acc = correct[is_struct].mean()\n",
        "                struct_preserved = is_struct & ~is_air_pred\n",
        "                struct_recall = struct_preserved.sum().float() / is_struct.sum().float()\n",
        "            else:\n",
        "                struct_acc = torch.tensor(0.0, device=device)\n",
        "                struct_recall = torch.tensor(0.0, device=device)\n",
        "\n",
        "            # Volume ratio\n",
        "            orig_vol = is_struct.sum().float()\n",
        "            pred_vol = (~is_air_pred).sum().float()\n",
        "            vol_ratio = pred_vol / orig_vol if orig_vol > 0 else torch.tensor(1.0, device=device)\n",
        "\n",
        "            # Error similarity\n",
        "            wrong_building = is_building & (preds != targets_flat)\n",
        "            if wrong_building.any():\n",
        "                pred_emb = self.block_emb.weight[preds[wrong_building]]\n",
        "                target_emb = self.block_emb.weight[targets_flat[wrong_building]]\n",
        "                error_similarity = F.cosine_similarity(pred_emb, target_emb, dim=-1).mean()\n",
        "            else:\n",
        "                error_similarity = torch.tensor(0.0, device=device)\n",
        "\n",
        "            wrong_terrain = is_terrain & (preds != targets_flat)\n",
        "            if wrong_terrain.any():\n",
        "                pred_emb_t = self.block_emb.weight[preds[wrong_terrain]]\n",
        "                target_emb_t = self.block_emb.weight[targets_flat[wrong_terrain]]\n",
        "                terrain_error_similarity = F.cosine_similarity(pred_emb_t, target_emb_t, dim=-1).mean()\n",
        "            else:\n",
        "                terrain_error_similarity = torch.tensor(0.0, device=device)\n",
        "\n",
        "        result = {\n",
        "            'loss': loss,\n",
        "            'overall_acc': overall_acc,\n",
        "            'terrain_acc': terrain_acc,\n",
        "            'building_acc': building_acc,\n",
        "            'building_recall': building_recall,\n",
        "            'building_false_air': building_false_air,\n",
        "            'struct_acc': struct_acc,\n",
        "            'struct_recall': struct_recall,\n",
        "            'vol_ratio': vol_ratio,\n",
        "            'error_similarity': error_similarity,\n",
        "            'terrain_error_similarity': terrain_error_similarity,\n",
        "        }\n",
        "        if 'residual_norms' in out:\n",
        "            result['residual_norms'] = out['residual_norms']\n",
        "        return result\n",
        "\n",
        "\n",
        "print(\"VQ-VAE v6 architecture defined!\")\n",
        "print(f\"RFSQ: {NUM_STAGES} stages with LayerNorm conditioning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 9: Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, optimizer, scaler, device,\n",
        "                air_tokens, terrain_tokens, structure_weight):\n",
        "    model.train()\n",
        "    model.rfsq.reset_usage()\n",
        "\n",
        "    metrics = {k: 0.0 for k in [\n",
        "        'loss', 'overall_acc', 'terrain_acc', 'building_acc',\n",
        "        'building_recall', 'building_false_air', 'struct_acc',\n",
        "        'struct_recall', 'vol_ratio', 'error_similarity',\n",
        "        'terrain_error_similarity',\n",
        "    ]}\n",
        "    grad_norms = []\n",
        "    all_residual_norms = []  # Track residual decay\n",
        "    n = 0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for batch_idx, batch in enumerate(tqdm(loader, desc=\"Train\", leave=False)):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        with torch.amp.autocast('cuda', enabled=USE_AMP):\n",
        "            # Get residual norms every 100 batches\n",
        "            return_norms = (batch_idx % 100 == 0)\n",
        "            out = model.compute_loss(batch, air_tokens, terrain_tokens, \n",
        "                                    structure_weight, return_norms=return_norms)\n",
        "            loss = out['loss'] / GRAD_ACCUM_STEPS\n",
        "\n",
        "        if return_norms and 'residual_norms' in out:\n",
        "            all_residual_norms.append(out['residual_norms'])\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (batch_idx + 1) % GRAD_ACCUM_STEPS == 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            grad_norms.append(grad_norm.item())\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        for k in metrics:\n",
        "            if k in out:\n",
        "                metrics[k] += out[k].item() if torch.is_tensor(out[k]) else out[k]\n",
        "        n += 1\n",
        "\n",
        "    # Per-stage RFSQ usage\n",
        "    stage_stats = model.rfsq.get_usage_stats()\n",
        "    for stage_name, (usage, perp) in stage_stats.items():\n",
        "        metrics[f'{stage_name}_usage'] = usage\n",
        "        metrics[f'{stage_name}_perplexity'] = perp\n",
        "\n",
        "    metrics['grad_norm'] = sum(grad_norms) / len(grad_norms) if grad_norms else 0.0\n",
        "\n",
        "    # Compute average residual decay\n",
        "    if all_residual_norms:\n",
        "        avg_norms = np.mean(all_residual_norms, axis=0)\n",
        "        if len(avg_norms) >= 2 and avg_norms[0] > 0:\n",
        "            metrics['residual_decay'] = avg_norms[-1] / avg_norms[0]  # Final/Initial\n",
        "        else:\n",
        "            metrics['residual_decay'] = 1.0\n",
        "    else:\n",
        "        metrics['residual_decay'] = 1.0\n",
        "\n",
        "    return {k: v/n if k not in ['stage0_usage', 'stage0_perplexity', \n",
        "                                 'stage1_usage', 'stage1_perplexity',\n",
        "                                 'grad_norm', 'residual_decay'] else v \n",
        "            for k, v in metrics.items()}\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, loader, device, air_tokens, terrain_tokens, structure_weight):\n",
        "    model.eval()\n",
        "    model.rfsq.reset_usage()\n",
        "\n",
        "    metrics = {k: 0.0 for k in [\n",
        "        'loss', 'overall_acc', 'terrain_acc', 'building_acc',\n",
        "        'building_recall', 'building_false_air', 'struct_acc',\n",
        "        'struct_recall', 'vol_ratio', 'error_similarity',\n",
        "        'terrain_error_similarity',\n",
        "    ]}\n",
        "    all_residual_norms = []\n",
        "    n = 0\n",
        "\n",
        "    for batch_idx, batch in enumerate(tqdm(loader, desc=\"Val\", leave=False)):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        with torch.amp.autocast('cuda', enabled=USE_AMP):\n",
        "            return_norms = (batch_idx % 50 == 0)\n",
        "            out = model.compute_loss(batch, air_tokens, terrain_tokens,\n",
        "                                    structure_weight, return_norms=return_norms)\n",
        "\n",
        "        if return_norms and 'residual_norms' in out:\n",
        "            all_residual_norms.append(out['residual_norms'])\n",
        "\n",
        "        for k in metrics:\n",
        "            if k in out:\n",
        "                metrics[k] += out[k].item() if torch.is_tensor(out[k]) else out[k]\n",
        "        n += 1\n",
        "\n",
        "    stage_stats = model.rfsq.get_usage_stats()\n",
        "    for stage_name, (usage, perp) in stage_stats.items():\n",
        "        metrics[f'{stage_name}_usage'] = usage\n",
        "        metrics[f'{stage_name}_perplexity'] = perp\n",
        "\n",
        "    if all_residual_norms:\n",
        "        avg_norms = np.mean(all_residual_norms, axis=0)\n",
        "        if len(avg_norms) >= 2 and avg_norms[0] > 0:\n",
        "            metrics['residual_decay'] = avg_norms[-1] / avg_norms[0]\n",
        "        else:\n",
        "            metrics['residual_decay'] = 1.0\n",
        "    else:\n",
        "        metrics['residual_decay'] = 1.0\n",
        "\n",
        "    return {k: v/n if k not in ['stage0_usage', 'stage0_perplexity',\n",
        "                                 'stage1_usage', 'stage1_perplexity',\n",
        "                                 'residual_decay'] else v\n",
        "            for k, v in metrics.items()}\n",
        "\n",
        "\n",
        "print(\"Training functions defined!\")\n",
        "print(\"NEW metrics: per-stage usage/perplexity, residual_decay\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 10: Create Model and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Data loaders\n",
        "g = torch.Generator().manual_seed(SEED)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True, generator=g)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                        num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "# Create model\n",
        "model = VQVAEv6(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    emb_dim=EMBEDDING_DIM,\n",
        "    hidden_dims=HIDDEN_DIMS,\n",
        "    rfsq_levels=RFSQ_LEVELS_PER_STAGE,\n",
        "    num_stages=NUM_STAGES,\n",
        "    pretrained_emb=v3_embeddings,\n",
        "    terrain_weight=TERRAIN_WEIGHT,\n",
        "    building_weight=BUILDING_WEIGHT,\n",
        "    air_weight=AIR_WEIGHT,\n",
        "    dropout=DROPOUT,\n",
        ").to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total params: {total_params:,}\")\n",
        "print(f\"Trainable params: {trainable_params:,}\")\n",
        "print(f\"RFSQ stages: {model.num_stages}\")\n",
        "print(f\"RFSQ total codes: {model.rfsq.codebook_size:,}\")\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.AdamW(\n",
        "    [p for p in model.parameters() if p.requires_grad],\n",
        "    lr=BASE_LR,\n",
        "    weight_decay=1e-5\n",
        ")\n",
        "\n",
        "scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP)\n",
        "\n",
        "print(f\"\\nOptimizer: AdamW, LR={BASE_LR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 11: Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"VQ-VAE V6 TRAINING - ROBUST RESIDUAL FSQ (RFSQ)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Key changes from v5.1:\")\n",
        "print(f\"  - RFSQ: {NUM_STAGES}-stage residual quantization\")\n",
        "print(f\"  - LayerNorm conditioning (prevents residual decay)\")\n",
        "print(f\"  - Per-stage metrics tracking\")\n",
        "print()\n",
        "\n",
        "history = {\n",
        "    # Core metrics\n",
        "    'train_loss': [], 'train_building_acc': [], 'train_building_recall': [],\n",
        "    'train_terrain_acc': [], 'train_struct_recall': [],\n",
        "    'val_loss': [], 'val_building_acc': [], 'val_building_recall': [],\n",
        "    'val_terrain_acc': [], 'val_struct_recall': [],\n",
        "    # Per-stage RFSQ metrics\n",
        "    'train_stage0_usage': [], 'train_stage0_perplexity': [],\n",
        "    'train_stage1_usage': [], 'train_stage1_perplexity': [],\n",
        "    'val_stage0_usage': [], 'val_stage0_perplexity': [],\n",
        "    'val_stage1_usage': [], 'val_stage1_perplexity': [],\n",
        "    # Diagnostic metrics\n",
        "    'train_building_false_air': [], 'val_building_false_air': [],\n",
        "    'train_vol_ratio': [], 'val_vol_ratio': [],\n",
        "    'train_error_similarity': [], 'val_error_similarity': [],\n",
        "    'train_terrain_error_similarity': [], 'val_terrain_error_similarity': [],\n",
        "    'train_grad_norm': [],\n",
        "    # NEW: Residual decay tracking\n",
        "    'train_residual_decay': [], 'val_residual_decay': [],\n",
        "}\n",
        "\n",
        "best_building_acc = 0\n",
        "best_epoch = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(TOTAL_EPOCHS):\n",
        "    train_m = train_epoch(model, train_loader, optimizer, scaler, device,\n",
        "                          AIR_TOKENS_TENSOR, TERRAIN_TOKENS_TENSOR, STRUCTURE_WEIGHT)\n",
        "\n",
        "    val_m = validate(model, val_loader, device,\n",
        "                     AIR_TOKENS_TENSOR, TERRAIN_TOKENS_TENSOR, STRUCTURE_WEIGHT)\n",
        "\n",
        "    # Record metrics\n",
        "    history['train_loss'].append(train_m['loss'])\n",
        "    history['train_building_acc'].append(train_m['building_acc'])\n",
        "    history['train_building_recall'].append(train_m['building_recall'])\n",
        "    history['train_terrain_acc'].append(train_m['terrain_acc'])\n",
        "    history['train_struct_recall'].append(train_m['struct_recall'])\n",
        "\n",
        "    history['val_loss'].append(val_m['loss'])\n",
        "    history['val_building_acc'].append(val_m['building_acc'])\n",
        "    history['val_building_recall'].append(val_m['building_recall'])\n",
        "    history['val_terrain_acc'].append(val_m['terrain_acc'])\n",
        "    history['val_struct_recall'].append(val_m['struct_recall'])\n",
        "\n",
        "    # Per-stage metrics\n",
        "    history['train_stage0_usage'].append(train_m.get('stage0_usage', 0))\n",
        "    history['train_stage0_perplexity'].append(train_m.get('stage0_perplexity', 0))\n",
        "    history['train_stage1_usage'].append(train_m.get('stage1_usage', 0))\n",
        "    history['train_stage1_perplexity'].append(train_m.get('stage1_perplexity', 0))\n",
        "\n",
        "    history['val_stage0_usage'].append(val_m.get('stage0_usage', 0))\n",
        "    history['val_stage0_perplexity'].append(val_m.get('stage0_perplexity', 0))\n",
        "    history['val_stage1_usage'].append(val_m.get('stage1_usage', 0))\n",
        "    history['val_stage1_perplexity'].append(val_m.get('stage1_perplexity', 0))\n",
        "\n",
        "    # Diagnostic metrics\n",
        "    history['train_building_false_air'].append(train_m['building_false_air'])\n",
        "    history['val_building_false_air'].append(val_m['building_false_air'])\n",
        "    history['train_vol_ratio'].append(train_m['vol_ratio'])\n",
        "    history['val_vol_ratio'].append(val_m['vol_ratio'])\n",
        "    history['train_error_similarity'].append(train_m['error_similarity'])\n",
        "    history['val_error_similarity'].append(val_m['error_similarity'])\n",
        "    history['train_terrain_error_similarity'].append(train_m['terrain_error_similarity'])\n",
        "    history['val_terrain_error_similarity'].append(val_m['terrain_error_similarity'])\n",
        "    history['train_grad_norm'].append(train_m['grad_norm'])\n",
        "\n",
        "    # Residual decay\n",
        "    history['train_residual_decay'].append(train_m.get('residual_decay', 1.0))\n",
        "    history['val_residual_decay'].append(val_m.get('residual_decay', 1.0))\n",
        "\n",
        "    # Best model\n",
        "    if val_m['building_acc'] > best_building_acc:\n",
        "        best_building_acc = val_m['building_acc']\n",
        "        best_epoch = epoch + 1\n",
        "        torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v6_best.pt\")\n",
        "\n",
        "    # Log\n",
        "    print(f\"Epoch {epoch+1:2d} | \"\n",
        "          f\"Build: {train_m['building_acc']:.1%}/{val_m['building_acc']:.1%} | \"\n",
        "          f\"S0: {val_m.get('stage0_perplexity', 0):.0f} S1: {val_m.get('stage1_perplexity', 0):.0f} | \"\n",
        "          f\"Decay: {val_m.get('residual_decay', 1.0):.2f} | \"\n",
        "          f\"ErrSim: {val_m['error_similarity']:.2f}\")\n",
        "\n",
        "train_time = time.time() - start_time\n",
        "print(f\"\\nTraining complete in {train_time/60:.1f} minutes\")\n",
        "print(f\"Best val building accuracy: {best_building_acc:.1%} at epoch {best_epoch}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 12: Plot Training Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(4, 4, figsize=(20, 16))\n",
        "epochs = range(1, TOTAL_EPOCHS + 1)\n",
        "\n",
        "# Row 1: Core metrics\n",
        "ax = axes[0, 0]\n",
        "ax.plot(epochs, history['train_building_acc'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_building_acc'], 'r--', label='Val')\n",
        "ax.set_title('Building Accuracy (KEY)', fontweight='bold')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[0, 1]\n",
        "ax.plot(epochs, history['train_building_recall'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_building_recall'], 'r--', label='Val')\n",
        "ax.axhline(y=0.85, color='g', linestyle='--', alpha=0.5)\n",
        "ax.set_title('Building Recall')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[0, 2]\n",
        "ax.plot(epochs, history['train_terrain_acc'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_terrain_acc'], 'r--', label='Val')\n",
        "ax.set_title('Terrain Accuracy')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[0, 3]\n",
        "ax.plot(epochs, history['train_struct_recall'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_struct_recall'], 'r--', label='Val')\n",
        "ax.set_title('Structure Recall')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Row 2: Per-stage RFSQ metrics\n",
        "ax = axes[1, 0]\n",
        "ax.plot(epochs, history['train_stage0_perplexity'], 'b-', label='Train S0')\n",
        "ax.plot(epochs, history['val_stage0_perplexity'], 'r--', label='Val S0')\n",
        "ax.set_title('Stage 0 Perplexity', fontweight='bold')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[1, 1]\n",
        "ax.plot(epochs, history['train_stage1_perplexity'], 'b-', label='Train S1')\n",
        "ax.plot(epochs, history['val_stage1_perplexity'], 'r--', label='Val S1')\n",
        "ax.set_title('Stage 1 Perplexity', fontweight='bold')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[1, 2]\n",
        "ax.plot(epochs, history['train_stage0_usage'], 'b-', label='Train S0')\n",
        "ax.plot(epochs, history['val_stage0_usage'], 'r--', label='Val S0')\n",
        "ax.plot(epochs, history['train_stage1_usage'], 'g-', label='Train S1')\n",
        "ax.plot(epochs, history['val_stage1_usage'], 'm--', label='Val S1')\n",
        "ax.axhline(y=0.3, color='orange', linestyle='--', alpha=0.5, label='Target 30%')\n",
        "ax.set_title('Stage Usage')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[1, 3]\n",
        "ax.plot(epochs, history['train_residual_decay'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_residual_decay'], 'r--', label='Val')\n",
        "ax.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='<50% target')\n",
        "ax.set_title('Residual Decay (Final/Initial)', fontweight='bold')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Row 3: Loss and diagnostics\n",
        "ax = axes[2, 0]\n",
        "ax.plot(epochs, history['train_loss'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_loss'], 'r--', label='Val')\n",
        "ax.set_title('Loss')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[2, 1]\n",
        "ax.plot(epochs, history['train_building_false_air'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_building_false_air'], 'r--', label='Val')\n",
        "ax.axhline(y=0.1, color='orange', linestyle='--', alpha=0.5)\n",
        "ax.set_title('Building False Air')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[2, 2]\n",
        "ax.plot(epochs, history['train_vol_ratio'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_vol_ratio'], 'r--', label='Val')\n",
        "ax.axhline(y=1.0, color='g', linestyle='--', alpha=0.5)\n",
        "ax.set_title('Volume Ratio')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[2, 3]\n",
        "ax.plot(epochs, history['train_grad_norm'], 'g-')\n",
        "ax.axhline(y=1.0, color='r', linestyle='--', alpha=0.5)\n",
        "ax.set_title('Gradient Norm')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Row 4: Error similarity and final metrics\n",
        "ax = axes[3, 0]\n",
        "ax.plot(epochs, history['val_error_similarity'], 'b-', label='Building')\n",
        "ax.plot(epochs, history['val_terrain_error_similarity'], 'g-', label='Terrain')\n",
        "ax.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5)\n",
        "ax.set_title('Error Similarity (Val)')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Comparison: v5.1 vs v6\n",
        "ax = axes[3, 1]\n",
        "v51_baseline = {'Build Acc': 0.456, 'Build Recall': 0.847, 'Err Sim': 0.24}\n",
        "v6_final = {\n",
        "    'Build Acc': history['val_building_acc'][-1],\n",
        "    'Build Recall': history['val_building_recall'][-1],\n",
        "    'Err Sim': history['val_error_similarity'][-1],\n",
        "}\n",
        "x = np.arange(len(v51_baseline))\n",
        "width = 0.35\n",
        "ax.bar(x - width/2, list(v51_baseline.values()), width, label='v5.1', color='gray')\n",
        "ax.bar(x + width/2, list(v6_final.values()), width, label='v6 (RFSQ)', color='green')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(v51_baseline.keys())\n",
        "ax.set_title('v5.1 vs v6 Comparison')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Final metrics\n",
        "ax = axes[3, 2]\n",
        "final = {\n",
        "    'Build\\nAcc': history['val_building_acc'][-1],\n",
        "    'Build\\nRecall': history['val_building_recall'][-1],\n",
        "    'S0\\nUsage': history['val_stage0_usage'][-1],\n",
        "    'S1\\nUsage': history['val_stage1_usage'][-1],\n",
        "    'Res\\nDecay': history['val_residual_decay'][-1],\n",
        "}\n",
        "colors = ['green', 'orange', 'blue', 'purple', 'red']\n",
        "bars = ax.bar(final.keys(), final.values(), color=colors)\n",
        "ax.set_title('Final Val Metrics')\n",
        "ax.set_ylim(0, 1)\n",
        "for bar, val in zip(bars, final.values()):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "            f'{val:.2f}', ha='center', fontsize=9)\n",
        "\n",
        "# Summary text\n",
        "ax = axes[3, 3]\n",
        "ax.axis('off')\n",
        "summary = f\"\"\"VQ-VAE v6 (RFSQ) Results\n",
        "─────────────────────────\n",
        "Best Building Acc: {best_building_acc:.1%} (epoch {best_epoch})\n",
        "Final Building Recall: {history['val_building_recall'][-1]:.1%}\n",
        "\n",
        "RFSQ Stage Perplexity:\n",
        "  Stage 0: {history['val_stage0_perplexity'][-1]:.0f}\n",
        "  Stage 1: {history['val_stage1_perplexity'][-1]:.0f}\n",
        "\n",
        "Residual Decay: {history['val_residual_decay'][-1]:.2f}\n",
        "  (<0.5 = LayerNorm working)\n",
        "\n",
        "Error Similarity: {history['val_error_similarity'][-1]:.2f}\n",
        "  (<0.4 = random errors)\n",
        "\n",
        "Training Time: {train_time/60:.1f} min\"\"\"\n",
        "ax.text(0.1, 0.9, summary, transform=ax.transAxes, fontsize=11,\n",
        "        verticalalignment='top', fontfamily='monospace')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUTPUT_DIR}/vqvae_v6_training.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Print analysis\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RFSQ ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nResidual Decay: {history['val_residual_decay'][-1]:.3f}\")\n",
        "if history['val_residual_decay'][-1] < 0.5:\n",
        "    print(\"  GOOD: LayerNorm preventing residual magnitude decay\")\n",
        "else:\n",
        "    print(\"  WARNING: Residual decay too high, LayerNorm may not be effective\")\n",
        "\n",
        "print(f\"\\nStage 0 Perplexity: {history['val_stage0_perplexity'][-1]:.0f}\")\n",
        "print(f\"Stage 1 Perplexity: {history['val_stage1_perplexity'][-1]:.0f}\")\n",
        "if history['val_stage1_perplexity'][-1] > 100:\n",
        "    print(\"  GOOD: Stage 1 capturing meaningful residual information\")\n",
        "else:\n",
        "    print(\"  WARNING: Stage 1 may not be useful (low perplexity)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 13: Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = {\n",
        "    'config': {\n",
        "        'version': 'v6',\n",
        "        'changes_from_v51': [\n",
        "            'RFSQ: 2-stage residual quantization',\n",
        "            'LayerNorm conditioning (prevents residual decay)',\n",
        "            'Per-stage metrics tracking',\n",
        "            'Residual decay monitoring',\n",
        "        ],\n",
        "        'hidden_dims': HIDDEN_DIMS,\n",
        "        'rfsq_levels_per_stage': RFSQ_LEVELS_PER_STAGE,\n",
        "        'num_stages': NUM_STAGES,\n",
        "        'codes_per_stage': CODES_PER_STAGE,\n",
        "        'total_implicit_codes': TOTAL_IMPLICIT_CODES,\n",
        "        'total_epochs': TOTAL_EPOCHS,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'base_lr': BASE_LR,\n",
        "        'terrain_weight': TERRAIN_WEIGHT,\n",
        "        'building_weight': BUILDING_WEIGHT,\n",
        "        'air_weight': AIR_WEIGHT,\n",
        "        'seed': SEED,\n",
        "    },\n",
        "    'results': {\n",
        "        'best_building_acc': float(best_building_acc),\n",
        "        'best_epoch': best_epoch,\n",
        "        'final_building_acc': float(history['val_building_acc'][-1]),\n",
        "        'final_building_recall': float(history['val_building_recall'][-1]),\n",
        "        'final_terrain_acc': float(history['val_terrain_acc'][-1]),\n",
        "        'final_struct_recall': float(history['val_struct_recall'][-1]),\n",
        "        'final_stage0_perplexity': float(history['val_stage0_perplexity'][-1]),\n",
        "        'final_stage1_perplexity': float(history['val_stage1_perplexity'][-1]),\n",
        "        'final_stage0_usage': float(history['val_stage0_usage'][-1]),\n",
        "        'final_stage1_usage': float(history['val_stage1_usage'][-1]),\n",
        "        'final_residual_decay': float(history['val_residual_decay'][-1]),\n",
        "        'final_error_similarity': float(history['val_error_similarity'][-1]),\n",
        "        'final_terrain_error_similarity': float(history['val_terrain_error_similarity'][-1]),\n",
        "        'training_time_min': float(train_time / 60),\n",
        "    },\n",
        "    'history': {k: [float(x) for x in v] for k, v in history.items()},\n",
        "}\n",
        "\n",
        "with open(f\"{OUTPUT_DIR}/vqvae_v6_results.json\", 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "# Save checkpoint\n",
        "checkpoint = {\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'config': {\n",
        "        'version': 'v6',\n",
        "        'vocab_size': VOCAB_SIZE,\n",
        "        'emb_dim': EMBEDDING_DIM,\n",
        "        'hidden_dims': HIDDEN_DIMS,\n",
        "        'rfsq_levels': RFSQ_LEVELS_PER_STAGE,\n",
        "        'num_stages': NUM_STAGES,\n",
        "        'terrain_weight': TERRAIN_WEIGHT,\n",
        "        'building_weight': BUILDING_WEIGHT,\n",
        "        'air_weight': AIR_WEIGHT,\n",
        "        'dropout': DROPOUT,\n",
        "    },\n",
        "    'air_tokens': AIR_TOKENS_LIST,\n",
        "    'terrain_tokens': sorted(TERRAIN_TOKENS),\n",
        "    'best_building_acc': float(best_building_acc),\n",
        "    'best_epoch': best_epoch,\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, f\"{OUTPUT_DIR}/vqvae_v6_best_checkpoint.pt\")\n",
        "torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v6_final.pt\")\n",
        "\n",
        "print(\"\\nResults saved:\")\n",
        "print(f\"  - {OUTPUT_DIR}/vqvae_v6_results.json\")\n",
        "print(f\"  - {OUTPUT_DIR}/vqvae_v6_best_checkpoint.pt\")\n",
        "print(f\"  - {OUTPUT_DIR}/vqvae_v6_final.pt\")\n",
        "print(f\"  - {OUTPUT_DIR}/vqvae_v6_training.png\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL RESULTS - VQ-VAE v6 (RFSQ)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Best building accuracy: {best_building_acc:.1%} at epoch {best_epoch}\")\n",
        "print(f\"Final building recall:  {history['val_building_recall'][-1]:.1%}\")\n",
        "print(f\"\\nRFSQ Perplexity (effective codes per stage):\")\n",
        "print(f\"  Stage 0: {history['val_stage0_perplexity'][-1]:.0f}\")\n",
        "print(f\"  Stage 1: {history['val_stage1_perplexity'][-1]:.0f}\")\n",
        "print(f\"\\nResidual Decay: {history['val_residual_decay'][-1]:.3f}\")\n",
        "print(f\"  (< 0.5 means LayerNorm is preventing decay)\")\n",
        "print(f\"\\nError Similarity: {history['val_error_similarity'][-1]:.3f}\")\n",
        "print(f\"  (< 0.4 = random errors, > 0.7 = material confusion)\")\n",
        "print(f\"\\nTraining time: {train_time/60:.1f} minutes\")\n",
        "\n",
        "# Comparison with v5.1\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPARISON: v5.1 vs v6\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Metric':<25} {'v5.1':>10} {'v6':>10} {'Change':>10}\")\n",
        "print(\"-\" * 55)\n",
        "v51 = {'Building Acc': 0.456, 'Building Recall': 0.847, 'Error Sim': 0.24}\n",
        "v6_res = {\n",
        "    'Building Acc': history['val_building_acc'][-1],\n",
        "    'Building Recall': history['val_building_recall'][-1],\n",
        "    'Error Sim': history['val_error_similarity'][-1],\n",
        "}\n",
        "for k in v51:\n",
        "    change = v6_res[k] - v51[k]\n",
        "    sign = '+' if change > 0 else ''\n",
        "    print(f\"{k:<25} {v51[k]:>10.1%} {v6_res[k]:>10.1%} {sign}{change:>9.1%}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
