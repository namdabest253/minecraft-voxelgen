{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-0"
      },
      "source": [
        "# VQ-VAE v7 Training - U-Net Skip Connections + Volume Penalty\n",
        "\n",
        "## Key Changes from v6-freq\n",
        "\n",
        "| Change | v6-freq | v7 |\n",
        "|--------|---------|-----|\n",
        "| Skip connections | None | **Dual U-Net (16x16x16 + 32x32x32)** |\n",
        "| Volume penalty | None | **MSE loss on vol_ratio** |\n",
        "| Frequency cap | 10x | **5x** |\n",
        "| Epochs | 25 | **40** |\n",
        "| LR schedule | Constant | **Cosine annealing** |\n",
        "| Early stopping | None | **On building_f1** |\n",
        "| Metrics | Missing precision/F1 | **Complete set** |\n",
        "\n",
        "## Goals\n",
        "\n",
        "| Metric | v6-freq | v7 Target |\n",
        "|--------|---------|----------|\n",
        "| Building Accuracy | 49.2% | **55-62%** |\n",
        "| Building Precision | ~58% (est) | **70-80%** |\n",
        "| Building F1 | ~73% (est) | **75-85%** |\n",
        "| Volume Ratio | 1.68x | **1.0-1.15** |\n",
        "| Rare Block Recall | 94.9% | **85-92%** |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-1"
      },
      "source": [
        "## Setup - Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-2"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create output directory\n",
        "import os\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/minecraft_ai/vqvae_v7'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"Output will be saved to: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-3"
      },
      "source": [
        "## Cell 1: Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Any, Set, Optional\n",
        "from collections import Counter\n",
        "\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if device == \"cuda\":\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-5"
      },
      "source": [
        "## Cell 2: Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-6"
      },
      "outputs": [],
      "source": [
        "# === Data Paths (UPDATE THESE FOR YOUR DRIVE) ===\n",
        "DRIVE_BASE = '/content/drive/MyDrive/minecraft_ai'\n",
        "\n",
        "DATA_DIR = f\"{DRIVE_BASE}/splits/train\"\n",
        "VAL_DIR = f\"{DRIVE_BASE}/splits/val\"\n",
        "VOCAB_PATH = f\"{DRIVE_BASE}/vocabulary/tok2block.json\"\n",
        "V3_EMBEDDINGS_PATH = f\"{DRIVE_BASE}/embeddings/block_embeddings_v3.npy\"\n",
        "\n",
        "OUTPUT_DIR = f\"{DRIVE_BASE}/vqvae_v7\"\n",
        "\n",
        "# === V7 Configuration ===\n",
        "VERSION = 'v7'\n",
        "HIDDEN_DIMS = [96, 192]\n",
        "RFSQ_LEVELS_PER_STAGE = [5, 5, 5, 5]\n",
        "NUM_STAGES = 2\n",
        "DROPOUT = 0.1\n",
        "\n",
        "# === FREQUENCY WEIGHTING (REDUCED cap from 10x to 5x) ===\n",
        "USE_FREQUENCY_WEIGHTING = True\n",
        "FREQUENCY_WEIGHT_CAP = 5.0  # Down from 10.0 in v6-freq\n",
        "\n",
        "# === VOLUME PENALTY (NEW in v7) ===\n",
        "VOLUME_PENALTY_WEIGHT = 0.1\n",
        "\n",
        "# === Structure weights ===\n",
        "STRUCTURE_WEIGHT = 50.0\n",
        "\n",
        "# === TERRAIN SETTINGS ===\n",
        "TERRAIN_WEIGHT = 0.2\n",
        "BUILDING_WEIGHT = 1.0\n",
        "AIR_WEIGHT = 0.1\n",
        "\n",
        "# === Training (Extended to 40 epochs) ===\n",
        "TOTAL_EPOCHS = 40\n",
        "BATCH_SIZE = 4\n",
        "BASE_LR = 3e-4\n",
        "MIN_LR = 1e-5  # For cosine annealing\n",
        "USE_AMP = True\n",
        "GRAD_ACCUM_STEPS = 4\n",
        "\n",
        "# === Early stopping (NEW in v7) ===\n",
        "EARLY_STOPPING_PATIENCE = 10\n",
        "EARLY_STOPPING_METRIC = 'building_f1'\n",
        "\n",
        "SEED = 42\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "CODES_PER_STAGE = int(np.prod(RFSQ_LEVELS_PER_STAGE))\n",
        "TOTAL_IMPLICIT_CODES = CODES_PER_STAGE ** NUM_STAGES\n",
        "\n",
        "print(\"VQ-VAE v7 Configuration:\")\n",
        "print(f\"  RFSQ: {NUM_STAGES} stages Ã— {CODES_PER_STAGE:,} codes\")\n",
        "print(f\"  Total implicit codes: {TOTAL_IMPLICIT_CODES:,}\")\n",
        "print(f\"\\nKEY CHANGES:\")\n",
        "print(f\"  Skip connections: Dual U-Net (16x16x16 + 32x32x32)\")\n",
        "print(f\"  Volume penalty weight: {VOLUME_PENALTY_WEIGHT}\")\n",
        "print(f\"  Frequency cap: {FREQUENCY_WEIGHT_CAP}x (down from 10x)\")\n",
        "print(f\"  Epochs: {TOTAL_EPOCHS} (up from 25)\")\n",
        "print(f\"  LR schedule: Cosine annealing ({BASE_LR} -> {MIN_LR})\")\n",
        "print(f\"  Early stopping: patience={EARLY_STOPPING_PATIENCE} on {EARLY_STOPPING_METRIC}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-7"
      },
      "source": [
        "## Cell 3: Load Vocabulary and Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-8"
      },
      "outputs": [],
      "source": [
        "with open(VOCAB_PATH, 'r') as f:\n",
        "    tok2block = {int(k): v for k, v in json.load(f).items()}\n",
        "\n",
        "block2tok = {v: k for k, v in tok2block.items()}\n",
        "VOCAB_SIZE = len(tok2block)\n",
        "print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
        "\n",
        "# Find air tokens\n",
        "AIR_TOKENS: Set[int] = set()\n",
        "for tok, block in tok2block.items():\n",
        "    if 'air' in block.lower() and 'stair' not in block.lower():\n",
        "        AIR_TOKENS.add(tok)\n",
        "        print(f\"  Air token: {tok} = {block}\")\n",
        "\n",
        "AIR_TOKENS_LIST = sorted(AIR_TOKENS)\n",
        "AIR_TOKENS_TENSOR = torch.tensor(AIR_TOKENS_LIST, dtype=torch.long)\n",
        "\n",
        "# Load V3 embeddings\n",
        "v3_embeddings = np.load(V3_EMBEDDINGS_PATH).astype(np.float32)\n",
        "EMBEDDING_DIM = v3_embeddings.shape[1]\n",
        "print(f\"V3 embeddings: {v3_embeddings.shape} (dim={EMBEDDING_DIM})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-9"
      },
      "source": [
        "## Cell 4: Compute Block Frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-10"
      },
      "outputs": [],
      "source": [
        "print(\"Computing block frequencies from training data...\")\n",
        "print(\"(This may take a few minutes)\")\n",
        "\n",
        "block_counts = Counter()\n",
        "train_files = sorted(Path(DATA_DIR).glob(\"*.h5\"))\n",
        "\n",
        "for h5_file in tqdm(train_files, desc=\"Scanning training data\"):\n",
        "    with h5py.File(h5_file, 'r') as f:\n",
        "        key = list(f.keys())[0]\n",
        "        structure = f[key][:].flatten()\n",
        "        block_counts.update(structure.tolist())\n",
        "\n",
        "total_blocks = sum(block_counts.values())\n",
        "print(f\"\\nTotal blocks scanned: {total_blocks:,}\")\n",
        "print(f\"Unique block types: {len(block_counts)}\")\n",
        "\n",
        "# Compute inverse frequency weights (capped at 5x for v7, down from 10x)\n",
        "max_count = max(block_counts.values())\n",
        "frequency_weights = {}\n",
        "for tok in range(VOCAB_SIZE):\n",
        "    count = block_counts.get(tok, 1)\n",
        "    weight = min(FREQUENCY_WEIGHT_CAP, max_count / count)\n",
        "    frequency_weights[tok] = weight\n",
        "\n",
        "FREQUENCY_WEIGHT_TENSOR = torch.tensor(\n",
        "    [frequency_weights[i] for i in range(VOCAB_SIZE)],\n",
        "    dtype=torch.float32\n",
        ")\n",
        "\n",
        "# Show top 10 rarest blocks\n",
        "print(f\"\\nTop 10 RAREST blocks (highest weights, capped at {FREQUENCY_WEIGHT_CAP}x):\")\n",
        "sorted_by_weight = sorted(frequency_weights.items(), key=lambda x: x[1], reverse=True)\n",
        "for tok, weight in sorted_by_weight[:10]:\n",
        "    block_name = tok2block.get(tok, f\"UNKNOWN_{tok}\")\n",
        "    count = block_counts.get(tok, 0)\n",
        "    print(f\"  {block_name}: weight={weight:.1f}x (count={count:,})\")\n",
        "\n",
        "# Identify rare block categories\n",
        "RARE_BLOCK_KEYWORDS = ['chest', 'door', 'fence', 'trapdoor', 'carpet', 'bed', 'button', 'lever']\n",
        "RARE_BLOCK_TOKENS = set()\n",
        "for tok, block in tok2block.items():\n",
        "    for keyword in RARE_BLOCK_KEYWORDS:\n",
        "        if keyword in block.lower():\n",
        "            RARE_BLOCK_TOKENS.add(tok)\n",
        "            break\n",
        "\n",
        "RARE_BLOCK_TOKENS_TENSOR = torch.tensor(sorted(RARE_BLOCK_TOKENS), dtype=torch.long)\n",
        "print(f\"\\nRare block tokens identified: {len(RARE_BLOCK_TOKENS)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-11"
      },
      "source": [
        "## Cell 5: Terrain Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-12"
      },
      "outputs": [],
      "source": [
        "TERRAIN_BLOCKS: Set[str] = {\n",
        "    'minecraft:dirt', 'minecraft:grass_block', 'minecraft:coarse_dirt',\n",
        "    'minecraft:podzol', 'minecraft:mycelium', 'minecraft:rooted_dirt',\n",
        "    'minecraft:dirt_path', 'minecraft:farmland', 'minecraft:mud',\n",
        "    'minecraft:stone', 'minecraft:cobblestone', 'minecraft:mossy_cobblestone',\n",
        "    'minecraft:bedrock', 'minecraft:deepslate', 'minecraft:tuff',\n",
        "    'minecraft:granite', 'minecraft:diorite', 'minecraft:andesite',\n",
        "    'minecraft:sand', 'minecraft:red_sand', 'minecraft:gravel', 'minecraft:clay',\n",
        "    'minecraft:water', 'minecraft:lava',\n",
        "    'minecraft:terracotta', 'minecraft:white_terracotta', 'minecraft:orange_terracotta',\n",
        "    'minecraft:brown_terracotta', 'minecraft:red_terracotta',\n",
        "    'minecraft:netherrack', 'minecraft:soul_sand', 'minecraft:soul_soil',\n",
        "    'minecraft:end_stone',\n",
        "    'minecraft:snow_block', 'minecraft:ice', 'minecraft:packed_ice',\n",
        "}\n",
        "\n",
        "TERRAIN_TOKENS: Set[int] = set()\n",
        "for tok, block in tok2block.items():\n",
        "    base_name = block.split('[')[0] if '[' in block else block\n",
        "    if base_name in TERRAIN_BLOCKS:\n",
        "        TERRAIN_TOKENS.add(tok)\n",
        "\n",
        "TERRAIN_TOKENS_TENSOR = torch.tensor(sorted(TERRAIN_TOKENS), dtype=torch.long)\n",
        "print(f\"Terrain tokens: {len(TERRAIN_TOKENS)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-13"
      },
      "source": [
        "## Cell 6: Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-14"
      },
      "outputs": [],
      "source": [
        "class VQVAEDataset(Dataset):\n",
        "    def __init__(self, data_dir: str):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.h5_files = sorted(self.data_dir.glob(\"*.h5\"))\n",
        "        if not self.h5_files:\n",
        "            raise ValueError(f\"No H5 files in {data_dir}\")\n",
        "        print(f\"Found {len(self.h5_files)} structures in {data_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.h5_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        with h5py.File(self.h5_files[idx], 'r') as f:\n",
        "            key = list(f.keys())[0]\n",
        "            structure = f[key][:].astype(np.int64)\n",
        "        return torch.from_numpy(structure).long()\n",
        "\n",
        "train_dataset = VQVAEDataset(DATA_DIR)\n",
        "val_dataset = VQVAEDataset(VAL_DIR)\n",
        "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-15"
      },
      "source": [
        "## Cell 7: FSQ Base Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-16"
      },
      "outputs": [],
      "source": [
        "class FSQ(nn.Module):\n",
        "    def __init__(self, levels: List[int], eps: float = 1e-3):\n",
        "        super().__init__()\n",
        "        self.levels = levels\n",
        "        self.dim = len(levels)\n",
        "        self.eps = eps\n",
        "        self.codebook_size = int(np.prod(levels))\n",
        "\n",
        "        self.register_buffer('_levels', torch.tensor(levels, dtype=torch.float32))\n",
        "        basis = []\n",
        "        acc = 1\n",
        "        for L in reversed(levels):\n",
        "            basis.append(acc)\n",
        "            acc *= L\n",
        "        self.register_buffer('_basis', torch.tensor(list(reversed(basis)), dtype=torch.long))\n",
        "        half_levels = [(L - 1) / 2 for L in levels]\n",
        "        self.register_buffer('_half_levels', torch.tensor(half_levels, dtype=torch.float32))\n",
        "        self.register_buffer('_usage', torch.zeros(self.codebook_size))\n",
        "\n",
        "    def reset_usage(self):\n",
        "        self._usage.zero_()\n",
        "\n",
        "    def get_usage_stats(self) -> Tuple[float, float]:\n",
        "        usage = (self._usage > 0).float().mean().item()\n",
        "        if self._usage.sum() == 0:\n",
        "            return usage, 0.0\n",
        "        probs = self._usage / self._usage.sum()\n",
        "        probs = probs[probs > 0]\n",
        "        entropy = -(probs * probs.log()).sum()\n",
        "        perplexity = entropy.exp().item()\n",
        "        return usage, perplexity\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        z_bounded = torch.tanh(z)\n",
        "        z_q_list = []\n",
        "        for i in range(self.dim):\n",
        "            L = self._levels[i]\n",
        "            half_L = self._half_levels[i]\n",
        "            z_i = z_bounded[..., i]\n",
        "            z_i = z_i * half_L\n",
        "            z_i = torch.round(z_i)\n",
        "            z_i = torch.clamp(z_i, -half_L, half_L)\n",
        "            z_i = z_i / half_L\n",
        "            z_q_list.append(z_i)\n",
        "        z_q = torch.stack(z_q_list, dim=-1)\n",
        "        z_q = z_bounded + (z_q - z_bounded).detach()\n",
        "        indices = torch.zeros(z_q.shape[:-1], dtype=torch.long, device=z_q.device)\n",
        "        for i in range(self.dim):\n",
        "            L = self._levels[i].long()\n",
        "            half_L = self._half_levels[i]\n",
        "            z_i = z_q[..., i]\n",
        "            level_idx = ((z_i * half_L) + half_L).round().long()\n",
        "            level_idx = torch.clamp(level_idx, 0, L - 1)\n",
        "            indices = indices + level_idx * self._basis[i]\n",
        "        with torch.no_grad():\n",
        "            for idx in indices.unique():\n",
        "                if idx < self.codebook_size:\n",
        "                    self._usage[idx] += (indices == idx).sum()\n",
        "        return z_q, indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-17"
      },
      "source": [
        "## Cell 8: RFSQ Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-18"
      },
      "outputs": [],
      "source": [
        "class InvertibleLayerNorm(nn.Module):\n",
        "    def __init__(self, num_features: int, eps: float = 1e-5):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(num_features))\n",
        "        self.bias = nn.Parameter(torch.zeros(num_features))\n",
        "        self.stored_mean = None\n",
        "        self.stored_std = None\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        self.stored_mean = x.mean(dim=(1, 2, 3), keepdim=True)\n",
        "        self.stored_std = x.std(dim=(1, 2, 3), keepdim=True) + self.eps\n",
        "        x_norm = (x - self.stored_mean) / self.stored_std\n",
        "        return x_norm * self.weight + self.bias\n",
        "\n",
        "    def inverse(self, x_norm: torch.Tensor) -> torch.Tensor:\n",
        "        x = (x_norm - self.bias) / self.weight\n",
        "        return x * self.stored_std + self.stored_mean\n",
        "\n",
        "\n",
        "class RFSQStage(nn.Module):\n",
        "    def __init__(self, levels: List[int]):\n",
        "        super().__init__()\n",
        "        self.fsq = FSQ(levels)\n",
        "        self.layernorm = InvertibleLayerNorm(len(levels))\n",
        "\n",
        "    @property\n",
        "    def codebook_size(self) -> int:\n",
        "        return self.fsq.codebook_size\n",
        "\n",
        "    def reset_usage(self):\n",
        "        self.fsq.reset_usage()\n",
        "\n",
        "    def get_usage_stats(self):\n",
        "        return self.fsq.get_usage_stats()\n",
        "\n",
        "    def forward(self, residual):\n",
        "        z_norm = self.layernorm(residual)\n",
        "        z_q_norm, indices = self.fsq(z_norm)\n",
        "        z_q = self.layernorm.inverse(z_q_norm)\n",
        "        new_residual = residual - z_q\n",
        "        return z_q, new_residual, indices\n",
        "\n",
        "\n",
        "class RFSQ(nn.Module):\n",
        "    def __init__(self, levels_per_stage: List[int], num_stages: int = 2):\n",
        "        super().__init__()\n",
        "        self.num_stages = num_stages\n",
        "        self.dim = len(levels_per_stage)\n",
        "        self.stages = nn.ModuleList([RFSQStage(levels_per_stage) for _ in range(num_stages)])\n",
        "        codes_per_stage = int(np.prod(levels_per_stage))\n",
        "        self.codebook_size = codes_per_stage ** num_stages\n",
        "        self.codes_per_stage = codes_per_stage\n",
        "\n",
        "    def reset_usage(self):\n",
        "        for stage in self.stages:\n",
        "            stage.reset_usage()\n",
        "\n",
        "    def get_usage_stats(self):\n",
        "        return {f'stage{i}': stage.get_usage_stats() for i, stage in enumerate(self.stages)}\n",
        "\n",
        "    def forward(self, z):\n",
        "        residual = z\n",
        "        z_q_sum = torch.zeros_like(z)\n",
        "        all_indices = []\n",
        "        for stage in self.stages:\n",
        "            z_q, residual, indices = stage(residual)\n",
        "            z_q_sum = z_q_sum + z_q\n",
        "            all_indices.append(indices)\n",
        "        return z_q_sum, all_indices\n",
        "\n",
        "    def forward_with_norms(self, z):\n",
        "        residual = z\n",
        "        z_q_sum = torch.zeros_like(z)\n",
        "        all_indices = []\n",
        "        residual_norms = []\n",
        "        for stage in self.stages:\n",
        "            residual_norms.append(residual.norm().item())\n",
        "            z_q, residual, indices = stage(residual)\n",
        "            z_q_sum = z_q_sum + z_q\n",
        "            all_indices.append(indices)\n",
        "        residual_norms.append(residual.norm().item())\n",
        "        return z_q_sum, all_indices, residual_norms\n",
        "\n",
        "print(f\"RFSQ module defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-19"
      },
      "source": [
        "## Cell 9: VQ-VAE v7 Architecture with U-Net Skip Connections\n",
        "\n",
        "Key architectural changes:\n",
        "1. **EncoderV7**: Returns z_e + skip_16 + skip_32\n",
        "2. **DecoderV7**: Accepts and concatenates skip connections\n",
        "3. **VolumeRatioPenalty**: Penalizes over-prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-20"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock3D(nn.Module):\n",
        "    def __init__(self, channels: int):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv3d(channels, channels, 3, padding=1)\n",
        "        self.conv2 = nn.Conv3d(channels, channels, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm3d(channels)\n",
        "        self.bn2 = nn.BatchNorm3d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        return F.relu(x + residual)\n",
        "\n",
        "\n",
        "class EncoderV7(nn.Module):\n",
        "    \"\"\"Encoder with dual skip connection outputs for U-Net architecture.\n",
        "    \n",
        "    Returns:\n",
        "        z_e: Final latent [B, rfsq_dim, 8, 8, 8]\n",
        "        skip_16: Features at 16x16x16 [B, hidden_dims[0], 16, 16, 16]\n",
        "        skip_32: Input embeddings [B, in_channels, 32, 32, 32]\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, in_channels: int, hidden_dims: List[int], rfsq_dim: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Stage 1: 32 -> 16 (output used for skip_16)\n",
        "        self.stage1 = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, hidden_dims[0], 4, stride=2, padding=1),\n",
        "            nn.BatchNorm3d(hidden_dims[0]),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout3d(dropout),\n",
        "            ResidualBlock3D(hidden_dims[0]),\n",
        "        )\n",
        "        \n",
        "        # Stage 2: 16 -> 8\n",
        "        self.stage2 = nn.Sequential(\n",
        "            nn.Conv3d(hidden_dims[0], hidden_dims[1], 4, stride=2, padding=1),\n",
        "            nn.BatchNorm3d(hidden_dims[1]),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout3d(dropout),\n",
        "            ResidualBlock3D(hidden_dims[1]),\n",
        "        )\n",
        "        \n",
        "        # Final processing at 8x8x8\n",
        "        self.final = nn.Sequential(\n",
        "            ResidualBlock3D(hidden_dims[1]),\n",
        "            ResidualBlock3D(hidden_dims[1]),\n",
        "            nn.Conv3d(hidden_dims[1], rfsq_dim, 3, padding=1),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        # Store input for skip_32 connection\n",
        "        skip_32 = x  # [B, 32, 32, 32, 32]\n",
        "        \n",
        "        # Stage 1: capture 16x16x16 features for skip_16\n",
        "        skip_16 = self.stage1(x)  # [B, 96, 16, 16, 16]\n",
        "        \n",
        "        # Stage 2: compress to 8x8x8\n",
        "        x = self.stage2(skip_16)  # [B, 192, 8, 8, 8]\n",
        "        \n",
        "        # Final projection to RFSQ dimension\n",
        "        z_e = self.final(x)  # [B, 4, 8, 8, 8]\n",
        "        \n",
        "        return z_e, skip_16, skip_32\n",
        "\n",
        "\n",
        "class DecoderV7(nn.Module):\n",
        "    \"\"\"Decoder with dual U-Net skip connections.\n",
        "    \n",
        "    Skip connections:\n",
        "        - skip_16: Concatenated after first upsample (8->16)\n",
        "        - skip_32: Concatenated after second upsample (16->32)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, rfsq_dim: int, hidden_dims: List[int], num_blocks: int, \n",
        "                 emb_dim: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        # hidden_dims is [192, 96] (reversed from encoder)\n",
        "        \n",
        "        # Initial projection from RFSQ dim\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv3d(rfsq_dim, hidden_dims[0], 3, padding=1),\n",
        "            nn.BatchNorm3d(hidden_dims[0]),\n",
        "            nn.ReLU(inplace=True),\n",
        "            ResidualBlock3D(hidden_dims[0]),\n",
        "            ResidualBlock3D(hidden_dims[0]),\n",
        "        )\n",
        "        \n",
        "        # Upsample 8 -> 16\n",
        "        self.up1 = nn.Sequential(\n",
        "            ResidualBlock3D(hidden_dims[0]),\n",
        "            nn.ConvTranspose3d(hidden_dims[0], hidden_dims[1], 4, stride=2, padding=1),\n",
        "            nn.BatchNorm3d(hidden_dims[1]),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout3d(dropout),\n",
        "        )\n",
        "        \n",
        "        # Skip connection 1 projection: 96 (up1) + 96 (skip_16) = 192 -> 96\n",
        "        self.skip1_proj = nn.Sequential(\n",
        "            nn.Conv3d(hidden_dims[1] * 2, hidden_dims[1], 1),\n",
        "            nn.BatchNorm3d(hidden_dims[1]),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        \n",
        "        # Process after skip 1\n",
        "        self.post_skip1 = nn.Sequential(\n",
        "            ResidualBlock3D(hidden_dims[1]),\n",
        "            ResidualBlock3D(hidden_dims[1]),\n",
        "        )\n",
        "        \n",
        "        # Upsample 16 -> 32\n",
        "        self.up2 = nn.Sequential(\n",
        "            ResidualBlock3D(hidden_dims[1]),\n",
        "            nn.ConvTranspose3d(hidden_dims[1], hidden_dims[1], 4, stride=2, padding=1),\n",
        "            nn.BatchNorm3d(hidden_dims[1]),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        \n",
        "        # Skip connection 2 projection: 96 (up2) + 32 (skip_32/emb) = 128 -> 96\n",
        "        self.skip2_proj = nn.Sequential(\n",
        "            nn.Conv3d(hidden_dims[1] + emb_dim, hidden_dims[1], 1),\n",
        "            nn.BatchNorm3d(hidden_dims[1]),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        \n",
        "        # Process after skip 2\n",
        "        self.post_skip2 = ResidualBlock3D(hidden_dims[1])\n",
        "        \n",
        "        # Final prediction\n",
        "        self.final = nn.Conv3d(hidden_dims[1], num_blocks, 3, padding=1)\n",
        "    \n",
        "    def forward(self, z_q: torch.Tensor, skip_16: torch.Tensor, skip_32: torch.Tensor) -> torch.Tensor:\n",
        "        # Initial processing at 8x8x8\n",
        "        x = self.initial(z_q)  # [B, 192, 8, 8, 8]\n",
        "        \n",
        "        # Upsample to 16x16x16\n",
        "        x = self.up1(x)  # [B, 96, 16, 16, 16]\n",
        "        \n",
        "        # Skip connection 1: concat with encoder's 16x16x16 features\n",
        "        x = torch.cat([x, skip_16], dim=1)  # [B, 192, 16, 16, 16]\n",
        "        x = self.skip1_proj(x)  # [B, 96, 16, 16, 16]\n",
        "        x = self.post_skip1(x)  # [B, 96, 16, 16, 16]\n",
        "        \n",
        "        # Upsample to 32x32x32\n",
        "        x = self.up2(x)  # [B, 96, 32, 32, 32]\n",
        "        \n",
        "        # Skip connection 2: concat with input embeddings\n",
        "        x = torch.cat([x, skip_32], dim=1)  # [B, 128, 32, 32, 32] (96 + 32)\n",
        "        x = self.skip2_proj(x)  # [B, 96, 32, 32, 32]\n",
        "        x = self.post_skip2(x)  # [B, 96, 32, 32, 32]\n",
        "        \n",
        "        # Predict block types\n",
        "        logits = self.final(x)  # [B, vocab_size, 32, 32, 32]\n",
        "        \n",
        "        return logits\n",
        "\n",
        "\n",
        "class FrequencyWeightedLoss(nn.Module):\n",
        "    \"\"\"Cross-entropy with terrain weighting AND per-block frequency weighting.\"\"\"\n",
        "\n",
        "    def __init__(self, frequency_weights: torch.Tensor,\n",
        "                 terrain_weight: float = 0.2, building_weight: float = 1.0, air_weight: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.register_buffer('frequency_weights', frequency_weights)\n",
        "        self.terrain_weight = terrain_weight\n",
        "        self.building_weight = building_weight\n",
        "        self.air_weight = air_weight\n",
        "\n",
        "    def forward(self, logits: torch.Tensor, targets: torch.Tensor,\n",
        "                terrain_mask: torch.Tensor, air_mask: torch.Tensor) -> torch.Tensor:\n",
        "        ce_loss = F.cross_entropy(logits, targets, reduction='none')\n",
        "        base_weights = torch.full_like(ce_loss, self.building_weight)\n",
        "        base_weights[terrain_mask] = self.terrain_weight\n",
        "        base_weights[air_mask] = self.air_weight\n",
        "        freq_weights = self.frequency_weights[targets]\n",
        "        combined_weights = base_weights * freq_weights\n",
        "        return (ce_loss * combined_weights).sum() / combined_weights.sum()\n",
        "\n",
        "\n",
        "class VolumeRatioPenalty(nn.Module):\n",
        "    \"\"\"Penalize when predicted volume deviates from ground truth.\n",
        "    \n",
        "    Loss = weight * (vol_ratio - 1.0)^2\n",
        "    \n",
        "    This addresses v6-freq's 1.68x over-prediction problem.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, weight: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.weight = weight\n",
        "    \n",
        "    def forward(self, preds: torch.Tensor, targets: torch.Tensor, \n",
        "                air_tokens: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Compute volume penalty from hard predictions.\"\"\"\n",
        "        gt_air = torch.isin(targets, air_tokens)\n",
        "        pred_air = torch.isin(preds, air_tokens)\n",
        "        \n",
        "        gt_volume = (~gt_air).sum().float()\n",
        "        pred_volume = (~pred_air).sum().float()\n",
        "        \n",
        "        vol_ratio = pred_volume / (gt_volume + 1e-6)\n",
        "        volume_penalty = self.weight * (vol_ratio - 1.0) ** 2\n",
        "        \n",
        "        return volume_penalty, vol_ratio.detach()\n",
        "\n",
        "\n",
        "print(\"V7 architecture components defined!\")\n",
        "print(\"  - EncoderV7: Returns z_e, skip_16, skip_32\")\n",
        "print(\"  - DecoderV7: Accepts dual skip connections\")\n",
        "print(\"  - VolumeRatioPenalty: Penalizes over-prediction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-21"
      },
      "source": [
        "## Cell 10: Complete Metrics Computation\n",
        "\n",
        "All metrics from CLAUDE.md reference including NEW: precision, F1, air_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-22"
      },
      "outputs": [],
      "source": [
        "def compute_all_metrics(preds: torch.Tensor, targets: torch.Tensor,\n",
        "                        air_tokens: torch.Tensor, terrain_tokens: torch.Tensor,\n",
        "                        rare_tokens: torch.Tensor, \n",
        "                        block_emb: nn.Embedding) -> Dict[str, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Compute ALL required metrics for VQ-VAE v7.\n",
        "    \n",
        "    NEW metrics in v7:\n",
        "        - building_precision: % of predicted building that is actually building\n",
        "        - building_f1: Balanced precision/recall score\n",
        "        - air_acc: % of GT air predicted as air\n",
        "        - air_precision: % of predicted air that is actually air\n",
        "        - false_block_rate: air incorrectly predicted as building\n",
        "        - rare_precision: precision on rare blocks\n",
        "    \"\"\"\n",
        "    device = preds.device\n",
        "    \n",
        "    # Masks\n",
        "    gt_air = torch.isin(targets, air_tokens)\n",
        "    pred_air = torch.isin(preds, air_tokens)\n",
        "    gt_terrain = torch.isin(targets, terrain_tokens) & ~gt_air\n",
        "    gt_building = ~gt_air & ~gt_terrain\n",
        "    gt_rare = torch.isin(targets, rare_tokens)\n",
        "    \n",
        "    correct = (preds == targets)\n",
        "    \n",
        "    metrics = {}\n",
        "    \n",
        "    # === CORE METRICS ===\n",
        "    metrics['overall_acc'] = correct.float().mean()\n",
        "    \n",
        "    # Building metrics\n",
        "    if gt_building.any():\n",
        "        metrics['building_acc'] = correct[gt_building].float().mean()\n",
        "        metrics['building_recall'] = (~pred_air[gt_building]).float().mean()\n",
        "        metrics['building_false_air'] = pred_air[gt_building].float().mean()\n",
        "    else:\n",
        "        metrics['building_acc'] = torch.tensor(0.0, device=device)\n",
        "        metrics['building_recall'] = torch.tensor(0.0, device=device)\n",
        "        metrics['building_false_air'] = torch.tensor(0.0, device=device)\n",
        "    \n",
        "    # Terrain metrics\n",
        "    if gt_terrain.any():\n",
        "        metrics['terrain_acc'] = correct[gt_terrain].float().mean()\n",
        "    else:\n",
        "        metrics['terrain_acc'] = torch.tensor(0.0, device=device)\n",
        "    \n",
        "    # === NEW: BUILDING PRECISION ===\n",
        "    pred_building = ~pred_air\n",
        "    if pred_building.any():\n",
        "        # Of all predicted non-air, how many are correct AND were actually non-air?\n",
        "        correct_building = correct & pred_building & ~gt_air\n",
        "        metrics['building_precision'] = correct_building.sum().float() / pred_building.sum().float()\n",
        "    else:\n",
        "        metrics['building_precision'] = torch.tensor(0.0, device=device)\n",
        "    \n",
        "    # === NEW: BUILDING F1 ===\n",
        "    prec = metrics['building_precision']\n",
        "    rec = metrics['building_recall']\n",
        "    if (prec + rec) > 0:\n",
        "        metrics['building_f1'] = 2 * (prec * rec) / (prec + rec)\n",
        "    else:\n",
        "        metrics['building_f1'] = torch.tensor(0.0, device=device)\n",
        "    \n",
        "    # === NEW: AIR METRICS ===\n",
        "    if gt_air.any():\n",
        "        metrics['air_acc'] = correct[gt_air].float().mean()\n",
        "        metrics['false_block_rate'] = (~pred_air[gt_air]).float().mean()\n",
        "    else:\n",
        "        metrics['air_acc'] = torch.tensor(1.0, device=device)\n",
        "        metrics['false_block_rate'] = torch.tensor(0.0, device=device)\n",
        "    \n",
        "    if pred_air.any():\n",
        "        correct_air = correct & pred_air & gt_air\n",
        "        metrics['air_precision'] = correct_air.sum().float() / pred_air.sum().float()\n",
        "    else:\n",
        "        metrics['air_precision'] = torch.tensor(0.0, device=device)\n",
        "    \n",
        "    # === VOLUME METRICS ===\n",
        "    gt_struct = ~gt_air\n",
        "    pred_struct = ~pred_air\n",
        "    \n",
        "    gt_volume = gt_struct.sum().float()\n",
        "    pred_volume = pred_struct.sum().float()\n",
        "    metrics['vol_ratio'] = pred_volume / (gt_volume + 1e-6)\n",
        "    \n",
        "    if gt_struct.any():\n",
        "        metrics['struct_recall'] = pred_struct[gt_struct].float().mean()\n",
        "    else:\n",
        "        metrics['struct_recall'] = torch.tensor(1.0, device=device)\n",
        "    \n",
        "    # === RARE BLOCK METRICS ===\n",
        "    if gt_rare.any():\n",
        "        metrics['rare_acc'] = correct[gt_rare].float().mean()\n",
        "        metrics['rare_recall'] = (~pred_air[gt_rare]).float().mean()\n",
        "        \n",
        "        # NEW: Rare precision\n",
        "        pred_rare = torch.isin(preds, rare_tokens)\n",
        "        if pred_rare.any():\n",
        "            correct_rare = correct & pred_rare & gt_rare\n",
        "            metrics['rare_precision'] = correct_rare.sum().float() / pred_rare.sum().float()\n",
        "        else:\n",
        "            metrics['rare_precision'] = torch.tensor(0.0, device=device)\n",
        "    else:\n",
        "        metrics['rare_acc'] = torch.tensor(0.0, device=device)\n",
        "        metrics['rare_recall'] = torch.tensor(0.0, device=device)\n",
        "        metrics['rare_precision'] = torch.tensor(0.0, device=device)\n",
        "    \n",
        "    # === ERROR SIMILARITY ===\n",
        "    wrong_building = gt_building & (preds != targets)\n",
        "    if wrong_building.any():\n",
        "        metrics['error_similarity'] = F.cosine_similarity(\n",
        "            block_emb.weight[preds[wrong_building]],\n",
        "            block_emb.weight[targets[wrong_building]], \n",
        "            dim=-1\n",
        "        ).mean()\n",
        "    else:\n",
        "        metrics['error_similarity'] = torch.tensor(0.0, device=device)\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "\n",
        "print(\"Complete metrics function defined!\")\n",
        "print(\"NEW metrics: building_precision, building_f1, air_acc, air_precision, false_block_rate, rare_precision\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-23"
      },
      "source": [
        "## Cell 11: VQ-VAE v7 Full Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-24"
      },
      "outputs": [],
      "source": [
        "class VQVAEv7(nn.Module):\n",
        "    \"\"\"VQ-VAE v7 with U-Net skip connections + Volume Penalty.\n",
        "    \n",
        "    Key improvements over v6-freq:\n",
        "    1. Dual skip connections (16x16x16 + 32x32x32) preserve fine details\n",
        "    2. Volume ratio penalty prevents over-prediction\n",
        "    3. Reduced frequency weight cap (10x -> 5x)\n",
        "    4. Complete metrics including precision/F1\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, vocab_size: int, emb_dim: int, hidden_dims: List[int],\n",
        "                 rfsq_levels: List[int], num_stages: int, pretrained_emb: np.ndarray,\n",
        "                 frequency_weights: torch.Tensor,\n",
        "                 terrain_weight: float = 0.2, building_weight: float = 1.0,\n",
        "                 air_weight: float = 0.1, volume_penalty_weight: float = 0.1,\n",
        "                 dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.vocab_size = vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "        self.rfsq_dim = len(rfsq_levels)\n",
        "        self.num_stages = num_stages\n",
        "        \n",
        "        # Block embeddings (frozen)\n",
        "        self.block_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.block_emb.weight.data.copy_(torch.from_numpy(pretrained_emb))\n",
        "        self.block_emb.weight.requires_grad = False\n",
        "        \n",
        "        # Encoder with dual skip outputs\n",
        "        self.encoder = EncoderV7(emb_dim, hidden_dims, self.rfsq_dim, dropout)\n",
        "        \n",
        "        # RFSQ quantization (unchanged from v6)\n",
        "        self.rfsq = RFSQ(rfsq_levels, num_stages)\n",
        "        \n",
        "        # Decoder with dual skip inputs\n",
        "        self.decoder = DecoderV7(\n",
        "            self.rfsq_dim, \n",
        "            list(reversed(hidden_dims)), \n",
        "            vocab_size, \n",
        "            emb_dim,  # For skip_32 projection\n",
        "            dropout\n",
        "        )\n",
        "        \n",
        "        # Loss functions\n",
        "        self.loss_fn = FrequencyWeightedLoss(frequency_weights, terrain_weight, building_weight, air_weight)\n",
        "        self.volume_penalty = VolumeRatioPenalty(weight=volume_penalty_weight)\n",
        "    \n",
        "    def forward(self, block_ids: torch.Tensor, return_norms: bool = False) -> Dict[str, Any]:\n",
        "        # Embed blocks\n",
        "        x = self.block_emb(block_ids)  # [B, 32, 32, 32, emb_dim]\n",
        "        x = x.permute(0, 4, 1, 2, 3).contiguous()  # [B, emb_dim, 32, 32, 32]\n",
        "        \n",
        "        # Encode with dual skip connections\n",
        "        z_e, skip_16, skip_32 = self.encoder(x)\n",
        "        # z_e: [B, 4, 8, 8, 8], skip_16: [B, 96, 16, 16, 16], skip_32: [B, 32, 32, 32, 32]\n",
        "        \n",
        "        # Permute for RFSQ (expects channels last)\n",
        "        z_e = z_e.permute(0, 2, 3, 4, 1).contiguous()  # [B, 8, 8, 8, 4]\n",
        "        \n",
        "        # Quantize\n",
        "        if return_norms:\n",
        "            z_q, all_indices, residual_norms = self.rfsq.forward_with_norms(z_e)\n",
        "        else:\n",
        "            z_q, all_indices = self.rfsq(z_e)\n",
        "            residual_norms = None\n",
        "        \n",
        "        # Permute back for decoder\n",
        "        z_q = z_q.permute(0, 4, 1, 2, 3).contiguous()  # [B, 4, 8, 8, 8]\n",
        "        \n",
        "        # Decode with dual skip connections\n",
        "        logits = self.decoder(z_q, skip_16, skip_32)  # [B, vocab, 32, 32, 32]\n",
        "        \n",
        "        result = {\n",
        "            'logits': logits,\n",
        "            'all_indices': all_indices,\n",
        "            'z_e': z_e,\n",
        "            'z_q': z_q,\n",
        "            'skip_16': skip_16,\n",
        "            'skip_32': skip_32,\n",
        "        }\n",
        "        \n",
        "        if residual_norms is not None:\n",
        "            result['residual_norms'] = residual_norms\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    def compute_loss(self, block_ids: torch.Tensor, air_tokens: torch.Tensor,\n",
        "                     terrain_tokens: torch.Tensor, rare_tokens: torch.Tensor,\n",
        "                     structure_weight: float = 50.0, return_norms: bool = False) -> Dict[str, torch.Tensor]:\n",
        "        out = self(block_ids, return_norms=return_norms)\n",
        "        logits = out['logits']\n",
        "        \n",
        "        B, C, X, Y, Z = logits.shape\n",
        "        logits_flat = logits.permute(0, 2, 3, 4, 1).reshape(-1, C)\n",
        "        targets_flat = block_ids.view(-1)\n",
        "        \n",
        "        device = targets_flat.device\n",
        "        air_dev = air_tokens.to(device)\n",
        "        terrain_dev = terrain_tokens.to(device)\n",
        "        rare_dev = rare_tokens.to(device)\n",
        "        \n",
        "        is_air = torch.isin(targets_flat, air_dev)\n",
        "        is_terrain = torch.isin(targets_flat, terrain_dev) & ~is_air\n",
        "        \n",
        "        # Frequency-weighted CE loss\n",
        "        ce_loss = self.loss_fn(logits_flat, targets_flat, is_terrain, is_air)\n",
        "        \n",
        "        # Compute predictions for volume penalty and metrics\n",
        "        with torch.no_grad():\n",
        "            preds = logits_flat.argmax(dim=1)\n",
        "        \n",
        "        # Volume penalty (NEW in v7)\n",
        "        vol_penalty, vol_ratio = self.volume_penalty(preds, targets_flat, air_dev)\n",
        "        \n",
        "        # Total loss\n",
        "        loss = ce_loss + vol_penalty\n",
        "        \n",
        "        # Compute all metrics\n",
        "        with torch.no_grad():\n",
        "            metrics = compute_all_metrics(\n",
        "                preds, targets_flat,\n",
        "                air_dev, terrain_dev, rare_dev,\n",
        "                self.block_emb\n",
        "            )\n",
        "        \n",
        "        result = {\n",
        "            'loss': loss,\n",
        "            'ce_loss': ce_loss,\n",
        "            'vol_penalty': vol_penalty,\n",
        "            **metrics,\n",
        "        }\n",
        "        \n",
        "        if 'residual_norms' in out:\n",
        "            result['residual_norms'] = out['residual_norms']\n",
        "        \n",
        "        return result\n",
        "\n",
        "\n",
        "print(\"VQ-VAE v7 model defined!\")\n",
        "print(\"  - U-Net dual skip connections\")\n",
        "print(\"  - Volume ratio penalty\")\n",
        "print(\"  - Complete metrics (precision, F1, air metrics)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-25"
      },
      "source": [
        "## Cell 12: Training Functions with Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-26"
      },
      "outputs": [],
      "source": [
        "# All metric keys for v7\n",
        "METRIC_KEYS = [\n",
        "    'loss', 'ce_loss', 'vol_penalty',\n",
        "    'overall_acc', 'terrain_acc', \n",
        "    'building_acc', 'building_recall', 'building_precision', 'building_f1', 'building_false_air',\n",
        "    'air_acc', 'air_precision', 'false_block_rate',\n",
        "    'struct_recall', 'vol_ratio', 'error_similarity',\n",
        "    'rare_acc', 'rare_recall', 'rare_precision',\n",
        "]\n",
        "\n",
        "\n",
        "def train_epoch(model, loader, optimizer, scaler, device,\n",
        "                air_tokens, terrain_tokens, rare_tokens, structure_weight):\n",
        "    model.train()\n",
        "    model.rfsq.reset_usage()\n",
        "    \n",
        "    metrics = {k: 0.0 for k in METRIC_KEYS}\n",
        "    grad_norms = []\n",
        "    all_residual_norms = []\n",
        "    n = 0\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    for batch_idx, batch in enumerate(tqdm(loader, desc=\"Train\", leave=False)):\n",
        "        batch = batch.to(device)\n",
        "        \n",
        "        with torch.amp.autocast('cuda', enabled=USE_AMP):\n",
        "            return_norms = (batch_idx % 100 == 0)\n",
        "            out = model.compute_loss(batch, air_tokens, terrain_tokens, rare_tokens,\n",
        "                                    structure_weight, return_norms=return_norms)\n",
        "            loss = out['loss'] / GRAD_ACCUM_STEPS\n",
        "        \n",
        "        if return_norms and 'residual_norms' in out:\n",
        "            all_residual_norms.append(out['residual_norms'])\n",
        "        \n",
        "        scaler.scale(loss).backward()\n",
        "        \n",
        "        if (batch_idx + 1) % GRAD_ACCUM_STEPS == 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            grad_norms.append(grad_norm.item())\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        for k in metrics:\n",
        "            if k in out:\n",
        "                metrics[k] += out[k].item() if torch.is_tensor(out[k]) else out[k]\n",
        "        n += 1\n",
        "    \n",
        "    # RFSQ stage stats\n",
        "    stage_stats = model.rfsq.get_usage_stats()\n",
        "    for stage_name, (usage, perp) in stage_stats.items():\n",
        "        metrics[f'{stage_name}_usage'] = usage\n",
        "        metrics[f'{stage_name}_perplexity'] = perp\n",
        "    \n",
        "    metrics['grad_norm'] = sum(grad_norms) / len(grad_norms) if grad_norms else 0.0\n",
        "    \n",
        "    if all_residual_norms:\n",
        "        avg_norms = np.mean(all_residual_norms, axis=0)\n",
        "        metrics['residual_decay'] = avg_norms[-1] / avg_norms[0] if avg_norms[0] > 0 else 1.0\n",
        "    else:\n",
        "        metrics['residual_decay'] = 1.0\n",
        "    \n",
        "    skip_avg = ['stage0_usage', 'stage0_perplexity', 'stage1_usage', 'stage1_perplexity', 'grad_norm', 'residual_decay']\n",
        "    return {k: v/n if k not in skip_avg else v for k, v in metrics.items()}\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, loader, device, air_tokens, terrain_tokens, rare_tokens, structure_weight):\n",
        "    model.eval()\n",
        "    model.rfsq.reset_usage()\n",
        "    \n",
        "    metrics = {k: 0.0 for k in METRIC_KEYS}\n",
        "    all_residual_norms = []\n",
        "    n = 0\n",
        "    \n",
        "    for batch_idx, batch in enumerate(tqdm(loader, desc=\"Val\", leave=False)):\n",
        "        batch = batch.to(device)\n",
        "        \n",
        "        with torch.amp.autocast('cuda', enabled=USE_AMP):\n",
        "            return_norms = (batch_idx % 50 == 0)\n",
        "            out = model.compute_loss(batch, air_tokens, terrain_tokens, rare_tokens,\n",
        "                                    structure_weight, return_norms=return_norms)\n",
        "        \n",
        "        if return_norms and 'residual_norms' in out:\n",
        "            all_residual_norms.append(out['residual_norms'])\n",
        "        \n",
        "        for k in metrics:\n",
        "            if k in out:\n",
        "                metrics[k] += out[k].item() if torch.is_tensor(out[k]) else out[k]\n",
        "        n += 1\n",
        "    \n",
        "    stage_stats = model.rfsq.get_usage_stats()\n",
        "    for stage_name, (usage, perp) in stage_stats.items():\n",
        "        metrics[f'{stage_name}_usage'] = usage\n",
        "        metrics[f'{stage_name}_perplexity'] = perp\n",
        "    \n",
        "    if all_residual_norms:\n",
        "        avg_norms = np.mean(all_residual_norms, axis=0)\n",
        "        metrics['residual_decay'] = avg_norms[-1] / avg_norms[0] if avg_norms[0] > 0 else 1.0\n",
        "    else:\n",
        "        metrics['residual_decay'] = 1.0\n",
        "    \n",
        "    skip_avg = ['stage0_usage', 'stage0_perplexity', 'stage1_usage', 'stage1_perplexity', 'residual_decay']\n",
        "    return {k: v/n if k not in skip_avg else v for k, v in metrics.items()}\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping based on validation metric.\"\"\"\n",
        "    def __init__(self, patience: int = 10, metric: str = 'building_f1', mode: str = 'max'):\n",
        "        self.patience = patience\n",
        "        self.metric = metric\n",
        "        self.mode = mode\n",
        "        self.best_value = float('-inf') if mode == 'max' else float('inf')\n",
        "        self.counter = 0\n",
        "        self.best_epoch = 0\n",
        "    \n",
        "    def __call__(self, value: float, epoch: int) -> bool:\n",
        "        is_better = (value > self.best_value) if self.mode == 'max' else (value < self.best_value)\n",
        "        if is_better:\n",
        "            self.best_value = value\n",
        "            self.best_epoch = epoch\n",
        "            self.counter = 0\n",
        "            return False  # Don't stop\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            return self.counter >= self.patience  # Stop if patience exceeded\n",
        "\n",
        "\n",
        "print(\"Training functions defined with early stopping!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-27"
      },
      "source": [
        "## Cell 13: Create Model and Optimizer with Cosine Annealing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-28"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "g = torch.Generator().manual_seed(SEED)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True, generator=g)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                        num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "model = VQVAEv7(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    emb_dim=EMBEDDING_DIM,\n",
        "    hidden_dims=HIDDEN_DIMS,\n",
        "    rfsq_levels=RFSQ_LEVELS_PER_STAGE,\n",
        "    num_stages=NUM_STAGES,\n",
        "    pretrained_emb=v3_embeddings,\n",
        "    frequency_weights=FREQUENCY_WEIGHT_TENSOR,\n",
        "    terrain_weight=TERRAIN_WEIGHT,\n",
        "    building_weight=BUILDING_WEIGHT,\n",
        "    air_weight=AIR_WEIGHT,\n",
        "    volume_penalty_weight=VOLUME_PENALTY_WEIGHT,\n",
        "    dropout=DROPOUT,\n",
        ").to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total params: {total_params:,}\")\n",
        "print(f\"Trainable params: {trainable_params:,}\")\n",
        "print(f\"RFSQ total codes: {model.rfsq.codebook_size:,}\")\n",
        "\n",
        "optimizer = optim.AdamW([p for p in model.parameters() if p.requires_grad], lr=BASE_LR, weight_decay=1e-5)\n",
        "\n",
        "# Cosine annealing LR scheduler (NEW in v7)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=TOTAL_EPOCHS, eta_min=MIN_LR)\n",
        "\n",
        "scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP)\n",
        "\n",
        "# Early stopping (NEW in v7)\n",
        "early_stopper = EarlyStopping(patience=EARLY_STOPPING_PATIENCE, metric=EARLY_STOPPING_METRIC, mode='max')\n",
        "\n",
        "print(f\"\\nOptimizer: AdamW, LR={BASE_LR}\")\n",
        "print(f\"LR Schedule: Cosine annealing ({BASE_LR} -> {MIN_LR})\")\n",
        "print(f\"Early stopping: patience={EARLY_STOPPING_PATIENCE} on {EARLY_STOPPING_METRIC}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-29"
      },
      "source": [
        "## Cell 14: Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-30"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"VQ-VAE V7 TRAINING - U-NET + VOLUME PENALTY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Key features:\")\n",
        "print(f\"  - U-Net dual skip connections (16x16x16 + 32x32x32)\")\n",
        "print(f\"  - Volume ratio penalty (weight={VOLUME_PENALTY_WEIGHT})\")\n",
        "print(f\"  - Frequency cap: {FREQUENCY_WEIGHT_CAP}x (down from 10x)\")\n",
        "print(f\"  - Cosine annealing LR: {BASE_LR} -> {MIN_LR}\")\n",
        "print(f\"  - Early stopping: {EARLY_STOPPING_PATIENCE} epochs on {EARLY_STOPPING_METRIC}\")\n",
        "print(f\"  - NEW metrics: precision, F1, air_acc\")\n",
        "print()\n",
        "\n",
        "# History with all v7 metrics\n",
        "history = {\n",
        "    # Core metrics\n",
        "    'train_loss': [], 'train_ce_loss': [], 'train_vol_penalty': [],\n",
        "    'train_building_acc': [], 'train_building_recall': [], 'train_building_precision': [], 'train_building_f1': [],\n",
        "    'train_terrain_acc': [], 'train_struct_recall': [], 'train_building_false_air': [],\n",
        "    'val_loss': [], 'val_ce_loss': [], 'val_vol_penalty': [],\n",
        "    'val_building_acc': [], 'val_building_recall': [], 'val_building_precision': [], 'val_building_f1': [],\n",
        "    'val_terrain_acc': [], 'val_struct_recall': [], 'val_building_false_air': [],\n",
        "    # Air metrics (NEW)\n",
        "    'train_air_acc': [], 'train_air_precision': [], 'train_false_block_rate': [],\n",
        "    'val_air_acc': [], 'val_air_precision': [], 'val_false_block_rate': [],\n",
        "    # Volume and error\n",
        "    'train_vol_ratio': [], 'val_vol_ratio': [],\n",
        "    'train_error_similarity': [], 'val_error_similarity': [],\n",
        "    # RFSQ metrics\n",
        "    'train_stage0_usage': [], 'train_stage0_perplexity': [],\n",
        "    'train_stage1_usage': [], 'train_stage1_perplexity': [],\n",
        "    'val_stage0_usage': [], 'val_stage0_perplexity': [],\n",
        "    'val_stage1_usage': [], 'val_stage1_perplexity': [],\n",
        "    'train_residual_decay': [], 'val_residual_decay': [],\n",
        "    # Rare block metrics\n",
        "    'train_rare_acc': [], 'val_rare_acc': [],\n",
        "    'train_rare_recall': [], 'val_rare_recall': [],\n",
        "    'train_rare_precision': [], 'val_rare_precision': [],\n",
        "    # Training diagnostics\n",
        "    'train_grad_norm': [], 'learning_rate': [],\n",
        "}\n",
        "\n",
        "best_building_f1 = 0\n",
        "best_building_acc = 0\n",
        "best_epoch = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(TOTAL_EPOCHS):\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    history['learning_rate'].append(current_lr)\n",
        "    \n",
        "    train_m = train_epoch(model, train_loader, optimizer, scaler, device,\n",
        "                          AIR_TOKENS_TENSOR, TERRAIN_TOKENS_TENSOR, RARE_BLOCK_TOKENS_TENSOR, STRUCTURE_WEIGHT)\n",
        "    val_m = validate(model, val_loader, device,\n",
        "                     AIR_TOKENS_TENSOR, TERRAIN_TOKENS_TENSOR, RARE_BLOCK_TOKENS_TENSOR, STRUCTURE_WEIGHT)\n",
        "    \n",
        "    # Update LR scheduler\n",
        "    scheduler.step()\n",
        "    \n",
        "    # Record all metrics\n",
        "    for key in history:\n",
        "        if key == 'learning_rate':\n",
        "            continue\n",
        "        if key.startswith('train_'):\n",
        "            metric_name = key[6:]\n",
        "            history[key].append(train_m.get(metric_name, 0))\n",
        "        elif key.startswith('val_'):\n",
        "            metric_name = key[4:]\n",
        "            history[key].append(val_m.get(metric_name, 0))\n",
        "    \n",
        "    # Track best building_f1 (for early stopping)\n",
        "    if val_m['building_f1'] > best_building_f1:\n",
        "        best_building_f1 = val_m['building_f1']\n",
        "        best_building_acc = val_m['building_acc']\n",
        "        best_epoch = epoch + 1\n",
        "        torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v7_best.pt\")\n",
        "    \n",
        "    # Print progress with NEW metrics\n",
        "    print(f\"Epoch {epoch+1:2d} | LR: {current_lr:.2e} | \"\n",
        "          f\"Build: {train_m['building_acc']:.1%}/{val_m['building_acc']:.1%} | \"\n",
        "          f\"Prec: {val_m['building_precision']:.1%} | F1: {val_m['building_f1']:.1%} | \"\n",
        "          f\"Vol: {val_m['vol_ratio']:.2f}\")\n",
        "    \n",
        "    # Early stopping check\n",
        "    if early_stopper(val_m['building_f1'], epoch + 1):\n",
        "        print(f\"\\nEarly stopping triggered! No improvement for {EARLY_STOPPING_PATIENCE} epochs.\")\n",
        "        print(f\"Best {EARLY_STOPPING_METRIC}: {early_stopper.best_value:.1%} at epoch {early_stopper.best_epoch}\")\n",
        "        break\n",
        "\n",
        "train_time = time.time() - start_time\n",
        "print(f\"\\nTraining complete in {train_time/60:.1f} minutes\")\n",
        "print(f\"Best val building F1: {best_building_f1:.1%} at epoch {best_epoch}\")\n",
        "print(f\"Best val building accuracy: {best_building_acc:.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-31"
      },
      "source": [
        "## Cell 15: Plot Training Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-32"
      },
      "outputs": [],
      "source": [
        "actual_epochs = len(history['train_loss'])\n",
        "epochs = range(1, actual_epochs + 1)\n",
        "\n",
        "fig, axes = plt.subplots(5, 4, figsize=(20, 20))\n",
        "\n",
        "# Row 1: Core building metrics\n",
        "ax = axes[0, 0]\n",
        "ax.plot(epochs, history['train_building_acc'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_building_acc'], 'r--', label='Val')\n",
        "ax.set_title('Building Accuracy (KEY)', fontweight='bold')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[0, 1]\n",
        "ax.plot(epochs, history['train_building_precision'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_building_precision'], 'r--', label='Val')\n",
        "ax.set_title('Building PRECISION (NEW)', fontweight='bold', color='green')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[0, 2]\n",
        "ax.plot(epochs, history['train_building_f1'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_building_f1'], 'r--', label='Val')\n",
        "ax.set_title('Building F1 (NEW)', fontweight='bold', color='green')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[0, 3]\n",
        "ax.plot(epochs, history['train_building_recall'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_building_recall'], 'r--', label='Val')\n",
        "ax.set_title('Building Recall')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Row 2: Air metrics (NEW)\n",
        "ax = axes[1, 0]\n",
        "ax.plot(epochs, history['train_air_acc'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_air_acc'], 'r--', label='Val')\n",
        "ax.set_title('Air Accuracy (NEW)', fontweight='bold', color='green')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[1, 1]\n",
        "ax.plot(epochs, history['train_false_block_rate'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_false_block_rate'], 'r--', label='Val')\n",
        "ax.set_title('False Block Rate (NEW)', fontweight='bold', color='orange')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[1, 2]\n",
        "ax.plot(epochs, history['train_vol_ratio'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_vol_ratio'], 'r--', label='Val')\n",
        "ax.axhline(y=1.0, color='g', linestyle='--', alpha=0.7, label='Target 1.0')\n",
        "ax.set_title('Volume Ratio (TARGET: ~1.0)', fontweight='bold')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[1, 3]\n",
        "ax.plot(epochs, history['train_vol_penalty'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_vol_penalty'], 'r--', label='Val')\n",
        "ax.set_title('Volume Penalty Loss (NEW)')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Row 3: RFSQ metrics\n",
        "ax = axes[2, 0]\n",
        "ax.plot(epochs, history['train_stage0_perplexity'], 'b-', label='Train S0')\n",
        "ax.plot(epochs, history['val_stage0_perplexity'], 'r--', label='Val S0')\n",
        "ax.set_title('Stage 0 Perplexity')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[2, 1]\n",
        "ax.plot(epochs, history['train_stage1_perplexity'], 'b-', label='Train S1')\n",
        "ax.plot(epochs, history['val_stage1_perplexity'], 'r--', label='Val S1')\n",
        "ax.set_title('Stage 1 Perplexity')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[2, 2]\n",
        "ax.plot(epochs, history['train_residual_decay'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_residual_decay'], 'r--', label='Val')\n",
        "ax.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='<50% target')\n",
        "ax.set_title('Residual Decay')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[2, 3]\n",
        "ax.plot(epochs, history['train_terrain_acc'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_terrain_acc'], 'r--', label='Val')\n",
        "ax.set_title('Terrain Accuracy')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Row 4: Rare blocks and diagnostics\n",
        "ax = axes[3, 0]\n",
        "ax.plot(epochs, history['train_rare_acc'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_rare_acc'], 'r--', label='Val')\n",
        "ax.set_title('Rare Block Accuracy')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[3, 1]\n",
        "ax.plot(epochs, history['train_rare_recall'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_rare_recall'], 'r--', label='Val')\n",
        "ax.set_title('Rare Block Recall')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[3, 2]\n",
        "ax.plot(epochs, history['train_loss'], 'b-', label='Train')\n",
        "ax.plot(epochs, history['val_loss'], 'r--', label='Val')\n",
        "ax.set_title('Total Loss')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[3, 3]\n",
        "ax.plot(epochs, history['learning_rate'], 'g-')\n",
        "ax.set_title('Learning Rate (Cosine Annealing)')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Row 5: Comparisons and summary\n",
        "ax = axes[4, 0]\n",
        "ax.plot(epochs, history['val_error_similarity'], 'b-')\n",
        "ax.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5)\n",
        "ax.set_title('Error Similarity (Val)')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# v6-freq vs v7 comparison\n",
        "ax = axes[4, 1]\n",
        "v6_freq = {'Build\\nAcc': 0.492, 'Build\\nPrec': 0.58, 'Build\\nF1': 0.73, 'Vol\\nRatio': 1.68}\n",
        "v7_final = {\n",
        "    'Build\\nAcc': history['val_building_acc'][-1],\n",
        "    'Build\\nPrec': history['val_building_precision'][-1],\n",
        "    'Build\\nF1': history['val_building_f1'][-1],\n",
        "    'Vol\\nRatio': history['val_vol_ratio'][-1],\n",
        "}\n",
        "x = np.arange(len(v6_freq))\n",
        "width = 0.35\n",
        "ax.bar(x - width/2, list(v6_freq.values()), width, label='v6-freq', color='gray')\n",
        "ax.bar(x + width/2, list(v7_final.values()), width, label='v7', color='green')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(v6_freq.keys())\n",
        "ax.set_title('v6-freq vs v7')\n",
        "ax.legend(); ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Final metrics\n",
        "ax = axes[4, 2]\n",
        "final = {\n",
        "    'Build\\nAcc': history['val_building_acc'][-1],\n",
        "    'Build\\nPrec': history['val_building_precision'][-1],\n",
        "    'Build\\nF1': history['val_building_f1'][-1],\n",
        "    'Vol\\nRatio': history['val_vol_ratio'][-1],\n",
        "    'Air\\nAcc': history['val_air_acc'][-1],\n",
        "}\n",
        "colors = ['green', 'blue', 'purple', 'orange', 'cyan']\n",
        "bars = ax.bar(final.keys(), final.values(), color=colors)\n",
        "ax.set_title('Final Val Metrics')\n",
        "ax.set_ylim(0, max(1.5, max(final.values()) * 1.1))\n",
        "for bar, val in zip(bars, final.values()):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "            f'{val:.2f}', ha='center', fontsize=9)\n",
        "\n",
        "# Summary\n",
        "ax = axes[4, 3]\n",
        "ax.axis('off')\n",
        "summary = f\"\"\"VQ-VAE v7 Results\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "Best Building F1: {best_building_f1:.1%} (epoch {best_epoch})\n",
        "Best Building Acc: {best_building_acc:.1%}\n",
        "\n",
        "Final Metrics:\n",
        "  Building Accuracy: {history['val_building_acc'][-1]:.1%}\n",
        "  Building Precision: {history['val_building_precision'][-1]:.1%}\n",
        "  Building F1: {history['val_building_f1'][-1]:.1%}\n",
        "  Volume Ratio: {history['val_vol_ratio'][-1]:.2f} (target ~1.0)\n",
        "  Air Accuracy: {history['val_air_acc'][-1]:.1%}\n",
        "  False Block Rate: {history['val_false_block_rate'][-1]:.1%}\n",
        "\n",
        "Changes from v6-freq:\n",
        "  - Dual U-Net skip connections\n",
        "  - Volume penalty: {VOLUME_PENALTY_WEIGHT}\n",
        "  - Freq cap: {FREQUENCY_WEIGHT_CAP}x\n",
        "  - Cosine annealing LR\n",
        "\n",
        "Training Time: {train_time/60:.1f} min\"\"\"\n",
        "ax.text(0.05, 0.95, summary, transform=ax.transAxes, fontsize=10,\n",
        "        verticalalignment='top', fontfamily='monospace')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUTPUT_DIR}/vqvae_v7_training.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Fixed Code Block\n",
        "print(f\"{'Metric':<25} {'v6-freq':<15} {'v7':<15} {'Change':<15}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# 1. Building Accuracy (Fixed order: <15.1%)\n",
        "print(f\"{'Building Accuracy':<25} {'49.2%':<15} {history['val_building_acc'][-1]:<15.1%} {(history['val_building_acc'][-1]-0.492)*100:+.1f}%\")\n",
        "\n",
        "# 2. Building Precision (Fixed order: <15.1%)\n",
        "print(f\"{'Building Precision':<25} {'~58%':<15} {history['val_building_precision'][-1]:<15.1%} {'(NEW)':<15}\")\n",
        "\n",
        "# 3. Building F1 (Fixed order: <15.1%)\n",
        "print(f\"{'Building F1':<25} {'~73%':<15} {history['val_building_f1'][-1]:<15.1%} {'(NEW)':<15}\")\n",
        "\n",
        "# 4. Volume Ratio (Fixed order: <15.2f)\n",
        "print(f\"{'Volume Ratio':<25} {'1.68':<15} {history['val_vol_ratio'][-1]:<15.2f} {history['val_vol_ratio'][-1]-1.68:+.2f}\")\n",
        "\n",
        "# 5. Air Accuracy (Fixed order: <15.1%)\n",
        "print(f\"{'Air Accuracy':<25} {'N/A':<15} {history['val_air_acc'][-1]:<15.1%} {'(NEW)':<15}\")\n",
        "\n",
        "# 6. False Block Rate (Fixed order: <15.1%)\n",
        "print(f\"{'False Block Rate':<25} {'N/A':<15} {history['val_false_block_rate'][-1]:<15.1%} {'(NEW)':<15}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-33"
      },
      "source": [
        "## Cell 16: Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-34"
      },
      "outputs": [],
      "source": [
        "results = {\n",
        "    'config': {\n",
        "        'version': 'v7',\n",
        "        'changes_from_v6_freq': [\n",
        "            'Dual U-Net skip connections (16x16x16 + 32x32x32)',\n",
        "            f'Volume ratio penalty (weight={VOLUME_PENALTY_WEIGHT})',\n",
        "            f'Reduced frequency cap ({FREQUENCY_WEIGHT_CAP}x from 10x)',\n",
        "            'Cosine annealing LR schedule',\n",
        "            f'Early stopping (patience={EARLY_STOPPING_PATIENCE} on {EARLY_STOPPING_METRIC})',\n",
        "            'New metrics: precision, F1, air_acc, false_block_rate',\n",
        "        ],\n",
        "        'hidden_dims': HIDDEN_DIMS,\n",
        "        'rfsq_levels_per_stage': RFSQ_LEVELS_PER_STAGE,\n",
        "        'num_stages': NUM_STAGES,\n",
        "        'frequency_weight_cap': FREQUENCY_WEIGHT_CAP,\n",
        "        'volume_penalty_weight': VOLUME_PENALTY_WEIGHT,\n",
        "        'total_epochs': TOTAL_EPOCHS,\n",
        "        'actual_epochs': actual_epochs,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'base_lr': BASE_LR,\n",
        "        'min_lr': MIN_LR,\n",
        "        'early_stopping_patience': EARLY_STOPPING_PATIENCE,\n",
        "        'early_stopping_metric': EARLY_STOPPING_METRIC,\n",
        "        'seed': SEED,\n",
        "    },\n",
        "    'results': {\n",
        "        'best_building_f1': float(best_building_f1),\n",
        "        'best_building_acc': float(best_building_acc),\n",
        "        'best_epoch': best_epoch,\n",
        "        'final_building_acc': float(history['val_building_acc'][-1]),\n",
        "        'final_building_precision': float(history['val_building_precision'][-1]),\n",
        "        'final_building_f1': float(history['val_building_f1'][-1]),\n",
        "        'final_building_recall': float(history['val_building_recall'][-1]),\n",
        "        'final_vol_ratio': float(history['val_vol_ratio'][-1]),\n",
        "        'final_air_acc': float(history['val_air_acc'][-1]),\n",
        "        'final_air_precision': float(history['val_air_precision'][-1]),\n",
        "        'final_false_block_rate': float(history['val_false_block_rate'][-1]),\n",
        "        'final_rare_acc': float(history['val_rare_acc'][-1]),\n",
        "        'final_rare_recall': float(history['val_rare_recall'][-1]),\n",
        "        'final_stage0_perplexity': float(history['val_stage0_perplexity'][-1]) if history['val_stage0_perplexity'] else 0,\n",
        "        'final_stage1_perplexity': float(history['val_stage1_perplexity'][-1]) if history['val_stage1_perplexity'] else 0,\n",
        "        'training_time_min': float(train_time / 60),\n",
        "    },\n",
        "    'history': {k: [float(x) for x in v] for k, v in history.items()},\n",
        "}\n",
        "\n",
        "with open(f\"{OUTPUT_DIR}/vqvae_v7_results.json\", 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "checkpoint = {\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'config': {\n",
        "        'version': 'v7',\n",
        "        'vocab_size': VOCAB_SIZE,\n",
        "        'emb_dim': EMBEDDING_DIM,\n",
        "        'hidden_dims': HIDDEN_DIMS,\n",
        "        'rfsq_levels': RFSQ_LEVELS_PER_STAGE,\n",
        "        'num_stages': NUM_STAGES,\n",
        "        'frequency_weight_cap': FREQUENCY_WEIGHT_CAP,\n",
        "        'volume_penalty_weight': VOLUME_PENALTY_WEIGHT,\n",
        "    },\n",
        "    'air_tokens': AIR_TOKENS_LIST,\n",
        "    'terrain_tokens': sorted(TERRAIN_TOKENS),\n",
        "    'rare_tokens': sorted(RARE_BLOCK_TOKENS),\n",
        "    'best_building_f1': float(best_building_f1),\n",
        "    'best_building_acc': float(best_building_acc),\n",
        "    'best_epoch': best_epoch,\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, f\"{OUTPUT_DIR}/vqvae_v7_best_checkpoint.pt\")\n",
        "torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v7_final.pt\")\n",
        "\n",
        "print(\"\\nResults saved:\")\n",
        "print(f\"  - {OUTPUT_DIR}/vqvae_v7_results.json\")\n",
        "print(f\"  - {OUTPUT_DIR}/vqvae_v7_best_checkpoint.pt\")\n",
        "print(f\"  - {OUTPUT_DIR}/vqvae_v7_final.pt\")\n",
        "print(f\"  - {OUTPUT_DIR}/vqvae_v7_training.png\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL RESULTS - VQ-VAE v7 (U-Net + Volume Penalty)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Best building F1: {best_building_f1:.1%} at epoch {best_epoch}\")\n",
        "print(f\"Best building accuracy: {best_building_acc:.1%}\")\n",
        "print(f\"\\nKEY IMPROVEMENTS:\")\n",
        "print(f\"  Volume ratio: {history['val_vol_ratio'][-1]:.2f} (v6-freq was 1.68)\")\n",
        "print(f\"  Building precision: {history['val_building_precision'][-1]:.1%}\")\n",
        "print(f\"  False block rate: {history['val_false_block_rate'][-1]:.1%}\")\n",
        "print(f\"\\nTraining time: {train_time/60:.1f} minutes\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
