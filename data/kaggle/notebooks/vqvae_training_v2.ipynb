{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQ-VAE v2: Fixed Training with EMA Codebook\n",
    "\n",
    "## Key Fixes from v1:\n",
    "\n",
    "1. **EMA Codebook Updates**: Instead of gradient descent on codebook, use exponential moving average\n",
    "2. **Dead Code Reset**: Reinitialize codebook entries that are never used\n",
    "3. **Weighted Loss**: Non-air blocks weighted 10x higher (combats class imbalance)\n",
    "4. **Higher Commitment Cost**: beta=0.5 instead of 0.25\n",
    "5. **Structure Accuracy Tracking**: Separate metrics for air vs non-air blocks\n",
    "\n",
    "## Why v1 Failed (Codebook Collapse)\n",
    "\n",
    "In v1, only 29 out of 512 codes were used because:\n",
    "- Air blocks dominate (~90% of voxels), so model optimized for predicting air\n",
    "- Unused codebook entries drifted away and were never recovered\n",
    "- Low commitment cost let encoder outputs \"hover\" between codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: Imports and Setup\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: Configuration (UPDATED)\n",
    "# ============================================================\n",
    "\n",
    "# === Data Paths ===\n",
    "DATA_DIR = \"/kaggle/input/minecraft-schematics/minecraft_splits/splits/train\"\n",
    "VAL_DIR = \"/kaggle/input/minecraft-schematics/minecraft_splits/splits/val\"\n",
    "VOCAB_PATH = \"/kaggle/input/minecraft-schematics/tok2block.json\"\n",
    "EMBEDDINGS_PATH = \"/kaggle/input/block2vec-embeddings/block_embeddings.npy\"\n",
    "OUTPUT_DIR = \"/kaggle/working\"\n",
    "\n",
    "# === Model Architecture ===\n",
    "BLOCK_EMBEDDING_DIM = 32\n",
    "HIDDEN_DIMS = [64, 128, 256]\n",
    "LATENT_DIM = 256\n",
    "NUM_CODEBOOK_ENTRIES = 512  # Keep 512 - EMA + reset will use more\n",
    "\n",
    "# === KEY CHANGES ===\n",
    "COMMITMENT_COST = 0.5       # Increased from 0.25 - stronger commitment\n",
    "EMA_DECAY = 0.99            # EMA decay rate for codebook updates\n",
    "STRUCTURE_WEIGHT = 10.0     # Weight non-air blocks 10x higher\n",
    "USE_FOCAL_LOSS = False      # Optional: focal loss for hard examples\n",
    "\n",
    "# === Training Hyperparameters ===\n",
    "EPOCHS = 30                 # Slightly more epochs for EMA to stabilize\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "USE_AMP = True\n",
    "\n",
    "# === Other ===\n",
    "SEED = 42\n",
    "NUM_WORKERS = 2\n",
    "AIR_INDEX = 0               # Block ID for air\n",
    "\n",
    "print(\"Configuration loaded (v2 with fixes)!\")\n",
    "print(f\"  Key changes:\")\n",
    "print(f\"    - EMA codebook updates (decay={EMA_DECAY})\")\n",
    "print(f\"    - Dead code reset\")\n",
    "print(f\"    - Structure weight: {STRUCTURE_WEIGHT}x for non-air blocks\")\n",
    "print(f\"    - Commitment cost: {COMMITMENT_COST}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: Load Vocabulary and Pre-trained Embeddings\n",
    "# ============================================================\n",
    "\n",
    "with open(VOCAB_PATH, 'r') as f:\n",
    "    tok2block = {int(k): v for k, v in json.load(f).items()}\n",
    "\n",
    "VOCAB_SIZE = len(tok2block)\n",
    "print(f\"Vocabulary size: {VOCAB_SIZE} block types\")\n",
    "\n",
    "# Find air block index\n",
    "for tok, block in tok2block.items():\n",
    "    if 'air' in block.lower() and 'stair' not in block.lower():\n",
    "        print(f\"Air block: token {tok} = '{block}'\")\n",
    "        AIR_INDEX = tok\n",
    "        break\n",
    "\n",
    "pretrained_embeddings = np.load(EMBEDDINGS_PATH)\n",
    "print(f\"Loaded embeddings: {pretrained_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: Dataset Class (unchanged)\n",
    "# ============================================================\n",
    "\n",
    "class VQVAEDataset(Dataset):\n",
    "    def __init__(self, data_dir: str, augment: bool = False, seed: int = 42):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.augment = augment\n",
    "        self.rng = random.Random(seed)\n",
    "        self.h5_files = sorted(self.data_dir.glob(\"*.h5\"))\n",
    "        if not self.h5_files:\n",
    "            raise ValueError(f\"No H5 files found in {data_dir}\")\n",
    "        print(f\"Found {len(self.h5_files)} structures in {data_dir}\")\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.h5_files)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        h5_path = self.h5_files[idx]\n",
    "        with h5py.File(h5_path, 'r') as f:\n",
    "            key = list(f.keys())[0]\n",
    "            structure = f[key][:].astype(np.int64)\n",
    "        \n",
    "        if self.augment:\n",
    "            k = self.rng.randint(0, 3)\n",
    "            if k > 0:\n",
    "                structure = np.rot90(structure, k=k, axes=(0, 2))\n",
    "            if self.rng.random() > 0.5:\n",
    "                structure = np.flip(structure, axis=2)\n",
    "            structure = np.ascontiguousarray(structure)\n",
    "        \n",
    "        return torch.from_numpy(structure).long()\n",
    "\n",
    "train_dataset = VQVAEDataset(DATA_DIR, augment=True, seed=SEED)\n",
    "val_dataset = VQVAEDataset(VAL_DIR, augment=False, seed=SEED)\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: Create DataLoaders\n",
    "# ============================================================\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=(device == \"cuda\"),\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=(device == \"cuda\"),\n",
    ")\n",
    "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: EMA Vector Quantizer (NEW!)\n",
    "\n",
    "The key fix: instead of learning the codebook via gradient descent, we update it using **Exponential Moving Average**:\n",
    "\n",
    "```\n",
    "For each codebook entry i:\n",
    "   N_i = decay * N_i + (1-decay) * (count of assignments to i)\n",
    "   m_i = decay * m_i + (1-decay) * (sum of encoder outputs assigned to i)\n",
    "   codebook[i] = m_i / N_i\n",
    "```\n",
    "\n",
    "This is more stable and prevents codebook collapse.\n",
    "\n",
    "We also **reset dead codes** - if a code isn't used, reinitialize it to a random encoder output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: EMA Vector Quantizer (KEY FIX!)\n",
    "# ============================================================\n",
    "\n",
    "class VectorQuantizerEMA(nn.Module):\n",
    "    \"\"\"\n",
    "    Vector Quantization with EMA codebook updates.\n",
    "    \n",
    "    Key improvements over gradient-based VQ:\n",
    "    1. EMA updates are more stable\n",
    "    2. Dead code reset prevents codebook collapse\n",
    "    3. No gradient on codebook - only commitment loss on encoder\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_embeddings: int = 512,\n",
    "        embedding_dim: int = 256,\n",
    "        commitment_cost: float = 0.5,\n",
    "        decay: float = 0.99,\n",
    "        epsilon: float = 1e-5,\n",
    "        dead_code_threshold: float = 0.01,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.commitment_cost = commitment_cost\n",
    "        self.decay = decay\n",
    "        self.epsilon = epsilon\n",
    "        self.dead_code_threshold = dead_code_threshold\n",
    "        \n",
    "        # Codebook (not a learnable parameter - updated via EMA)\n",
    "        self.register_buffer(\"codebook\", torch.randn(num_embeddings, embedding_dim))\n",
    "        self.register_buffer(\"ema_cluster_size\", torch.zeros(num_embeddings))\n",
    "        self.register_buffer(\"ema_embed_sum\", torch.randn(num_embeddings, embedding_dim))\n",
    "        self.register_buffer(\"initialized\", torch.tensor(False))\n",
    "        self.register_buffer(\"usage_count\", torch.zeros(num_embeddings))\n",
    "    \n",
    "    def _init_codebook(self, flat_z_e: torch.Tensor):\n",
    "        \"\"\"Initialize codebook from first batch of encoder outputs.\"\"\"\n",
    "        n_samples = flat_z_e.shape[0]\n",
    "        if n_samples >= self.num_embeddings:\n",
    "            indices = torch.randperm(n_samples, device=flat_z_e.device)[:self.num_embeddings]\n",
    "            self.codebook.data.copy_(flat_z_e[indices])\n",
    "        else:\n",
    "            self.codebook.data[:n_samples].copy_(flat_z_e)\n",
    "        \n",
    "        self.ema_cluster_size.fill_(1.0)\n",
    "        self.ema_embed_sum.data.copy_(self.codebook.data)\n",
    "        self.initialized.fill_(True)\n",
    "        print(\"Codebook initialized from encoder outputs!\")\n",
    "    \n",
    "    def _reset_dead_codes(self, flat_z_e: torch.Tensor, encoding_indices: torch.Tensor):\n",
    "        \"\"\"Reset codebook entries that are rarely used.\"\"\"\n",
    "        batch_usage = torch.bincount(\n",
    "            encoding_indices.view(-1), minlength=self.num_embeddings\n",
    "        ).float()\n",
    "        \n",
    "        self.usage_count.data.mul_(self.decay).add_(batch_usage, alpha=1 - self.decay)\n",
    "        \n",
    "        avg_usage = self.usage_count.sum() / self.num_embeddings\n",
    "        dead_mask = self.usage_count < (avg_usage * self.dead_code_threshold)\n",
    "        n_dead = dead_mask.sum().item()\n",
    "        \n",
    "        if n_dead > 0 and flat_z_e.shape[0] > 0:\n",
    "            n_samples = min(int(n_dead), flat_z_e.shape[0])\n",
    "            indices = torch.randperm(flat_z_e.shape[0], device=flat_z_e.device)[:n_samples]\n",
    "            samples = flat_z_e[indices]\n",
    "            dead_indices = torch.where(dead_mask)[0][:n_samples]\n",
    "            \n",
    "            self.codebook.data[dead_indices] = samples\n",
    "            self.ema_cluster_size.data[dead_indices] = 1.0\n",
    "            self.ema_embed_sum.data[dead_indices] = samples\n",
    "            self.usage_count.data[dead_indices] = avg_usage\n",
    "        \n",
    "        return n_dead\n",
    "    \n",
    "    def forward(self, z_e: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        # Reshape to [N, C]\n",
    "        z_e_permuted = z_e.permute(0, 2, 3, 4, 1).contiguous()\n",
    "        flat_z_e = z_e_permuted.view(-1, self.embedding_dim)\n",
    "        \n",
    "        # Initialize codebook from first batch\n",
    "        if not self.initialized and self.training:\n",
    "            self._init_codebook(flat_z_e)\n",
    "        \n",
    "        # Find nearest codebook entry\n",
    "        z_e_sq = (flat_z_e ** 2).sum(dim=1, keepdim=True)\n",
    "        codebook_sq = (self.codebook ** 2).sum(dim=1, keepdim=True).t()\n",
    "        dot_product = torch.mm(flat_z_e, self.codebook.t())\n",
    "        distances = z_e_sq + codebook_sq - 2 * dot_product\n",
    "        encoding_indices = distances.argmin(dim=1)\n",
    "        \n",
    "        z_q_flat = F.embedding(encoding_indices, self.codebook)\n",
    "        \n",
    "        # EMA update (only during training)\n",
    "        if self.training:\n",
    "            encodings = F.one_hot(encoding_indices, self.num_embeddings).float()\n",
    "            \n",
    "            batch_cluster_size = encodings.sum(0)\n",
    "            self.ema_cluster_size.data.mul_(self.decay).add_(\n",
    "                batch_cluster_size, alpha=1 - self.decay\n",
    "            )\n",
    "            \n",
    "            batch_embed_sum = encodings.t() @ flat_z_e\n",
    "            self.ema_embed_sum.data.mul_(self.decay).add_(\n",
    "                batch_embed_sum, alpha=1 - self.decay\n",
    "            )\n",
    "            \n",
    "            n = self.ema_cluster_size.sum()\n",
    "            smoothed_cluster_size = (\n",
    "                (self.ema_cluster_size + self.epsilon) /\n",
    "                (n + self.num_embeddings * self.epsilon) * n\n",
    "            )\n",
    "            \n",
    "            self.codebook.data.copy_(\n",
    "                self.ema_embed_sum / smoothed_cluster_size.unsqueeze(1)\n",
    "            )\n",
    "            \n",
    "            self._reset_dead_codes(flat_z_e, encoding_indices)\n",
    "        \n",
    "        z_q_permuted = z_q_flat.view(z_e_permuted.shape)\n",
    "        \n",
    "        # Only commitment loss (codebook updated via EMA)\n",
    "        commitment_loss = F.mse_loss(z_e_permuted, z_q_permuted.detach())\n",
    "        vq_loss = self.commitment_cost * commitment_loss\n",
    "        \n",
    "        # Straight-through\n",
    "        z_q_st = z_e_permuted + (z_q_permuted - z_e_permuted).detach()\n",
    "        z_q = z_q_st.permute(0, 4, 1, 2, 3).contiguous()\n",
    "        \n",
    "        encoding_indices = encoding_indices.view(z_e_permuted.shape[:-1])\n",
    "        \n",
    "        return z_q, vq_loss, encoding_indices\n",
    "    \n",
    "    def get_usage_stats(self) -> Tuple[int, float]:\n",
    "        \"\"\"Get codebook utilization.\"\"\"\n",
    "        avg_usage = self.usage_count.sum() / self.num_embeddings\n",
    "        used_mask = self.usage_count > (avg_usage * self.dead_code_threshold)\n",
    "        num_used = used_mask.sum().item()\n",
    "        return int(num_used), num_used / self.num_embeddings\n",
    "\n",
    "print(\"VectorQuantizerEMA defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: Residual Block (unchanged)\n",
    "# ============================================================\n",
    "\n",
    "class ResidualBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(in_channels)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.skip = nn.Conv3d(in_channels, out_channels, kernel_size=1) \\\n",
    "            if in_channels != out_channels else nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = self.skip(x)\n",
    "        out = F.relu(self.bn1(x))\n",
    "        out = self.conv1(out)\n",
    "        out = F.relu(self.bn2(out))\n",
    "        out = self.conv2(out)\n",
    "        return out + identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 8: Encoder (unchanged)\n",
    "# ============================================================\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels=32, hidden_dims=None, latent_dim=256):\n",
    "        super().__init__()\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [64, 128, 256]\n",
    "        \n",
    "        layers = []\n",
    "        current_channels = in_channels\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Conv3d(current_channels, hidden_dim, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm3d(hidden_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                ResidualBlock3D(hidden_dim, hidden_dim),\n",
    "            ])\n",
    "            current_channels = hidden_dim\n",
    "        layers.append(nn.Conv3d(current_channels, latent_dim, kernel_size=3, padding=1))\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 9: Decoder (unchanged)\n",
    "# ============================================================\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=256, hidden_dims=None, num_blocks=3717):\n",
    "        super().__init__()\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [256, 128, 64]\n",
    "        \n",
    "        layers = []\n",
    "        current_channels = latent_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                ResidualBlock3D(current_channels, current_channels),\n",
    "                nn.ConvTranspose3d(current_channels, hidden_dim, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm3d(hidden_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ])\n",
    "            current_channels = hidden_dim\n",
    "        layers.append(nn.Conv3d(current_channels, num_blocks, kernel_size=3, padding=1))\n",
    "        self.decoder = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, z_q):\n",
    "        return self.decoder(z_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 10: Full VQ-VAE Model (UPDATED with weighted loss)\n",
    "# ============================================================\n",
    "\n",
    "class VQVAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        block_embedding_dim: int,\n",
    "        hidden_dims: List[int],\n",
    "        latent_dim: int,\n",
    "        num_codebook_entries: int,\n",
    "        commitment_cost: float,\n",
    "        ema_decay: float,\n",
    "        pretrained_embeddings: np.ndarray,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_codebook_entries = num_codebook_entries\n",
    "        \n",
    "        # Block embeddings (frozen)\n",
    "        self.block_embeddings = nn.Embedding(vocab_size, block_embedding_dim)\n",
    "        self.block_embeddings.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
    "        self.block_embeddings.weight.requires_grad = False\n",
    "        \n",
    "        self.encoder = Encoder(in_channels=block_embedding_dim, hidden_dims=hidden_dims, latent_dim=latent_dim)\n",
    "        \n",
    "        # Use EMA quantizer!\n",
    "        self.quantizer = VectorQuantizerEMA(\n",
    "            num_embeddings=num_codebook_entries,\n",
    "            embedding_dim=latent_dim,\n",
    "            commitment_cost=commitment_cost,\n",
    "            decay=ema_decay,\n",
    "        )\n",
    "        \n",
    "        self.decoder = Decoder(latent_dim=latent_dim, hidden_dims=list(reversed(hidden_dims)), num_blocks=vocab_size)\n",
    "    \n",
    "    def forward(self, block_ids: torch.Tensor) -> Dict[str, Any]:\n",
    "        embedded = self.block_embeddings(block_ids)\n",
    "        embedded = embedded.permute(0, 4, 1, 2, 3).contiguous()\n",
    "        z_e = self.encoder(embedded)\n",
    "        z_q, vq_loss, indices = self.quantizer(z_e)\n",
    "        logits = self.decoder(z_q)\n",
    "        return {\"logits\": logits, \"vq_loss\": vq_loss, \"indices\": indices}\n",
    "    \n",
    "    def compute_loss(\n",
    "        self,\n",
    "        block_ids: torch.Tensor,\n",
    "        air_index: int = 0,\n",
    "        structure_weight: float = 10.0,\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Compute loss with class imbalance handling.\n",
    "        Non-air blocks are weighted higher to combat air dominance.\n",
    "        \"\"\"\n",
    "        outputs = self(block_ids)\n",
    "        \n",
    "        logits = outputs[\"logits\"].permute(0, 2, 3, 4, 1).contiguous()\n",
    "        logits_flat = logits.view(-1, self.vocab_size)\n",
    "        targets_flat = block_ids.view(-1)\n",
    "        \n",
    "        # Weight non-air blocks higher\n",
    "        is_structure = (targets_flat != air_index).float()\n",
    "        weights = 1.0 + is_structure * (structure_weight - 1)  # air=1, structure=10\n",
    "        \n",
    "        # Weighted cross-entropy\n",
    "        ce_loss = F.cross_entropy(logits_flat, targets_flat, reduction='none')\n",
    "        reconstruction_loss = (weights * ce_loss).mean()\n",
    "        \n",
    "        total_loss = reconstruction_loss + outputs[\"vq_loss\"]\n",
    "        \n",
    "        # Detailed accuracy metrics\n",
    "        with torch.no_grad():\n",
    "            predictions = logits_flat.argmax(dim=1)\n",
    "            correct = (predictions == targets_flat).float()\n",
    "            accuracy = correct.mean()\n",
    "            \n",
    "            air_mask = targets_flat == air_index\n",
    "            air_accuracy = correct[air_mask].mean() if air_mask.sum() > 0 else torch.tensor(0.0)\n",
    "            \n",
    "            structure_mask = ~air_mask\n",
    "            structure_accuracy = correct[structure_mask].mean() if structure_mask.sum() > 0 else torch.tensor(0.0)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"vq_loss\": outputs[\"vq_loss\"],\n",
    "            \"accuracy\": accuracy,\n",
    "            \"air_accuracy\": air_accuracy,\n",
    "            \"structure_accuracy\": structure_accuracy,\n",
    "            \"indices\": outputs[\"indices\"],\n",
    "        }\n",
    "\n",
    "print(\"VQVAE model defined (with EMA and weighted loss)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 11: Create Model\n",
    "# ============================================================\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "model = VQVAE(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    block_embedding_dim=BLOCK_EMBEDDING_DIM,\n",
    "    hidden_dims=HIDDEN_DIMS,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    num_codebook_entries=NUM_CODEBOOK_ENTRIES,\n",
    "    commitment_cost=COMMITMENT_COST,\n",
    "    ema_decay=EMA_DECAY,\n",
    "    pretrained_embeddings=pretrained_embeddings,\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total params: {total_params:,}, Trainable: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 12: Test Forward Pass\n",
    "# ============================================================\n",
    "\n",
    "print(\"Testing forward pass...\")\n",
    "with torch.no_grad():\n",
    "    test_batch = torch.randint(0, VOCAB_SIZE, (2, 32, 32, 32)).to(device)\n",
    "    outputs = model.compute_loss(test_batch, air_index=AIR_INDEX, structure_weight=STRUCTURE_WEIGHT)\n",
    "    print(f\"  Loss: {outputs['loss'].item():.4f}\")\n",
    "    print(f\"  Structure accuracy: {outputs['structure_accuracy'].item():.4f}\")\n",
    "print(\"Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 13: Create Optimizer and Scaler\n",
    "# ============================================================\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP)\n",
    "\n",
    "print(f\"Optimizer: AdamW, Scheduler: ReduceLROnPlateau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 14: Training Functions (UPDATED)\n",
    "# ============================================================\n",
    "\n",
    "def train_epoch(model, loader, optimizer, scaler, device, air_index, structure_weight, use_amp=True):\n",
    "    model.train()\n",
    "    metrics = {\"loss\": 0, \"recon\": 0, \"vq\": 0, \"acc\": 0, \"air_acc\": 0, \"struct_acc\": 0}\n",
    "    all_indices = []\n",
    "    \n",
    "    for batch in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        with torch.amp.autocast('cuda', enabled=use_amp):\n",
    "            outputs = model.compute_loss(batch, air_index=air_index, structure_weight=structure_weight)\n",
    "            loss = outputs[\"loss\"]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        metrics[\"loss\"] += loss.item()\n",
    "        metrics[\"recon\"] += outputs[\"reconstruction_loss\"].item()\n",
    "        metrics[\"vq\"] += outputs[\"vq_loss\"].item()\n",
    "        metrics[\"acc\"] += outputs[\"accuracy\"].item()\n",
    "        metrics[\"air_acc\"] += outputs[\"air_accuracy\"].item()\n",
    "        metrics[\"struct_acc\"] += outputs[\"structure_accuracy\"].item()\n",
    "        all_indices.append(outputs[\"indices\"].cpu())\n",
    "    \n",
    "    n = len(loader)\n",
    "    for k in metrics:\n",
    "        metrics[k] /= n\n",
    "    \n",
    "    # Codebook usage\n",
    "    all_indices = torch.cat([idx.view(-1) for idx in all_indices])\n",
    "    unique_codes = len(torch.unique(all_indices))\n",
    "    metrics[\"codebook_usage\"] = unique_codes / NUM_CODEBOOK_ENTRIES\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, device, air_index, structure_weight, use_amp=True):\n",
    "    model.eval()\n",
    "    metrics = {\"loss\": 0, \"recon\": 0, \"acc\": 0, \"air_acc\": 0, \"struct_acc\": 0}\n",
    "    \n",
    "    for batch in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        with torch.amp.autocast('cuda', enabled=use_amp):\n",
    "            outputs = model.compute_loss(batch, air_index=air_index, structure_weight=structure_weight)\n",
    "        \n",
    "        metrics[\"loss\"] += outputs[\"loss\"].item()\n",
    "        metrics[\"recon\"] += outputs[\"reconstruction_loss\"].item()\n",
    "        metrics[\"acc\"] += outputs[\"accuracy\"].item()\n",
    "        metrics[\"air_acc\"] += outputs[\"air_accuracy\"].item()\n",
    "        metrics[\"struct_acc\"] += outputs[\"structure_accuracy\"].item()\n",
    "    \n",
    "    n = len(loader)\n",
    "    for k in metrics:\n",
    "        metrics[k] /= n\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 15: Main Training Loop (UPDATED)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Starting Training (v2 with EMA + weighted loss)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": [], \"train_recon\": [], \"train_vq\": [],\n",
    "    \"train_acc\": [], \"train_air_acc\": [], \"train_struct_acc\": [],\n",
    "    \"val_loss\": [], \"val_recon\": [],\n",
    "    \"val_acc\": [], \"val_air_acc\": [], \"val_struct_acc\": [],\n",
    "    \"codebook_usage\": [], \"lr\": [],\n",
    "}\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    train_metrics = train_epoch(\n",
    "        model, train_loader, optimizer, scaler, device,\n",
    "        air_index=AIR_INDEX, structure_weight=STRUCTURE_WEIGHT, use_amp=USE_AMP\n",
    "    )\n",
    "    \n",
    "    val_metrics = validate(\n",
    "        model, val_loader, device,\n",
    "        air_index=AIR_INDEX, structure_weight=STRUCTURE_WEIGHT, use_amp=USE_AMP\n",
    "    )\n",
    "    \n",
    "    scheduler.step(val_metrics[\"loss\"])\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    \n",
    "    # Track history\n",
    "    history[\"train_loss\"].append(train_metrics[\"loss\"])\n",
    "    history[\"train_recon\"].append(train_metrics[\"recon\"])\n",
    "    history[\"train_vq\"].append(train_metrics[\"vq\"])\n",
    "    history[\"train_acc\"].append(train_metrics[\"acc\"])\n",
    "    history[\"train_air_acc\"].append(train_metrics[\"air_acc\"])\n",
    "    history[\"train_struct_acc\"].append(train_metrics[\"struct_acc\"])\n",
    "    history[\"val_loss\"].append(val_metrics[\"loss\"])\n",
    "    history[\"val_recon\"].append(val_metrics[\"recon\"])\n",
    "    history[\"val_acc\"].append(val_metrics[\"acc\"])\n",
    "    history[\"val_air_acc\"].append(val_metrics[\"air_acc\"])\n",
    "    history[\"val_struct_acc\"].append(val_metrics[\"struct_acc\"])\n",
    "    history[\"codebook_usage\"].append(train_metrics[\"codebook_usage\"])\n",
    "    history[\"lr\"].append(current_lr)\n",
    "    \n",
    "    if val_metrics[\"loss\"] < best_val_loss:\n",
    "        best_val_loss = val_metrics[\"loss\"]\n",
    "        torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_best.pt\")\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(\n",
    "        f\"Epoch {epoch+1:3d}/{EPOCHS} | \"\n",
    "        f\"Loss: {train_metrics['loss']:.3f} | \"\n",
    "        f\"Struct: {train_metrics['struct_acc']:.1%} | \"\n",
    "        f\"Val: {val_metrics['struct_acc']:.1%} | \"\n",
    "        f\"CB: {train_metrics['codebook_usage']:.1%} | \"\n",
    "        f\"{epoch_time:.0f}s\"\n",
    "    )\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTraining complete in {total_time/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 16: Save Results\n",
    "# ============================================================\n",
    "\n",
    "torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_final.pt\")\n",
    "codebook = model.quantizer.codebook.cpu().numpy()\n",
    "np.save(f\"{OUTPUT_DIR}/codebook.npy\", codebook)\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/training_history.json\", \"w\") as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(\"Results saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 17: Plot Training Curves (UPDATED)\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Loss\n",
    "ax = axes[0, 0]\n",
    "ax.plot(history[\"train_loss\"], label=\"Train\")\n",
    "ax.plot(history[\"val_loss\"], label=\"Val\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Total Loss\")\n",
    "ax.set_title(\"Training and Validation Loss\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Structure Accuracy (the key metric!)\n",
    "ax = axes[0, 1]\n",
    "ax.plot(history[\"train_struct_acc\"], label=\"Train Structure\")\n",
    "ax.plot(history[\"val_struct_acc\"], label=\"Val Structure\")\n",
    "ax.plot(history[\"train_air_acc\"], label=\"Train Air\", linestyle=\"--\", alpha=0.5)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Block Prediction Accuracy (Structure vs Air)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss Components\n",
    "ax = axes[1, 0]\n",
    "ax.plot(history[\"train_recon\"], label=\"Reconstruction\")\n",
    "ax.plot(history[\"train_vq\"], label=\"VQ (commitment)\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Loss Components\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Codebook Usage\n",
    "ax = axes[1, 1]\n",
    "ax.plot(history[\"codebook_usage\"], color=\"green\")\n",
    "ax.axhline(y=1.0, color=\"red\", linestyle=\"--\", label=\"100% usage\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Fraction Used\")\n",
    "ax.set_title(\"Codebook Utilization\")\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/training_curves.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Structure Accuracy: Train {history['train_struct_acc'][-1]:.1%}, Val {history['val_struct_acc'][-1]:.1%}\")\n",
    "print(f\"Codebook Usage: {history['codebook_usage'][-1]:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 18: Visualize Reconstructions\n",
    "# ============================================================\n",
    "\n",
    "def visualize_reconstruction(model, dataset, device, idx=0):\n",
    "    model.eval()\n",
    "    original = dataset[idx].unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(original)\n",
    "        reconstructed = outputs[\"logits\"].argmax(dim=1)\n",
    "    \n",
    "    original = original.cpu().numpy()[0]\n",
    "    reconstructed = reconstructed.cpu().numpy()[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    slice_idx = 16\n",
    "    \n",
    "    for i, (ax_row, data, label) in enumerate([\n",
    "        (axes[0], original, \"Original\"),\n",
    "        (axes[1], reconstructed, \"Reconstructed\")\n",
    "    ]):\n",
    "        ax_row[0].imshow(data[slice_idx, :, :], cmap='tab20')\n",
    "        ax_row[0].set_title(f'{label} (X slice {slice_idx})')\n",
    "        ax_row[0].axis('off')\n",
    "        \n",
    "        ax_row[1].imshow(data[:, slice_idx, :], cmap='tab20')\n",
    "        ax_row[1].set_title(f'{label} (Y slice {slice_idx})')\n",
    "        ax_row[1].axis('off')\n",
    "        \n",
    "        ax_row[2].imshow(data[:, :, slice_idx], cmap='tab20')\n",
    "        ax_row[2].set_title(f'{label} (Z slice {slice_idx})')\n",
    "        ax_row[2].axis('off')\n",
    "    \n",
    "    accuracy = (original == reconstructed).mean()\n",
    "    plt.suptitle(f'Reconstruction Accuracy: {accuracy:.1%}', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{OUTPUT_DIR}/reconstruction_{idx}.png\", dpi=150)\n",
    "    plt.show()\n",
    "    return accuracy\n",
    "\n",
    "for i in range(3):\n",
    "    acc = visualize_reconstruction(model, val_dataset, device, idx=i)\n",
    "    print(f\"Sample {i}: {acc:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 19: Analyze Codebook\n",
    "# ============================================================\n",
    "\n",
    "@torch.no_grad()\n",
    "def analyze_codebook(model, loader, device):\n",
    "    model.eval()\n",
    "    all_indices = []\n",
    "    \n",
    "    for batch in tqdm(loader, desc=\"Analyzing\"):\n",
    "        batch = batch.to(device)\n",
    "        outputs = model(batch)\n",
    "        all_indices.append(outputs[\"indices\"].cpu().view(-1))\n",
    "    \n",
    "    all_indices = torch.cat(all_indices)\n",
    "    usage = torch.bincount(all_indices, minlength=NUM_CODEBOOK_ENTRIES)\n",
    "    return (usage.float() / usage.sum()).numpy()\n",
    "\n",
    "codebook_usage = analyze_codebook(model, val_loader, device)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.bar(range(NUM_CODEBOOK_ENTRIES), sorted(codebook_usage, reverse=True))\n",
    "ax.set_xlabel(\"Codebook Entry (sorted)\")\n",
    "ax.set_ylabel(\"Usage Frequency\")\n",
    "ax.set_title(\"Codebook Usage Distribution\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "ax = axes[1]\n",
    "used_codes = (codebook_usage > 0).sum()\n",
    "top10 = sum(sorted(codebook_usage, reverse=True)[:10])\n",
    "stats = f\"\"\"Codebook Statistics:\n",
    "\n",
    "Total codes: {NUM_CODEBOOK_ENTRIES}\n",
    "Used codes: {used_codes} ({used_codes/NUM_CODEBOOK_ENTRIES:.1%})\n",
    "Dead codes: {NUM_CODEBOOK_ENTRIES - used_codes}\n",
    "\n",
    "Top 10 codes: {top10:.1%}\n",
    "Max usage: {max(codebook_usage):.3%}\n",
    "\"\"\"\n",
    "ax.text(0.1, 0.5, stats, transform=ax.transAxes, fontsize=12, verticalalignment='center', fontfamily='monospace')\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/codebook_analysis.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 20: Summary\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VQ-VAE v2 TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nKey improvements:\")\n",
    "print(f\"  - EMA codebook updates (decay={EMA_DECAY})\")\n",
    "print(f\"  - Dead code reset\")\n",
    "print(f\"  - Weighted loss (structure={STRUCTURE_WEIGHT}x)\")\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  - Structure accuracy: {history['val_struct_acc'][-1]:.1%}\")\n",
    "print(f\"  - Codebook usage: {history['codebook_usage'][-1]:.1%}\")\n",
    "print(f\"\\nOutput files: vqvae_best.pt, vqvae_final.pt, codebook.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
