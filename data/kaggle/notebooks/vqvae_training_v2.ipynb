{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# VQ-VAE v2: Fixed Training with EMA Codebook\n\n## Key Fixes from v1:\n\n1. **EMA Codebook Updates**: Instead of gradient descent on codebook, use exponential moving average\n2. **Dead Code Reset**: Reinitialize codebook entries that are never used\n3. **Weighted Loss**: Non-air blocks weighted 10x higher (combats class imbalance)\n4. **Higher Commitment Cost**: beta=0.5 instead of 0.25\n5. **Structure Accuracy Tracking**: Separate metrics for air vs non-air blocks\n\n## BUG FIX (2024-12): Correct Air Token Detection\n\n**Previous bug**: Code used `AIR_INDEX = 0`, but token 0 is `UNKNOWN_BLOCK`, not air!\n\n**The problem**: In Phase 0 validation, `val_acc` and `val_struct_acc` were identical to 15 decimal places because the \"non-air mask\" was checking `block_ids != 0` instead of actual air tokens.\n\n**The fix**: Minecraft has 3 types of air blocks:\n- Token 19: `minecraft:air` (most common)\n- Token 164: `minecraft:cave_air` (generated in caves)\n- Token 932: `minecraft:void_air` (below world)\n\nNow using `torch.isin(targets, AIR_TOKENS_TENSOR)` to correctly identify all air blocks.\n\n## Why v1 Failed (Codebook Collapse)\n\nIn v1, only 29 out of 512 codes were used because:\n- Air blocks dominate (~90% of voxels), so model optimized for predicting air\n- Unused codebook entries drifted away and were never recovered\n- Low commitment cost let encoder outputs \"hover\" between codes\n\n## Phase 0 Validation Results (Block2Vec Comparison)\n\nFrom validation runs comparing different embeddings:\n- **V1 embeddings**: 88.19% val accuracy, loss 1.006\n- **V2 embeddings**: 87.32% val accuracy, loss 1.140  \n- **Random embeddings**: 87.29% val accuracy, loss 1.101\n\n**Key insight**: Block embeddings barely affect VQ-VAE reconstruction (~0.9% difference).\nThe VQ-VAE learns its own latent space regardless of input embeddings."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: Imports and Setup\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 2: Configuration (UPDATED)\n# ============================================================\n\n# === Data Paths ===\nDATA_DIR = \"/kaggle/input/minecraft-schematics/minecraft_splits/splits/train\"\nVAL_DIR = \"/kaggle/input/minecraft-schematics/minecraft_splits/splits/val\"\nVOCAB_PATH = \"/kaggle/input/minecraft-schematics/tok2block.json\"\nEMBEDDINGS_PATH = \"/kaggle/input/block2vec-embeddings/block_embeddings.npy\"\nOUTPUT_DIR = \"/kaggle/working\"\n\n# === Model Architecture ===\nBLOCK_EMBEDDING_DIM = 32\nHIDDEN_DIMS = [64, 128, 256]\nLATENT_DIM = 256\nNUM_CODEBOOK_ENTRIES = 512  # Keep 512 - EMA + reset will use more\n\n# === KEY CHANGES ===\nCOMMITMENT_COST = 0.5       # Increased from 0.25 - stronger commitment\nEMA_DECAY = 0.99            # EMA decay rate for codebook updates\nSTRUCTURE_WEIGHT = 10.0     # Weight non-air blocks 10x higher\nUSE_FOCAL_LOSS = False      # Optional: focal loss for hard examples\n\n# === Training Hyperparameters ===\nEPOCHS = 30                 # Slightly more epochs for EMA to stabilize\nBATCH_SIZE = 8\nLEARNING_RATE = 1e-4\nWEIGHT_DECAY = 1e-5\nUSE_AMP = True\n\n# === Other ===\nSEED = 42\nNUM_WORKERS = 2\n\n# AIR TOKENS: There are 3 types of air in Minecraft!\n# - minecraft:air (most common, token 19)\n# - minecraft:cave_air (generated in caves, token 164)\n# - minecraft:void_air (below world, token 932)\n# BUG FIX: Previous version used AIR_INDEX=0 which is UNKNOWN_BLOCK, not air!\nAIR_TOKENS = set()  # Will be populated from vocabulary in CELL 3\n\nprint(\"Configuration loaded (v2 with fixes)!\")\nprint(f\"  Key changes:\")\nprint(f\"    - EMA codebook updates (decay={EMA_DECAY})\")\nprint(f\"    - Dead code reset\")\nprint(f\"    - Structure weight: {STRUCTURE_WEIGHT}x for non-air blocks\")\nprint(f\"    - Commitment cost: {COMMITMENT_COST}\")\nprint(f\"    - FIXED: Now tracking ALL air tokens (air, cave_air, void_air)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 3: Load Vocabulary and Pre-trained Embeddings\n# ============================================================\n\nwith open(VOCAB_PATH, 'r') as f:\n    tok2block = {int(k): v for k, v in json.load(f).items()}\n\nVOCAB_SIZE = len(tok2block)\nprint(f\"Vocabulary size: {VOCAB_SIZE} block types\")\n\n# Find ALL air block tokens (air, cave_air, void_air)\n# BUG FIX: Previous code only found one air token and used AIR_INDEX=0\n# Token 0 is actually UNKNOWN_BLOCK, not air!\nfor tok, block in tok2block.items():\n    block_lower = block.lower()\n    # Match 'air' but exclude 'stairs' (e.g., oak_stairs)\n    if 'air' in block_lower and 'stair' not in block_lower:\n        AIR_TOKENS.add(tok)\n        print(f\"  Air token: {tok} = '{block}'\")\n\nprint(f\"\\nTotal air tokens found: {len(AIR_TOKENS)}\")\nif len(AIR_TOKENS) == 0:\n    print(\"WARNING: No air tokens found! Check vocabulary.\")\nelif len(AIR_TOKENS) < 3:\n    print(\"NOTE: Expected 3 air types (air, cave_air, void_air)\")\n\n# Convert to tensor for efficient lookup during training\nAIR_TOKENS_TENSOR = torch.tensor(list(AIR_TOKENS), dtype=torch.long)\nprint(f\"Air tokens tensor: {AIR_TOKENS_TENSOR.tolist()}\")\n\npretrained_embeddings = np.load(EMBEDDINGS_PATH)\nprint(f\"Loaded embeddings: {pretrained_embeddings.shape}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: Dataset Class (unchanged)\n",
    "# ============================================================\n",
    "\n",
    "class VQVAEDataset(Dataset):\n",
    "    def __init__(self, data_dir: str, augment: bool = False, seed: int = 42):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.augment = augment\n",
    "        self.rng = random.Random(seed)\n",
    "        self.h5_files = sorted(self.data_dir.glob(\"*.h5\"))\n",
    "        if not self.h5_files:\n",
    "            raise ValueError(f\"No H5 files found in {data_dir}\")\n",
    "        print(f\"Found {len(self.h5_files)} structures in {data_dir}\")\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.h5_files)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        h5_path = self.h5_files[idx]\n",
    "        with h5py.File(h5_path, 'r') as f:\n",
    "            key = list(f.keys())[0]\n",
    "            structure = f[key][:].astype(np.int64)\n",
    "        \n",
    "        if self.augment:\n",
    "            k = self.rng.randint(0, 3)\n",
    "            if k > 0:\n",
    "                structure = np.rot90(structure, k=k, axes=(0, 2))\n",
    "            if self.rng.random() > 0.5:\n",
    "                structure = np.flip(structure, axis=2)\n",
    "            structure = np.ascontiguousarray(structure)\n",
    "        \n",
    "        return torch.from_numpy(structure).long()\n",
    "\n",
    "train_dataset = VQVAEDataset(DATA_DIR, augment=True, seed=SEED)\n",
    "val_dataset = VQVAEDataset(VAL_DIR, augment=False, seed=SEED)\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: Create DataLoaders\n",
    "# ============================================================\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=(device == \"cuda\"),\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=(device == \"cuda\"),\n",
    ")\n",
    "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: EMA Vector Quantizer (NEW!)\n",
    "\n",
    "The key fix: instead of learning the codebook via gradient descent, we update it using **Exponential Moving Average**:\n",
    "\n",
    "```\n",
    "For each codebook entry i:\n",
    "   N_i = decay * N_i + (1-decay) * (count of assignments to i)\n",
    "   m_i = decay * m_i + (1-decay) * (sum of encoder outputs assigned to i)\n",
    "   codebook[i] = m_i / N_i\n",
    "```\n",
    "\n",
    "This is more stable and prevents codebook collapse.\n",
    "\n",
    "We also **reset dead codes** - if a code isn't used, reinitialize it to a random encoder output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: EMA Vector Quantizer (KEY FIX!)\n",
    "# ============================================================\n",
    "\n",
    "class VectorQuantizerEMA(nn.Module):\n",
    "    \"\"\"\n",
    "    Vector Quantization with EMA codebook updates.\n",
    "    \n",
    "    Key improvements over gradient-based VQ:\n",
    "    1. EMA updates are more stable\n",
    "    2. Dead code reset prevents codebook collapse\n",
    "    3. No gradient on codebook - only commitment loss on encoder\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_embeddings: int = 512,\n",
    "        embedding_dim: int = 256,\n",
    "        commitment_cost: float = 0.5,\n",
    "        decay: float = 0.99,\n",
    "        epsilon: float = 1e-5,\n",
    "        dead_code_threshold: float = 0.01,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.commitment_cost = commitment_cost\n",
    "        self.decay = decay\n",
    "        self.epsilon = epsilon\n",
    "        self.dead_code_threshold = dead_code_threshold\n",
    "        \n",
    "        # Codebook (not a learnable parameter - updated via EMA)\n",
    "        self.register_buffer(\"codebook\", torch.randn(num_embeddings, embedding_dim))\n",
    "        self.register_buffer(\"ema_cluster_size\", torch.zeros(num_embeddings))\n",
    "        self.register_buffer(\"ema_embed_sum\", torch.randn(num_embeddings, embedding_dim))\n",
    "        self.register_buffer(\"initialized\", torch.tensor(False))\n",
    "        self.register_buffer(\"usage_count\", torch.zeros(num_embeddings))\n",
    "    \n",
    "    def _init_codebook(self, flat_z_e: torch.Tensor):\n",
    "        \"\"\"Initialize codebook from first batch of encoder outputs.\"\"\"\n",
    "        n_samples = flat_z_e.shape[0]\n",
    "        if n_samples >= self.num_embeddings:\n",
    "            indices = torch.randperm(n_samples, device=flat_z_e.device)[:self.num_embeddings]\n",
    "            self.codebook.data.copy_(flat_z_e[indices])\n",
    "        else:\n",
    "            self.codebook.data[:n_samples].copy_(flat_z_e)\n",
    "        \n",
    "        self.ema_cluster_size.fill_(1.0)\n",
    "        self.ema_embed_sum.data.copy_(self.codebook.data)\n",
    "        self.initialized.fill_(True)\n",
    "        print(\"Codebook initialized from encoder outputs!\")\n",
    "    \n",
    "    def _reset_dead_codes(self, flat_z_e: torch.Tensor, encoding_indices: torch.Tensor):\n",
    "        \"\"\"Reset codebook entries that are rarely used.\"\"\"\n",
    "        batch_usage = torch.bincount(\n",
    "            encoding_indices.view(-1), minlength=self.num_embeddings\n",
    "        ).float()\n",
    "        \n",
    "        self.usage_count.data.mul_(self.decay).add_(batch_usage, alpha=1 - self.decay)\n",
    "        \n",
    "        avg_usage = self.usage_count.sum() / self.num_embeddings\n",
    "        dead_mask = self.usage_count < (avg_usage * self.dead_code_threshold)\n",
    "        n_dead = dead_mask.sum().item()\n",
    "        \n",
    "        if n_dead > 0 and flat_z_e.shape[0] > 0:\n",
    "            n_samples = min(int(n_dead), flat_z_e.shape[0])\n",
    "            indices = torch.randperm(flat_z_e.shape[0], device=flat_z_e.device)[:n_samples]\n",
    "            samples = flat_z_e[indices]\n",
    "            dead_indices = torch.where(dead_mask)[0][:n_samples]\n",
    "            \n",
    "            self.codebook.data[dead_indices] = samples\n",
    "            self.ema_cluster_size.data[dead_indices] = 1.0\n",
    "            self.ema_embed_sum.data[dead_indices] = samples\n",
    "            self.usage_count.data[dead_indices] = avg_usage\n",
    "        \n",
    "        return n_dead\n",
    "    \n",
    "    def forward(self, z_e: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        # Reshape to [N, C]\n",
    "        z_e_permuted = z_e.permute(0, 2, 3, 4, 1).contiguous()\n",
    "        flat_z_e = z_e_permuted.view(-1, self.embedding_dim)\n",
    "        \n",
    "        # Initialize codebook from first batch\n",
    "        if not self.initialized and self.training:\n",
    "            self._init_codebook(flat_z_e)\n",
    "        \n",
    "        # Find nearest codebook entry\n",
    "        z_e_sq = (flat_z_e ** 2).sum(dim=1, keepdim=True)\n",
    "        codebook_sq = (self.codebook ** 2).sum(dim=1, keepdim=True).t()\n",
    "        dot_product = torch.mm(flat_z_e, self.codebook.t())\n",
    "        distances = z_e_sq + codebook_sq - 2 * dot_product\n",
    "        encoding_indices = distances.argmin(dim=1)\n",
    "        \n",
    "        z_q_flat = F.embedding(encoding_indices, self.codebook)\n",
    "        \n",
    "        # EMA update (only during training)\n",
    "        if self.training:\n",
    "            encodings = F.one_hot(encoding_indices, self.num_embeddings).float()\n",
    "            \n",
    "            batch_cluster_size = encodings.sum(0)\n",
    "            self.ema_cluster_size.data.mul_(self.decay).add_(\n",
    "                batch_cluster_size, alpha=1 - self.decay\n",
    "            )\n",
    "            \n",
    "            batch_embed_sum = encodings.t() @ flat_z_e\n",
    "            self.ema_embed_sum.data.mul_(self.decay).add_(\n",
    "                batch_embed_sum, alpha=1 - self.decay\n",
    "            )\n",
    "            \n",
    "            n = self.ema_cluster_size.sum()\n",
    "            smoothed_cluster_size = (\n",
    "                (self.ema_cluster_size + self.epsilon) /\n",
    "                (n + self.num_embeddings * self.epsilon) * n\n",
    "            )\n",
    "            \n",
    "            self.codebook.data.copy_(\n",
    "                self.ema_embed_sum / smoothed_cluster_size.unsqueeze(1)\n",
    "            )\n",
    "            \n",
    "            self._reset_dead_codes(flat_z_e, encoding_indices)\n",
    "        \n",
    "        z_q_permuted = z_q_flat.view(z_e_permuted.shape)\n",
    "        \n",
    "        # Only commitment loss (codebook updated via EMA)\n",
    "        commitment_loss = F.mse_loss(z_e_permuted, z_q_permuted.detach())\n",
    "        vq_loss = self.commitment_cost * commitment_loss\n",
    "        \n",
    "        # Straight-through\n",
    "        z_q_st = z_e_permuted + (z_q_permuted - z_e_permuted).detach()\n",
    "        z_q = z_q_st.permute(0, 4, 1, 2, 3).contiguous()\n",
    "        \n",
    "        encoding_indices = encoding_indices.view(z_e_permuted.shape[:-1])\n",
    "        \n",
    "        return z_q, vq_loss, encoding_indices\n",
    "    \n",
    "    def get_usage_stats(self) -> Tuple[int, float]:\n",
    "        \"\"\"Get codebook utilization.\"\"\"\n",
    "        avg_usage = self.usage_count.sum() / self.num_embeddings\n",
    "        used_mask = self.usage_count > (avg_usage * self.dead_code_threshold)\n",
    "        num_used = used_mask.sum().item()\n",
    "        return int(num_used), num_used / self.num_embeddings\n",
    "\n",
    "print(\"VectorQuantizerEMA defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: Residual Block (unchanged)\n",
    "# ============================================================\n",
    "\n",
    "class ResidualBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(in_channels)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.skip = nn.Conv3d(in_channels, out_channels, kernel_size=1) \\\n",
    "            if in_channels != out_channels else nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = self.skip(x)\n",
    "        out = F.relu(self.bn1(x))\n",
    "        out = self.conv1(out)\n",
    "        out = F.relu(self.bn2(out))\n",
    "        out = self.conv2(out)\n",
    "        return out + identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 8: Encoder (unchanged)\n",
    "# ============================================================\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels=32, hidden_dims=None, latent_dim=256):\n",
    "        super().__init__()\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [64, 128, 256]\n",
    "        \n",
    "        layers = []\n",
    "        current_channels = in_channels\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Conv3d(current_channels, hidden_dim, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm3d(hidden_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                ResidualBlock3D(hidden_dim, hidden_dim),\n",
    "            ])\n",
    "            current_channels = hidden_dim\n",
    "        layers.append(nn.Conv3d(current_channels, latent_dim, kernel_size=3, padding=1))\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 9: Decoder (unchanged)\n",
    "# ============================================================\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=256, hidden_dims=None, num_blocks=3717):\n",
    "        super().__init__()\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [256, 128, 64]\n",
    "        \n",
    "        layers = []\n",
    "        current_channels = latent_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                ResidualBlock3D(current_channels, current_channels),\n",
    "                nn.ConvTranspose3d(current_channels, hidden_dim, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm3d(hidden_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ])\n",
    "            current_channels = hidden_dim\n",
    "        layers.append(nn.Conv3d(current_channels, num_blocks, kernel_size=3, padding=1))\n",
    "        self.decoder = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, z_q):\n",
    "        return self.decoder(z_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 10: Full VQ-VAE Model (UPDATED with weighted loss)\n# ============================================================\n\nclass VQVAE(nn.Module):\n    def __init__(\n        self,\n        vocab_size: int,\n        block_embedding_dim: int,\n        hidden_dims: List[int],\n        latent_dim: int,\n        num_codebook_entries: int,\n        commitment_cost: float,\n        ema_decay: float,\n        pretrained_embeddings: np.ndarray,\n    ):\n        super().__init__()\n        \n        self.vocab_size = vocab_size\n        self.latent_dim = latent_dim\n        self.num_codebook_entries = num_codebook_entries\n        \n        # Block embeddings (frozen)\n        self.block_embeddings = nn.Embedding(vocab_size, block_embedding_dim)\n        self.block_embeddings.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n        self.block_embeddings.weight.requires_grad = False\n        \n        self.encoder = Encoder(in_channels=block_embedding_dim, hidden_dims=hidden_dims, latent_dim=latent_dim)\n        \n        # Use EMA quantizer!\n        self.quantizer = VectorQuantizerEMA(\n            num_embeddings=num_codebook_entries,\n            embedding_dim=latent_dim,\n            commitment_cost=commitment_cost,\n            decay=ema_decay,\n        )\n        \n        self.decoder = Decoder(latent_dim=latent_dim, hidden_dims=list(reversed(hidden_dims)), num_blocks=vocab_size)\n    \n    def forward(self, block_ids: torch.Tensor) -> Dict[str, Any]:\n        embedded = self.block_embeddings(block_ids)\n        embedded = embedded.permute(0, 4, 1, 2, 3).contiguous()\n        z_e = self.encoder(embedded)\n        z_q, vq_loss, indices = self.quantizer(z_e)\n        logits = self.decoder(z_q)\n        return {\"logits\": logits, \"vq_loss\": vq_loss, \"indices\": indices}\n    \n    def compute_loss(\n        self,\n        block_ids: torch.Tensor,\n        air_tokens_tensor: torch.Tensor,\n        structure_weight: float = 10.0,\n    ) -> Dict[str, torch.Tensor]:\n        \"\"\"\n        Compute loss with class imbalance handling.\n        Non-air blocks are weighted higher to combat air dominance.\n        \n        BUG FIX: Now uses air_tokens_tensor (all air types) instead of single air_index.\n        Previous version used air_index=0, but token 0 is UNKNOWN_BLOCK, not air!\n        Air tokens are: 19 (air), 164 (cave_air), 932 (void_air)\n        \"\"\"\n        outputs = self(block_ids)\n        \n        logits = outputs[\"logits\"].permute(0, 2, 3, 4, 1).contiguous()\n        logits_flat = logits.view(-1, self.vocab_size)\n        targets_flat = block_ids.view(-1)\n        \n        # Move air tokens to same device as targets\n        air_tokens_device = air_tokens_tensor.to(targets_flat.device)\n        \n        # Check if each target is ANY type of air (air, cave_air, void_air)\n        # Using torch.isin for efficient membership testing\n        is_air = torch.isin(targets_flat, air_tokens_device)\n        is_structure = ~is_air\n        \n        # Weight non-air blocks higher\n        weights = torch.ones_like(targets_flat, dtype=torch.float32)\n        weights[is_structure] = structure_weight  # air=1, structure=10\n        \n        # Weighted cross-entropy\n        ce_loss = F.cross_entropy(logits_flat, targets_flat, reduction='none')\n        reconstruction_loss = (weights * ce_loss).mean()\n        \n        total_loss = reconstruction_loss + outputs[\"vq_loss\"]\n        \n        # Detailed accuracy metrics\n        with torch.no_grad():\n            predictions = logits_flat.argmax(dim=1)\n            correct = (predictions == targets_flat).float()\n            accuracy = correct.mean()\n            \n            # Air accuracy (all air types combined)\n            air_accuracy = correct[is_air].mean() if is_air.sum() > 0 else torch.tensor(0.0)\n            \n            # Structure accuracy (non-air blocks) - THE KEY METRIC!\n            structure_accuracy = correct[is_structure].mean() if is_structure.sum() > 0 else torch.tensor(0.0)\n            \n            # Also track air percentage for debugging\n            air_percentage = is_air.float().mean()\n        \n        return {\n            \"loss\": total_loss,\n            \"reconstruction_loss\": reconstruction_loss,\n            \"vq_loss\": outputs[\"vq_loss\"],\n            \"accuracy\": accuracy,\n            \"air_accuracy\": air_accuracy,\n            \"structure_accuracy\": structure_accuracy,\n            \"air_percentage\": air_percentage,\n            \"indices\": outputs[\"indices\"],\n        }\n\nprint(\"VQVAE model defined (with EMA and weighted loss)!\")\nprint(\"BUG FIX: compute_loss now correctly identifies all air tokens\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 11: Create Model\n",
    "# ============================================================\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "model = VQVAE(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    block_embedding_dim=BLOCK_EMBEDDING_DIM,\n",
    "    hidden_dims=HIDDEN_DIMS,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    num_codebook_entries=NUM_CODEBOOK_ENTRIES,\n",
    "    commitment_cost=COMMITMENT_COST,\n",
    "    ema_decay=EMA_DECAY,\n",
    "    pretrained_embeddings=pretrained_embeddings,\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total params: {total_params:,}, Trainable: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 12: Test Forward Pass\n# ============================================================\n\nprint(\"Testing forward pass...\")\nwith torch.no_grad():\n    test_batch = torch.randint(0, VOCAB_SIZE, (2, 32, 32, 32)).to(device)\n    # Use AIR_TOKENS_TENSOR instead of AIR_INDEX\n    outputs = model.compute_loss(\n        test_batch, \n        air_tokens_tensor=AIR_TOKENS_TENSOR,\n        structure_weight=STRUCTURE_WEIGHT\n    )\n    print(f\"  Loss: {outputs['loss'].item():.4f}\")\n    print(f\"  Structure accuracy: {outputs['structure_accuracy'].item():.4f}\")\n    print(f\"  Air percentage: {outputs['air_percentage'].item():.2%}\")\nprint(\"Forward pass successful!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 13: Create Optimizer and Scaler\n",
    "# ============================================================\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP)\n",
    "\n",
    "print(f\"Optimizer: AdamW, Scheduler: ReduceLROnPlateau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 14: Training Functions (UPDATED)\n# ============================================================\n\ndef train_epoch(model, loader, optimizer, scaler, device, air_tokens_tensor, structure_weight, use_amp=True):\n    \"\"\"\n    Train for one epoch.\n    \n    BUG FIX: Now uses air_tokens_tensor (all air types) instead of single air_index.\n    \"\"\"\n    model.train()\n    metrics = {\"loss\": 0, \"recon\": 0, \"vq\": 0, \"acc\": 0, \"air_acc\": 0, \"struct_acc\": 0, \"air_pct\": 0}\n    all_indices = []\n    \n    for batch in tqdm(loader, desc=\"Training\", leave=False):\n        batch = batch.to(device)\n        \n        with torch.amp.autocast('cuda', enabled=use_amp):\n            outputs = model.compute_loss(\n                batch, \n                air_tokens_tensor=air_tokens_tensor,\n                structure_weight=structure_weight\n            )\n            loss = outputs[\"loss\"]\n        \n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        scaler.step(optimizer)\n        scaler.update()\n        \n        metrics[\"loss\"] += loss.item()\n        metrics[\"recon\"] += outputs[\"reconstruction_loss\"].item()\n        metrics[\"vq\"] += outputs[\"vq_loss\"].item()\n        metrics[\"acc\"] += outputs[\"accuracy\"].item()\n        metrics[\"air_acc\"] += outputs[\"air_accuracy\"].item()\n        metrics[\"struct_acc\"] += outputs[\"structure_accuracy\"].item()\n        metrics[\"air_pct\"] += outputs[\"air_percentage\"].item()\n        all_indices.append(outputs[\"indices\"].cpu())\n    \n    n = len(loader)\n    for k in metrics:\n        metrics[k] /= n\n    \n    # Codebook usage\n    all_indices = torch.cat([idx.view(-1) for idx in all_indices])\n    unique_codes = len(torch.unique(all_indices))\n    metrics[\"codebook_usage\"] = unique_codes / NUM_CODEBOOK_ENTRIES\n    \n    return metrics\n\n\n@torch.no_grad()\ndef validate(model, loader, device, air_tokens_tensor, structure_weight, use_amp=True):\n    \"\"\"\n    Validate model.\n    \n    BUG FIX: Now uses air_tokens_tensor (all air types) instead of single air_index.\n    \"\"\"\n    model.eval()\n    metrics = {\"loss\": 0, \"recon\": 0, \"acc\": 0, \"air_acc\": 0, \"struct_acc\": 0, \"air_pct\": 0}\n    \n    for batch in tqdm(loader, desc=\"Validating\", leave=False):\n        batch = batch.to(device)\n        \n        with torch.amp.autocast('cuda', enabled=use_amp):\n            outputs = model.compute_loss(\n                batch,\n                air_tokens_tensor=air_tokens_tensor,\n                structure_weight=structure_weight\n            )\n        \n        metrics[\"loss\"] += outputs[\"loss\"].item()\n        metrics[\"recon\"] += outputs[\"reconstruction_loss\"].item()\n        metrics[\"acc\"] += outputs[\"accuracy\"].item()\n        metrics[\"air_acc\"] += outputs[\"air_accuracy\"].item()\n        metrics[\"struct_acc\"] += outputs[\"structure_accuracy\"].item()\n        metrics[\"air_pct\"] += outputs[\"air_percentage\"].item()\n    \n    n = len(loader)\n    for k in metrics:\n        metrics[k] /= n\n    \n    return metrics\n\nprint(\"Training functions defined!\")\nprint(\"BUG FIX: Now using air_tokens_tensor for correct non-air accuracy\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 15: Main Training Loop (UPDATED)\n# ============================================================\n\nprint(\"=\" * 60)\nprint(\"Starting Training (v2 with EMA + weighted loss)\")\nprint(\"=\" * 60)\nprint(f\"Air tokens being excluded from structure accuracy: {AIR_TOKENS_TENSOR.tolist()}\")\n\nhistory = {\n    \"train_loss\": [], \"train_recon\": [], \"train_vq\": [],\n    \"train_acc\": [], \"train_air_acc\": [], \"train_struct_acc\": [],\n    \"val_loss\": [], \"val_recon\": [],\n    \"val_acc\": [], \"val_air_acc\": [], \"val_struct_acc\": [],\n    \"codebook_usage\": [], \"lr\": [],\n    \"train_air_pct\": [], \"val_air_pct\": [],  # Track air percentage\n}\n\nbest_val_loss = float(\"inf\")\nstart_time = time.time()\n\nfor epoch in range(EPOCHS):\n    epoch_start = time.time()\n    \n    train_metrics = train_epoch(\n        model, train_loader, optimizer, scaler, device,\n        air_tokens_tensor=AIR_TOKENS_TENSOR, structure_weight=STRUCTURE_WEIGHT, use_amp=USE_AMP\n    )\n    \n    val_metrics = validate(\n        model, val_loader, device,\n        air_tokens_tensor=AIR_TOKENS_TENSOR, structure_weight=STRUCTURE_WEIGHT, use_amp=USE_AMP\n    )\n    \n    scheduler.step(val_metrics[\"loss\"])\n    current_lr = optimizer.param_groups[0][\"lr\"]\n    \n    # Track history\n    history[\"train_loss\"].append(train_metrics[\"loss\"])\n    history[\"train_recon\"].append(train_metrics[\"recon\"])\n    history[\"train_vq\"].append(train_metrics[\"vq\"])\n    history[\"train_acc\"].append(train_metrics[\"acc\"])\n    history[\"train_air_acc\"].append(train_metrics[\"air_acc\"])\n    history[\"train_struct_acc\"].append(train_metrics[\"struct_acc\"])\n    history[\"train_air_pct\"].append(train_metrics[\"air_pct\"])\n    history[\"val_loss\"].append(val_metrics[\"loss\"])\n    history[\"val_recon\"].append(val_metrics[\"recon\"])\n    history[\"val_acc\"].append(val_metrics[\"acc\"])\n    history[\"val_air_acc\"].append(val_metrics[\"air_acc\"])\n    history[\"val_struct_acc\"].append(val_metrics[\"struct_acc\"])\n    history[\"val_air_pct\"].append(val_metrics[\"air_pct\"])\n    history[\"codebook_usage\"].append(train_metrics[\"codebook_usage\"])\n    history[\"lr\"].append(current_lr)\n    \n    if val_metrics[\"loss\"] < best_val_loss:\n        best_val_loss = val_metrics[\"loss\"]\n        torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_best.pt\")\n    \n    epoch_time = time.time() - epoch_start\n    print(\n        f\"Epoch {epoch+1:3d}/{EPOCHS} | \"\n        f\"Loss: {train_metrics['loss']:.3f} | \"\n        f\"Struct: {train_metrics['struct_acc']:.1%} | \"\n        f\"Val Struct: {val_metrics['struct_acc']:.1%} | \"\n        f\"Air%: {train_metrics['air_pct']:.1%} | \"\n        f\"CB: {train_metrics['codebook_usage']:.1%} | \"\n        f\"{epoch_time:.0f}s\"\n    )\n\ntotal_time = time.time() - start_time\nprint(f\"\\nTraining complete in {total_time/60:.1f} minutes\")\nprint(f\"\\nNOTE: Structure accuracy now correctly excludes ALL air blocks:\")\nprint(f\"  - Air tokens: {AIR_TOKENS_TENSOR.tolist()}\")\nprint(f\"  - Average air percentage: {np.mean(history['train_air_pct']):.1%}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 16: Save Results\n",
    "# ============================================================\n",
    "\n",
    "torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_final.pt\")\n",
    "codebook = model.quantizer.codebook.cpu().numpy()\n",
    "np.save(f\"{OUTPUT_DIR}/codebook.npy\", codebook)\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/training_history.json\", \"w\") as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(\"Results saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 17: Plot Training Curves (UPDATED)\n# ============================================================\n\nfig, axes = plt.subplots(2, 3, figsize=(18, 10))\n\n# Loss\nax = axes[0, 0]\nax.plot(history[\"train_loss\"], label=\"Train\")\nax.plot(history[\"val_loss\"], label=\"Val\")\nax.set_xlabel(\"Epoch\")\nax.set_ylabel(\"Total Loss\")\nax.set_title(\"Training and Validation Loss\")\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Structure Accuracy vs Overall (the key metric!)\nax = axes[0, 1]\nax.plot(history[\"train_acc\"], label=\"Train Overall\", linestyle=\"--\", alpha=0.5)\nax.plot(history[\"train_struct_acc\"], label=\"Train Structure\", linewidth=2)\nax.plot(history[\"val_acc\"], label=\"Val Overall\", linestyle=\"--\", alpha=0.5)\nax.plot(history[\"val_struct_acc\"], label=\"Val Structure\", linewidth=2)\nax.set_xlabel(\"Epoch\")\nax.set_ylabel(\"Accuracy\")\nax.set_title(\"Block Prediction Accuracy\\n(Structure = non-air blocks)\")\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Air vs Structure Accuracy\nax = axes[0, 2]\nax.plot(history[\"train_air_acc\"], label=\"Train Air\", linestyle=\"--\")\nax.plot(history[\"train_struct_acc\"], label=\"Train Structure\")\nax.plot(history[\"val_air_acc\"], label=\"Val Air\", linestyle=\"--\")\nax.plot(history[\"val_struct_acc\"], label=\"Val Structure\")\nax.set_xlabel(\"Epoch\")\nax.set_ylabel(\"Accuracy\")\nax.set_title(\"Air vs Structure Accuracy\\n(Should be DIFFERENT if fix worked)\")\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Loss Components\nax = axes[1, 0]\nax.plot(history[\"train_recon\"], label=\"Reconstruction\")\nax.plot(history[\"train_vq\"], label=\"VQ (commitment)\")\nax.set_xlabel(\"Epoch\")\nax.set_ylabel(\"Loss\")\nax.set_title(\"Loss Components\")\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Codebook Usage\nax = axes[1, 1]\nax.plot(history[\"codebook_usage\"], color=\"green\")\nax.axhline(y=1.0, color=\"red\", linestyle=\"--\", label=\"100% usage\")\nax.set_xlabel(\"Epoch\")\nax.set_ylabel(\"Fraction Used\")\nax.set_title(\"Codebook Utilization\")\nax.set_ylim(0, 1.1)\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Air Percentage (sanity check)\nax = axes[1, 2]\nax.plot(history[\"train_air_pct\"], label=\"Train\")\nax.plot(history[\"val_air_pct\"], label=\"Val\")\nax.set_xlabel(\"Epoch\")\nax.set_ylabel(\"Air Percentage\")\nax.set_title(f\"Air Block Percentage\\n(Expected ~85-95%)\")\nax.legend()\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(f\"{OUTPUT_DIR}/training_curves.png\", dpi=150)\nplt.show()\n\n# Sanity check: Structure accuracy should be DIFFERENT from overall accuracy\nprint(f\"\\n{'='*60}\")\nprint(\"SANITY CHECK: Air token detection\")\nprint(f\"{'='*60}\")\nprint(f\"Air tokens used: {sorted(AIR_TOKENS)}\")\nprint(f\"Average air percentage: {np.mean(history['train_air_pct']):.1%}\")\nprint(f\"\\nFinal accuracies:\")\nprint(f\"  Overall:   Train {history['train_acc'][-1]:.4f}, Val {history['val_acc'][-1]:.4f}\")\nprint(f\"  Structure: Train {history['train_struct_acc'][-1]:.4f}, Val {history['val_struct_acc'][-1]:.4f}\")\nprint(f\"  Air:       Train {history['train_air_acc'][-1]:.4f}, Val {history['val_air_acc'][-1]:.4f}\")\n\n# Check if fix worked\nif abs(history['val_acc'][-1] - history['val_struct_acc'][-1]) < 0.001:\n    print(\"\\n⚠️  WARNING: Overall and Structure accuracy are nearly identical!\")\n    print(\"    This suggests air detection may still be broken.\")\nelse:\n    print(\"\\n✓ SUCCESS: Structure accuracy differs from overall accuracy\")\n    print(\"    Air token detection is working correctly.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 18: Visualize Reconstructions\n",
    "# ============================================================\n",
    "\n",
    "def visualize_reconstruction(model, dataset, device, idx=0):\n",
    "    model.eval()\n",
    "    original = dataset[idx].unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(original)\n",
    "        reconstructed = outputs[\"logits\"].argmax(dim=1)\n",
    "    \n",
    "    original = original.cpu().numpy()[0]\n",
    "    reconstructed = reconstructed.cpu().numpy()[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    slice_idx = 16\n",
    "    \n",
    "    for i, (ax_row, data, label) in enumerate([\n",
    "        (axes[0], original, \"Original\"),\n",
    "        (axes[1], reconstructed, \"Reconstructed\")\n",
    "    ]):\n",
    "        ax_row[0].imshow(data[slice_idx, :, :], cmap='tab20')\n",
    "        ax_row[0].set_title(f'{label} (X slice {slice_idx})')\n",
    "        ax_row[0].axis('off')\n",
    "        \n",
    "        ax_row[1].imshow(data[:, slice_idx, :], cmap='tab20')\n",
    "        ax_row[1].set_title(f'{label} (Y slice {slice_idx})')\n",
    "        ax_row[1].axis('off')\n",
    "        \n",
    "        ax_row[2].imshow(data[:, :, slice_idx], cmap='tab20')\n",
    "        ax_row[2].set_title(f'{label} (Z slice {slice_idx})')\n",
    "        ax_row[2].axis('off')\n",
    "    \n",
    "    accuracy = (original == reconstructed).mean()\n",
    "    plt.suptitle(f'Reconstruction Accuracy: {accuracy:.1%}', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{OUTPUT_DIR}/reconstruction_{idx}.png\", dpi=150)\n",
    "    plt.show()\n",
    "    return accuracy\n",
    "\n",
    "for i in range(3):\n",
    "    acc = visualize_reconstruction(model, val_dataset, device, idx=i)\n",
    "    print(f\"Sample {i}: {acc:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 19: Analyze Codebook\n",
    "# ============================================================\n",
    "\n",
    "@torch.no_grad()\n",
    "def analyze_codebook(model, loader, device):\n",
    "    model.eval()\n",
    "    all_indices = []\n",
    "    \n",
    "    for batch in tqdm(loader, desc=\"Analyzing\"):\n",
    "        batch = batch.to(device)\n",
    "        outputs = model(batch)\n",
    "        all_indices.append(outputs[\"indices\"].cpu().view(-1))\n",
    "    \n",
    "    all_indices = torch.cat(all_indices)\n",
    "    usage = torch.bincount(all_indices, minlength=NUM_CODEBOOK_ENTRIES)\n",
    "    return (usage.float() / usage.sum()).numpy()\n",
    "\n",
    "codebook_usage = analyze_codebook(model, val_loader, device)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.bar(range(NUM_CODEBOOK_ENTRIES), sorted(codebook_usage, reverse=True))\n",
    "ax.set_xlabel(\"Codebook Entry (sorted)\")\n",
    "ax.set_ylabel(\"Usage Frequency\")\n",
    "ax.set_title(\"Codebook Usage Distribution\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "ax = axes[1]\n",
    "used_codes = (codebook_usage > 0).sum()\n",
    "top10 = sum(sorted(codebook_usage, reverse=True)[:10])\n",
    "stats = f\"\"\"Codebook Statistics:\n",
    "\n",
    "Total codes: {NUM_CODEBOOK_ENTRIES}\n",
    "Used codes: {used_codes} ({used_codes/NUM_CODEBOOK_ENTRIES:.1%})\n",
    "Dead codes: {NUM_CODEBOOK_ENTRIES - used_codes}\n",
    "\n",
    "Top 10 codes: {top10:.1%}\n",
    "Max usage: {max(codebook_usage):.3%}\n",
    "\"\"\"\n",
    "ax.text(0.1, 0.5, stats, transform=ax.transAxes, fontsize=12, verticalalignment='center', fontfamily='monospace')\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/codebook_analysis.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 20: Summary\n# ============================================================\n\nprint(\"=\" * 60)\nprint(\"VQ-VAE v2 TRAINING COMPLETE!\")\nprint(\"=\" * 60)\nprint(f\"\\nKey improvements:\")\nprint(f\"  - EMA codebook updates (decay={EMA_DECAY})\")\nprint(f\"  - Dead code reset\")\nprint(f\"  - Weighted loss (structure={STRUCTURE_WEIGHT}x)\")\nprint(f\"  - BUG FIX: Correct air token detection ({len(AIR_TOKENS)} air types)\")\nprint(f\"\\nAir tokens used: {sorted(AIR_TOKENS)}\")\nprint(f\"Average air percentage in data: {np.mean(history['train_air_pct']):.1%}\")\nprint(f\"\\nResults:\")\nprint(f\"  - Overall accuracy: {history['val_acc'][-1]:.1%}\")\nprint(f\"  - Structure accuracy (non-air): {history['val_struct_acc'][-1]:.1%}\")\nprint(f\"  - Air accuracy: {history['val_air_acc'][-1]:.1%}\")\nprint(f\"  - Codebook usage: {history['codebook_usage'][-1]:.1%}\")\nprint(f\"\\nOutput files: vqvae_best.pt, vqvae_final.pt, codebook.npy\")\nprint(f\"\\nNOTE: Structure accuracy should now differ from overall accuracy!\")\nprint(f\"      If they're still identical, check that AIR_TOKENS contains the right values.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}