{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Phase 0: VQ-VAE Embedding Validation\n\n## Critical Question\n\n**Do Block2Vec embeddings actually help VQ-VAE, or would random embeddings work just as well?**\n\nBefore spending more time optimizing Block2Vec, we need to answer this fundamental question.\n\n## Experiment Design\n\nWe train three identical mini VQ-VAEs with different input embeddings:\n\n| Condition | Embeddings | Purpose |\n|-----------|------------|---------|\n| **V1** | Block2Vec V1 (skip-gram) | Our baseline trained embeddings |\n| **V2** | Block2Vec V2 (hybrid) | Our improved embeddings |\n| **Random** | Random initialization | Null hypothesis - no learned structure |\n\n## Success Criteria\n\n- **V1/V2 >> Random (>20% better on STRUCTURE accuracy)**: Block2Vec is useful\n- **V1/V2 ≈ Random**: Block2Vec doesn't matter for reconstruction\n- **V1 > V2**: The hybrid approach was harmful, use V1\n\n## BUG FIX (2024-12): Correct Non-Air Accuracy\n\n**Previous bug**: Code used `block_ids != 0` to find non-air blocks, but token 0 is `UNKNOWN_BLOCK`, not air!\n\n**Why this matters**: ~90% of voxels are air. If we include air in accuracy:\n- Predicting air everywhere ≈ 90% accuracy\n- The 88% accuracy we saw tells us almost nothing about structure reconstruction\n\n**The fix**: Minecraft has 3 types of air:\n- Token 19: `minecraft:air`\n- Token 164: `minecraft:cave_air`  \n- Token 932: `minecraft:void_air`\n\nNow using `torch.isin(targets, AIR_TOKENS)` to correctly identify all air blocks.\n\n## Mini VQ-VAE Config\n\nTo make this fast (~2 hours total for all 3 conditions):\n- 10 epochs (instead of 25)\n- Smaller hidden dims [32, 64, 128] (instead of [64, 128, 256])\n- Same codebook size (512)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: Imports and Setup\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 2: Configuration\n# ============================================================\n\n# === Data Paths ===\nDATA_DIR = \"/kaggle/input/minecraft-schematics/minecraft_splits/splits/train\"\nVAL_DIR = \"/kaggle/input/minecraft-schematics/minecraft_splits/splits/val\"\nVOCAB_PATH = \"/kaggle/input/minecraft-schematics/tok2block.json\"\n\n# Embeddings paths\nV1_EMBEDDINGS_PATH = \"/kaggle/input/block2vec-embeddings/block_embeddings.npy\"\nV2_EMBEDDINGS_PATH = \"/kaggle/input/block2vec-v2/block_embeddings_v2.npy\"\nV2_MAPPING_PATH = \"/kaggle/input/block2vec-v2/original_to_collapsed.json\"\n\nOUTPUT_DIR = \"/kaggle/working\"\n\n# === Mini Model Architecture (faster training) ===\nBLOCK_EMBEDDING_DIM = 32\nHIDDEN_DIMS = [32, 64, 128]  # Smaller than full model\nLATENT_DIM = 128             # Smaller than full model (256)\nNUM_CODEBOOK_ENTRIES = 512\nCOMMITMENT_COST = 0.25\n\n# === Training (faster) ===\nEPOCHS = 10\nBATCH_SIZE = 4  # Reduced from 16 - cross_entropy on 32x32x32x3717 is memory-intensive\nLEARNING_RATE = 3e-4\nUSE_AMP = True\nGRAD_ACCUM_STEPS = 4  # Accumulate gradients to simulate larger effective batch\n\n# === Other ===\nSEED = 42\nNUM_WORKERS = 2\n\nprint(\"Mini VQ-VAE Configuration:\")\nprint(f\"  Hidden dims: {HIDDEN_DIMS}\")\nprint(f\"  Latent dim: {LATENT_DIM}\")\nprint(f\"  Epochs: {EPOCHS}\")\nprint(f\"  Batch size: {BATCH_SIZE} (effective: {BATCH_SIZE * GRAD_ACCUM_STEPS})\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 3: Load Vocabulary and Prepare Embeddings\n# ============================================================\n\n# Load vocabulary\nwith open(VOCAB_PATH, 'r') as f:\n    tok2block = {int(k): v for k, v in json.load(f).items()}\n\nVOCAB_SIZE = len(tok2block)\nprint(f\"Vocabulary size: {VOCAB_SIZE} block types\")\n\n# ============================================================\n# BUG FIX: Find ALL air tokens (not just token 0!)\n# Token 0 is UNKNOWN_BLOCK, not air!\n# Air tokens are: 19 (air), 164 (cave_air), 932 (void_air)\n# ============================================================\nAIR_TOKENS = set()\nfor tok, block in tok2block.items():\n    block_lower = block.lower()\n    if 'air' in block_lower and 'stair' not in block_lower:\n        AIR_TOKENS.add(tok)\n        print(f\"  Found air token: {tok} = '{block}'\")\n\nAIR_TOKENS_TENSOR = torch.tensor(sorted(AIR_TOKENS), dtype=torch.long)\nprint(f\"\\nAir tokens: {AIR_TOKENS_TENSOR.tolist()}\")\nprint(f\"Total air types: {len(AIR_TOKENS)}\")\n\n# Load V1 embeddings (3717, 32)\nv1_embeddings = np.load(V1_EMBEDDINGS_PATH)\nprint(f\"\\nV1 embeddings: {v1_embeddings.shape}\")\n\n# Load V2 embeddings (1007, 32) and mapping\nv2_collapsed = np.load(V2_EMBEDDINGS_PATH)\nwith open(V2_MAPPING_PATH, 'r') as f:\n    original_to_collapsed = {int(k): int(v) for k, v in json.load(f).items()}\nprint(f\"V2 collapsed embeddings: {v2_collapsed.shape}\")\n\n# Expand V2 to full vocabulary using mapping\n# Each original token maps to a collapsed token\nv2_embeddings = np.zeros((VOCAB_SIZE, BLOCK_EMBEDDING_DIM), dtype=np.float32)\nfor orig_tok in range(VOCAB_SIZE):\n    if orig_tok in original_to_collapsed:\n        collapsed_tok = original_to_collapsed[orig_tok]\n        if collapsed_tok < len(v2_collapsed):\n            v2_embeddings[orig_tok] = v2_collapsed[collapsed_tok]\n\nprint(f\"V2 expanded embeddings: {v2_embeddings.shape}\")\n\n# Create random embeddings (same scale as V1)\nnp.random.seed(SEED)\nv1_std = v1_embeddings.std()\nrandom_embeddings = np.random.randn(VOCAB_SIZE, BLOCK_EMBEDDING_DIM).astype(np.float32) * v1_std\nprint(f\"Random embeddings: {random_embeddings.shape} (std={v1_std:.4f})\")\n\n# Store all embedding variants\nEMBEDDING_VARIANTS = {\n    'V1': v1_embeddings,\n    'V2': v2_embeddings,\n    'Random': random_embeddings,\n}\n\nprint(\"\\nAll embedding variants prepared!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: Dataset\n",
    "# ============================================================\n",
    "\n",
    "class VQVAEDataset(Dataset):\n",
    "    def __init__(self, data_dir: str, seed: int = 42):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.h5_files = sorted(self.data_dir.glob(\"*.h5\"))\n",
    "        if not self.h5_files:\n",
    "            raise ValueError(f\"No H5 files found in {data_dir}\")\n",
    "        print(f\"Found {len(self.h5_files)} structures in {data_dir}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.h5_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.h5_files[idx], 'r') as f:\n",
    "            key = list(f.keys())[0]\n",
    "            structure = f[key][:].astype(np.int64)\n",
    "        return torch.from_numpy(structure).long()\n",
    "\n",
    "\n",
    "train_dataset = VQVAEDataset(DATA_DIR, seed=SEED)\n",
    "val_dataset = VQVAEDataset(VAL_DIR, seed=SEED)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 5: Mini VQ-VAE Model\n# ============================================================\n\nclass ResidualBlock3D(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.conv1 = nn.Conv3d(channels, channels, 3, padding=1)\n        self.conv2 = nn.Conv3d(channels, channels, 3, padding=1)\n        self.bn1 = nn.BatchNorm3d(channels)\n        self.bn2 = nn.BatchNorm3d(channels)\n    \n    def forward(self, x):\n        residual = x\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.bn2(self.conv2(x))\n        return F.relu(x + residual)\n\n\nclass MiniVQVAE(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dims, latent_dim, \n                 num_codes, commitment_cost, pretrained_embeddings):\n        super().__init__()\n        self.vocab_size = vocab_size\n        self.latent_dim = latent_dim\n        self.num_codes = num_codes\n        self.commitment_cost = commitment_cost\n        \n        # Block embeddings (frozen)\n        self.block_emb = nn.Embedding(vocab_size, embedding_dim)\n        self.block_emb.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n        self.block_emb.weight.requires_grad = False\n        \n        # Encoder\n        enc_layers = []\n        in_ch = embedding_dim\n        for h_dim in hidden_dims:\n            enc_layers.extend([\n                nn.Conv3d(in_ch, h_dim, 4, stride=2, padding=1),\n                nn.BatchNorm3d(h_dim),\n                nn.ReLU(inplace=True),\n                ResidualBlock3D(h_dim),\n            ])\n            in_ch = h_dim\n        enc_layers.append(nn.Conv3d(in_ch, latent_dim, 3, padding=1))\n        self.encoder = nn.Sequential(*enc_layers)\n        \n        # Codebook\n        self.codebook = nn.Embedding(num_codes, latent_dim)\n        self.codebook.weight.data.uniform_(-1/num_codes, 1/num_codes)\n        \n        # Decoder\n        dec_layers = []\n        in_ch = latent_dim\n        for h_dim in reversed(hidden_dims):\n            dec_layers.extend([\n                ResidualBlock3D(in_ch),\n                nn.ConvTranspose3d(in_ch, h_dim, 4, stride=2, padding=1),\n                nn.BatchNorm3d(h_dim),\n                nn.ReLU(inplace=True),\n            ])\n            in_ch = h_dim\n        dec_layers.append(nn.Conv3d(in_ch, vocab_size, 3, padding=1))\n        self.decoder = nn.Sequential(*dec_layers)\n    \n    def quantize(self, z_e):\n        # z_e: [B, C, D, H, W]\n        z_e_perm = z_e.permute(0, 2, 3, 4, 1).contiguous()  # [B, D, H, W, C]\n        flat = z_e_perm.view(-1, self.latent_dim)\n        \n        # Distances\n        d = (flat**2).sum(1, keepdim=True) + \\\n            (self.codebook.weight**2).sum(1) - \\\n            2 * flat @ self.codebook.weight.t()\n        \n        indices = d.argmin(1)\n        z_q_flat = self.codebook(indices)\n        z_q_perm = z_q_flat.view(z_e_perm.shape)\n        \n        # Losses\n        codebook_loss = F.mse_loss(z_q_perm, z_e_perm.detach())\n        commit_loss = F.mse_loss(z_e_perm, z_q_perm.detach())\n        vq_loss = codebook_loss + self.commitment_cost * commit_loss\n        \n        # Straight-through\n        z_q_st = z_e_perm + (z_q_perm - z_e_perm).detach()\n        z_q = z_q_st.permute(0, 4, 1, 2, 3).contiguous()\n        \n        return z_q, vq_loss, indices.view(z_e_perm.shape[:-1])\n    \n    def forward(self, block_ids):\n        # Embed\n        x = self.block_emb(block_ids)  # [B, 32, 32, 32, emb]\n        x = x.permute(0, 4, 1, 2, 3).contiguous()  # [B, emb, 32, 32, 32]\n        \n        # Encode\n        z_e = self.encoder(x)\n        \n        # Quantize\n        z_q, vq_loss, indices = self.quantize(z_e)\n        \n        # Decode\n        logits = self.decoder(z_q)\n        \n        return {'logits': logits, 'vq_loss': vq_loss, 'indices': indices}\n    \n    def compute_loss(self, block_ids, air_tokens_tensor):\n        \"\"\"\n        Compute loss and metrics.\n        \n        BUG FIX: Now uses air_tokens_tensor to correctly identify air blocks.\n        Previous version used `block_ids != 0`, but token 0 is UNKNOWN_BLOCK!\n        Air tokens are: 19 (air), 164 (cave_air), 932 (void_air)\n        \"\"\"\n        out = self(block_ids)\n        \n        # Reconstruction loss\n        logits = out['logits'].permute(0, 2, 3, 4, 1).contiguous()\n        recon_loss = F.cross_entropy(logits.view(-1, self.vocab_size), block_ids.view(-1))\n        \n        total_loss = recon_loss + out['vq_loss']\n        \n        # Accuracy metrics\n        with torch.no_grad():\n            preds = logits.argmax(-1)\n            targets_flat = block_ids.view(-1)\n            preds_flat = preds.view(-1)\n            \n            # Overall accuracy\n            correct = (preds_flat == targets_flat).float()\n            acc = correct.mean()\n            \n            # Move air tokens to same device\n            air_tokens_device = air_tokens_tensor.to(targets_flat.device)\n            \n            # Find air and non-air blocks using torch.isin\n            is_air = torch.isin(targets_flat, air_tokens_device)\n            is_structure = ~is_air\n            \n            # Air accuracy\n            if is_air.sum() > 0:\n                air_acc = correct[is_air].mean()\n            else:\n                air_acc = torch.tensor(0.0, device=block_ids.device)\n            \n            # Structure accuracy (non-air) - THE KEY METRIC!\n            if is_structure.sum() > 0:\n                struct_acc = correct[is_structure].mean()\n            else:\n                struct_acc = torch.tensor(0.0, device=block_ids.device)\n            \n            # Track air percentage for sanity check\n            air_pct = is_air.float().mean()\n        \n        return {\n            'loss': total_loss,\n            'recon_loss': recon_loss,\n            'vq_loss': out['vq_loss'],\n            'accuracy': acc,\n            'air_accuracy': air_acc,\n            'struct_accuracy': struct_acc,\n            'air_percentage': air_pct,\n            'indices': out['indices'],\n        }\n\n\nprint(\"MiniVQVAE defined!\")\nprint(\"BUG FIX: compute_loss now correctly identifies all air tokens\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 6: Training Functions\n# ============================================================\n\ndef train_epoch(model, loader, optimizer, scaler, device, air_tokens_tensor):\n    \"\"\"Train for one epoch.\"\"\"\n    model.train()\n    metrics = {'loss': 0, 'recon': 0, 'vq': 0, 'acc': 0, 'air_acc': 0, 'struct_acc': 0, 'air_pct': 0}\n    n = 0\n    \n    optimizer.zero_grad()\n    \n    for batch_idx, batch in enumerate(tqdm(loader, desc=\"Train\", leave=False)):\n        batch = batch.to(device)\n        \n        with torch.amp.autocast('cuda', enabled=USE_AMP):\n            out = model.compute_loss(batch, air_tokens_tensor)\n            # Scale loss for gradient accumulation\n            loss = out['loss'] / GRAD_ACCUM_STEPS\n        \n        scaler.scale(loss).backward()\n        \n        # Step optimizer every GRAD_ACCUM_STEPS batches\n        if (batch_idx + 1) % GRAD_ACCUM_STEPS == 0:\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n        \n        metrics['loss'] += out['loss'].item()\n        metrics['recon'] += out['recon_loss'].item()\n        metrics['vq'] += out['vq_loss'].item()\n        metrics['acc'] += out['accuracy'].item()\n        metrics['air_acc'] += out['air_accuracy'].item()\n        metrics['struct_acc'] += out['struct_accuracy'].item()\n        metrics['air_pct'] += out['air_percentage'].item()\n        n += 1\n    \n    # Handle remaining gradients if loader length not divisible by GRAD_ACCUM_STEPS\n    if len(loader) % GRAD_ACCUM_STEPS != 0:\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n    \n    return {k: v/n for k, v in metrics.items()}\n\n\n@torch.no_grad()\ndef validate(model, loader, device, air_tokens_tensor):\n    \"\"\"Validate model.\"\"\"\n    model.eval()\n    metrics = {'loss': 0, 'recon': 0, 'acc': 0, 'air_acc': 0, 'struct_acc': 0, 'air_pct': 0}\n    n = 0\n    \n    for batch in tqdm(loader, desc=\"Val\", leave=False):\n        batch = batch.to(device)\n        \n        with torch.amp.autocast('cuda', enabled=USE_AMP):\n            out = model.compute_loss(batch, air_tokens_tensor)\n        \n        metrics['loss'] += out['loss'].item()\n        metrics['recon'] += out['recon_loss'].item()\n        metrics['acc'] += out['accuracy'].item()\n        metrics['air_acc'] += out['air_accuracy'].item()\n        metrics['struct_acc'] += out['struct_accuracy'].item()\n        metrics['air_pct'] += out['air_percentage'].item()\n        n += 1\n    \n    return {k: v/n for k, v in metrics.items()}\n\n\nprint(\"Training functions defined!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 7: Run Experiment for One Embedding Type\n# ============================================================\n\ndef run_experiment(name, embeddings, air_tokens_tensor):\n    \"\"\"Train and evaluate VQ-VAE with given embeddings.\"\"\"\n    print(f\"\\n{'='*60}\")\n    print(f\"Training with {name} embeddings\")\n    print(f\"{'='*60}\")\n    print(f\"Air tokens: {air_tokens_tensor.tolist()}\")\n    \n    # Clear GPU memory from previous experiment\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        torch.cuda.synchronize()\n    \n    # Set seeds for reproducibility\n    torch.manual_seed(SEED)\n    np.random.seed(SEED)\n    random.seed(SEED)\n    \n    # Create model\n    model = MiniVQVAE(\n        vocab_size=VOCAB_SIZE,\n        embedding_dim=BLOCK_EMBEDDING_DIM,\n        hidden_dims=HIDDEN_DIMS,\n        latent_dim=LATENT_DIM,\n        num_codes=NUM_CODEBOOK_ENTRIES,\n        commitment_cost=COMMITMENT_COST,\n        pretrained_embeddings=embeddings,\n    ).to(device)\n    \n    # Count params\n    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f\"Trainable parameters: {trainable:,}\")\n    \n    # Print GPU memory status\n    if torch.cuda.is_available():\n        allocated = torch.cuda.memory_allocated() / 1e9\n        reserved = torch.cuda.memory_reserved() / 1e9\n        print(f\"GPU memory: {allocated:.2f} GB allocated, {reserved:.2f} GB reserved\")\n    \n    # Optimizer\n    optimizer = optim.AdamW(\n        filter(lambda p: p.requires_grad, model.parameters()),\n        lr=LEARNING_RATE,\n    )\n    scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP)\n    \n    # Training loop - now tracking air_acc and air_pct\n    history = {\n        'train_loss': [], 'train_acc': [], 'train_air_acc': [], 'train_struct_acc': [], 'train_air_pct': [],\n        'val_loss': [], 'val_acc': [], 'val_air_acc': [], 'val_struct_acc': [], 'val_air_pct': [],\n    }\n    \n    start_time = time.time()\n    \n    for epoch in range(EPOCHS):\n        train_metrics = train_epoch(model, train_loader, optimizer, scaler, device, air_tokens_tensor)\n        val_metrics = validate(model, val_loader, device, air_tokens_tensor)\n        \n        history['train_loss'].append(train_metrics['loss'])\n        history['train_acc'].append(train_metrics['acc'])\n        history['train_air_acc'].append(train_metrics['air_acc'])\n        history['train_struct_acc'].append(train_metrics['struct_acc'])\n        history['train_air_pct'].append(train_metrics['air_pct'])\n        history['val_loss'].append(val_metrics['loss'])\n        history['val_acc'].append(val_metrics['acc'])\n        history['val_air_acc'].append(val_metrics['air_acc'])\n        history['val_struct_acc'].append(val_metrics['struct_acc'])\n        history['val_air_pct'].append(val_metrics['air_pct'])\n        \n        # Show all metrics including structure accuracy\n        print(f\"Epoch {epoch+1:2d}/{EPOCHS} | \"\n              f\"Loss: {train_metrics['loss']:.3f} | \"\n              f\"Acc: {train_metrics['acc']:.1%} | \"\n              f\"Struct: {train_metrics['struct_acc']:.1%} | \"\n              f\"Air: {train_metrics['air_acc']:.1%} | \"\n              f\"Val Struct: {val_metrics['struct_acc']:.1%} | \"\n              f\"Air%: {val_metrics['air_pct']:.1%}\")\n    \n    train_time = time.time() - start_time\n    print(f\"Training time: {train_time/60:.1f} minutes\")\n    \n    # Sanity check: struct_acc should differ from overall acc\n    if abs(history['val_acc'][-1] - history['val_struct_acc'][-1]) < 0.001:\n        print(\"⚠️  WARNING: Overall and Structure accuracy are nearly identical!\")\n        print(\"    Air detection may still be broken.\")\n    else:\n        print(f\"✓ Structure accuracy ({history['val_struct_acc'][-1]:.1%}) differs from overall ({history['val_acc'][-1]:.1%})\")\n    \n    # Final metrics\n    final_metrics = {\n        'name': name,\n        'final_train_loss': history['train_loss'][-1],\n        'final_val_loss': history['val_loss'][-1],\n        'final_train_acc': history['train_acc'][-1],\n        'final_val_acc': history['val_acc'][-1],\n        'final_train_struct_acc': history['train_struct_acc'][-1],\n        'final_val_struct_acc': history['val_struct_acc'][-1],\n        'final_train_air_acc': history['train_air_acc'][-1],\n        'final_val_air_acc': history['val_air_acc'][-1],\n        'avg_air_pct': np.mean(history['val_air_pct']),\n        'best_val_loss': min(history['val_loss']),\n        'best_val_acc': max(history['val_acc']),\n        'best_val_struct_acc': max(history['val_struct_acc']),\n        'training_time': train_time,\n        'history': history,\n    }\n    \n    # Cleanup\n    del model, optimizer, scaler\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    \n    return final_metrics\n\n\nprint(\"Experiment function defined!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 8: Run All Experiments\n# ============================================================\n\nprint(\"=\"*60)\nprint(\"PHASE 0: VQ-VAE EMBEDDING VALIDATION\")\nprint(\"=\"*60)\nprint(f\"\\nAir tokens being used: {AIR_TOKENS_TENSOR.tolist()}\")\nprint(\"These will be EXCLUDED from structure accuracy calculation.\\n\")\n\nall_results = {}\n\nfor name, embeddings in EMBEDDING_VARIANTS.items():\n    results = run_experiment(name, embeddings, AIR_TOKENS_TENSOR)\n    all_results[name] = results\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ALL EXPERIMENTS COMPLETE\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 9: Compare Results\n# ============================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"RESULTS COMPARISON\")\nprint(\"=\"*70)\n\n# Show air percentage first\navg_air_pct = np.mean([all_results[name]['avg_air_pct'] for name in ['V1', 'V2', 'Random']])\nprint(f\"\\nAverage air percentage in data: {avg_air_pct:.1%}\")\nprint(\"This is why STRUCTURE accuracy (non-air) is the key metric!\\n\")\n\n# Create comparison table - emphasize STRUCTURE accuracy\nprint(\"{:<10} {:>12} {:>12} {:>12} {:>12} {:>12}\".format(\n    \"Embeddings\", \"Val Loss\", \"Overall Acc\", \"STRUCT Acc\", \"Air Acc\", \"Time\"))\nprint(\"-\"*70)\n\nfor name in ['V1', 'V2', 'Random']:\n    r = all_results[name]\n    print(\"{:<10} {:>12.4f} {:>12.1%} {:>12.1%} {:>12.1%} {:>10.1f}m\".format(\n        name,\n        r['best_val_loss'],\n        r['best_val_acc'],\n        r['best_val_struct_acc'],\n        r['final_val_air_acc'],\n        r['training_time']/60\n    ))\n\n# Calculate improvements over random - STRUCTURE accuracy is key!\nprint(\"\\n\" + \"=\"*70)\nprint(\"IMPROVEMENT OVER RANDOM BASELINE (Structure Accuracy = Key Metric)\")\nprint(\"=\"*70)\n\nrandom_loss = all_results['Random']['best_val_loss']\nrandom_acc = all_results['Random']['best_val_acc']\nrandom_struct = all_results['Random']['best_val_struct_acc']\n\nfor name in ['V1', 'V2']:\n    r = all_results[name]\n    loss_improvement = (random_loss - r['best_val_loss']) / random_loss * 100\n    acc_improvement = (r['best_val_acc'] - random_acc) / random_acc * 100\n    struct_improvement = (r['best_val_struct_acc'] - random_struct) / random_struct * 100\n    \n    print(f\"\\n{name} vs Random:\")\n    print(f\"  Loss:            {loss_improvement:+.1f}% {'(better)' if loss_improvement > 0 else '(worse)'}\")\n    print(f\"  Overall Acc:     {acc_improvement:+.1f}% {'(better)' if acc_improvement > 0 else '(worse)'}\")\n    print(f\"  ★ STRUCT Acc:    {struct_improvement:+.1f}% {'(better)' if struct_improvement > 0 else '(worse)'} ← KEY METRIC\")\n\n# Decision based on STRUCTURE accuracy\nprint(\"\\n\" + \"=\"*70)\nprint(\"CONCLUSION (Based on STRUCTURE Accuracy)\")\nprint(\"=\"*70)\n\nv1_struct_improvement = (all_results['V1']['best_val_struct_acc'] - random_struct) / random_struct * 100\nv2_struct_improvement = (all_results['V2']['best_val_struct_acc'] - random_struct) / random_struct * 100\n\nprint(f\"\\nStructure accuracy improvements over random:\")\nprint(f\"  V1: {v1_struct_improvement:+.1f}%\")\nprint(f\"  V2: {v2_struct_improvement:+.1f}%\")\n\nif v1_struct_improvement > 20 or v2_struct_improvement > 20:\n    print(\"\\n✓ Block2Vec embeddings ARE useful for VQ-VAE structure reconstruction!\")\n    print(\"  Proceed with Block2Vec optimization.\")\n    if all_results['V1']['best_val_struct_acc'] > all_results['V2']['best_val_struct_acc']:\n        print(f\"  V1 is better for structure - the hybrid approach may have been harmful.\")\n    else:\n        print(f\"  V2 is better for structure - continue with hybrid approach.\")\nelif v1_struct_improvement > 5 or v2_struct_improvement > 5:\n    print(\"\\n~ Block2Vec provides MODEST improvement for structure reconstruction.\")\n    print(\"  Consider whether optimization effort is worth it.\")\nelse:\n    print(\"\\n✗ Block2Vec embeddings do NOT significantly help structure reconstruction.\")\n    print(\"  Either:\")\n    print(\"  1. Use simple one-hot encoding\")\n    print(\"  2. Let VQ-VAE learn its own embeddings\")\n    print(\"  3. Focus optimization elsewhere (VQ-VAE architecture, training, etc.)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 10: Plot Comparison\n# ============================================================\n\nfig, axes = plt.subplots(2, 3, figsize=(18, 10))\n\ncolors = {'V1': 'blue', 'V2': 'green', 'Random': 'red'}\n\n# Validation Loss\nax = axes[0, 0]\nfor name in ['V1', 'V2', 'Random']:\n    ax.plot(all_results[name]['history']['val_loss'], label=name, \n            color=colors[name], linewidth=2)\nax.set_xlabel('Epoch')\nax.set_ylabel('Validation Loss')\nax.set_title('Validation Loss by Embedding Type')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Overall Accuracy (less important - dominated by air)\nax = axes[0, 1]\nfor name in ['V1', 'V2', 'Random']:\n    ax.plot(all_results[name]['history']['val_acc'], label=name,\n            color=colors[name], linewidth=2)\nax.set_xlabel('Epoch')\nax.set_ylabel('Validation Accuracy')\nax.set_title('Overall Accuracy (includes ~90% air)')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# STRUCTURE Accuracy - THE KEY METRIC!\nax = axes[0, 2]\nfor name in ['V1', 'V2', 'Random']:\n    ax.plot(all_results[name]['history']['val_struct_acc'], label=name,\n            color=colors[name], linewidth=2)\nax.set_xlabel('Epoch')\nax.set_ylabel('Structure Accuracy (non-air)')\nax.set_title('★ STRUCTURE Accuracy (KEY METRIC) ★')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Air Accuracy\nax = axes[1, 0]\nfor name in ['V1', 'V2', 'Random']:\n    ax.plot(all_results[name]['history']['val_air_acc'], label=name,\n            color=colors[name], linewidth=2)\nax.set_xlabel('Epoch')\nax.set_ylabel('Air Accuracy')\nax.set_title('Air Block Accuracy')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Air Percentage (sanity check)\nax = axes[1, 1]\nfor name in ['V1', 'V2', 'Random']:\n    ax.plot(all_results[name]['history']['val_air_pct'], label=name,\n            color=colors[name], linewidth=2, alpha=0.7)\nax.set_xlabel('Epoch')\nax.set_ylabel('Air Percentage')\nax.set_title(f'Air Block % in Data (~should be constant)')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Bar chart comparison - emphasize structure accuracy\nax = axes[1, 2]\nx = np.arange(3)\nwidth = 0.35\nstruct_accs = [all_results[name]['best_val_struct_acc'] for name in ['V1', 'V2', 'Random']]\noverall_accs = [all_results[name]['best_val_acc'] for name in ['V1', 'V2', 'Random']]\n\nbars1 = ax.bar(x - width/2, struct_accs, width, label='Structure Acc (KEY)', color=['blue', 'green', 'red'], alpha=0.9)\nbars2 = ax.bar(x + width/2, overall_accs, width, label='Overall Acc', color=['blue', 'green', 'red'], alpha=0.4)\n\nax.set_ylabel('Accuracy')\nax.set_title('Best Accuracy Comparison\\n(Structure Acc is the key metric!)')\nax.set_xticks(x)\nax.set_xticklabels(['V1', 'V2', 'Random'])\nax.legend()\nax.grid(True, alpha=0.3, axis='y')\n\n# Add value labels on bars\nfor bar, val in zip(bars1, struct_accs):\n    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n            f'{val:.1%}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig(f\"{OUTPUT_DIR}/embedding_comparison.png\", dpi=150)\nplt.show()\n\n# Sanity check output\nprint(\"\\n\" + \"=\"*60)\nprint(\"SANITY CHECK\")\nprint(\"=\"*60)\nfor name in ['V1', 'V2', 'Random']:\n    r = all_results[name]\n    struct = r['best_val_struct_acc']\n    overall = r['best_val_acc']\n    diff = abs(struct - overall)\n    status = \"✓\" if diff > 0.01 else \"⚠️\"\n    print(f\"{status} {name}: Overall={overall:.3f}, Structure={struct:.3f}, Diff={diff:.3f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 11: Save Results\n# ============================================================\n\n# Save summary (without full history to keep file small)\nsummary = {}\nfor name, results in all_results.items():\n    summary[name] = {\n        'final_val_loss': results['final_val_loss'],\n        'final_val_acc': results['final_val_acc'],\n        'final_val_struct_acc': results['final_val_struct_acc'],\n        'final_val_air_acc': results['final_val_air_acc'],\n        'best_val_loss': results['best_val_loss'],\n        'best_val_acc': results['best_val_acc'],\n        'best_val_struct_acc': results['best_val_struct_acc'],\n        'avg_air_percentage': results['avg_air_pct'],\n        'training_time_minutes': results['training_time'] / 60,\n    }\n\nwith open(f\"{OUTPUT_DIR}/embedding_validation_results.json\", 'w') as f:\n    json.dump(summary, f, indent=2)\n\nprint(\"Results saved to embedding_validation_results.json\")\n\n# Save full history for detailed analysis\nfull_results = {}\nfor name, results in all_results.items():\n    full_results[name] = {\n        'history': results['history'],\n        'training_time': results['training_time'],\n    }\n\nwith open(f\"{OUTPUT_DIR}/embedding_validation_full.json\", 'w') as f:\n    json.dump(full_results, f, indent=2)\n\nprint(\"Full history saved to embedding_validation_full.json\")\n\n# Also save air tokens used for reproducibility\nwith open(f\"{OUTPUT_DIR}/air_tokens_used.json\", 'w') as f:\n    json.dump({\n        'air_tokens': sorted(AIR_TOKENS),\n        'note': 'These tokens were excluded from structure accuracy calculation'\n    }, f, indent=2)\n\nprint(\"Air tokens saved to air_tokens_used.json\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 12: Final Summary\n# ============================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"PHASE 0 COMPLETE: VQ-VAE EMBEDDING VALIDATION\")\nprint(\"=\"*70)\n\nprint(\"\\nQuestion: Do Block2Vec embeddings help VQ-VAE reconstruct STRUCTURES?\")\nprint(f\"\\nAir tokens excluded: {sorted(AIR_TOKENS)}\")\nprint(f\"Average air percentage: {avg_air_pct:.1%}\")\nprint(\"\\nNOTE: Overall accuracy is ~{:.0%} just from predicting air correctly.\".format(avg_air_pct))\nprint(\"      STRUCTURE accuracy is the true measure of reconstruction quality!\")\n\nprint(\"\\nResults:\")\nprint(\"\\n{:<12} {:>12} {:>15} {:>15} {:>12}\".format(\n    \"\", \"Val Loss\", \"Overall Acc\", \"★STRUCT Acc★\", \"Air Acc\"))\nprint(\"-\"*70)\nfor name in ['V1', 'V2', 'Random']:\n    r = all_results[name]\n    print(\"{:<12} {:>12.4f} {:>15.1%} {:>15.1%} {:>12.1%}\".format(\n        name,\n        r['best_val_loss'],\n        r['best_val_acc'],\n        r['best_val_struct_acc'],\n        r['final_val_air_acc']\n    ))\n\n# Final verdict\nprint(\"\\n\" + \"=\"*70)\nv1_improvement = (all_results['V1']['best_val_struct_acc'] - all_results['Random']['best_val_struct_acc']) / all_results['Random']['best_val_struct_acc'] * 100\nv2_improvement = (all_results['V2']['best_val_struct_acc'] - all_results['Random']['best_val_struct_acc']) / all_results['Random']['best_val_struct_acc'] * 100\n\nprint(f\"Structure accuracy improvement over random:\")\nprint(f\"  V1: {v1_improvement:+.1f}%\")\nprint(f\"  V2: {v2_improvement:+.1f}%\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"Files saved:\")\nprint(f\"  - {OUTPUT_DIR}/embedding_comparison.png\")\nprint(f\"  - {OUTPUT_DIR}/embedding_validation_results.json\")\nprint(f\"  - {OUTPUT_DIR}/embedding_validation_full.json\")\nprint(f\"  - {OUTPUT_DIR}/air_tokens_used.json\")\nprint(\"=\"*70)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}