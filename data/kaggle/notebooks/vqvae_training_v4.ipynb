{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# VQ-VAE v4 Training - Shape Preservation Focus\n\n## Philosophy: SHAPE FIRST, DETAILS SECOND\n\nThe key insight from Phase 2.5 validation: **buildings were disappearing** in reconstructions.\nThe model was predicting AIR where there should be structure blocks.\n\nThis version addresses that with:\n1. **Asymmetric Cross-Entropy**: structure→air errors penalized 10x more than air→structure\n2. **False Air Penalty**: explicit loss for predicting air where structure exists\n3. **Volume Preservation**: penalize if reconstruction has fewer blocks than original\n4. **Structure Recall**: new key metric tracking shape preservation\n\n## Key Improvements over v3\n\n| Change | v3 | v4 |\n|--------|-----|-----|\n| Latent grid | 4x4x4 (512:1) | **8x8x8 (64:1)** |\n| Embeddings | Frozen | **Trainable** |\n| Loss | CE only | **CE + embedding similarity + shape preservation** |\n| Metric | Exact-match | **Structure Recall (shape preservation)** |\n| Key focus | Accuracy | **Don't erase buildings!** |\n\n## New Metrics\n\n- **Structure Recall**: Of blocks that SHOULD be structure, how many are NOT erased? (Target: >90%)\n- **False Air Rate**: What % of structure was wrongly predicted as air? (Target: <10%)\n- **Volume Ratio**: predicted_volume / original_volume (Target: ~1.0)\n\n## Configuration\n\n- **Epochs**: 15 total (5 warmup + 10 full)\n- **Structure weight**: 50x (increased from 10x)\n- **False air weight**: 5x\n- **Structure→air weight**: 10x (asymmetric CE)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: Imports\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from collections import Counter\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 2: Configuration\n# ============================================================\n\n# === Data Paths ===\nDATA_DIR = \"/kaggle/input/minecraft-schematics/minecraft_splits/splits/train\"\nVAL_DIR = \"/kaggle/input/minecraft-schematics/minecraft_splits/splits/val\"\nVOCAB_PATH = \"/kaggle/input/minecraft-schematics/tok2block.json\"\nV3_EMBEDDINGS_PATH = \"/kaggle/input/minecraft-embeddings-v3/block_embeddings_v3.npy\"\n\nOUTPUT_DIR = \"/kaggle/working\"\n\n# === V4 Model Architecture ===\nHIDDEN_DIMS = [96, 192]  # 2 stages for 32->8 (not 3 stages for 32->4)\nLATENT_DIM = 256\nNUM_CODEBOOK_ENTRIES = 512\nDROPOUT = 0.1\n\n# === VQ-VAE Settings ===\nCOMMITMENT_COST = 0.5\nEMA_DECAY = 0.99\nSTRUCTURE_WEIGHT = 50.0  # INCREASED from 10.0 for shape preservation\n\n# === V4 Specific Settings ===\nEMBEDDING_LOSS_ALPHA = 0.5  # Weight for embedding similarity loss\nSTABILITY_WEIGHT = 0.01    # Embedding stability regularization\nDIVERSITY_WEIGHT = 0.001   # Embedding diversity regularization\n\n# === SHAPE PRESERVATION SETTINGS (NEW) ===\n# These prevent the \"buildings disappearing\" problem\nFALSE_AIR_WEIGHT = 5.0     # Heavily penalize predicting air where structure exists\nVOLUME_WEIGHT = 2.0        # Penalize losing structure volume\nSTRUCTURE_TO_AIR_WEIGHT = 10.0  # Asymmetric CE: structure->air errors 10x worse\nUSE_SHAPE_LOSS = True      # Enable shape preservation loss\nUSE_ASYMMETRIC_LOSS = True # Enable asymmetric cross-entropy\n\n# === Training ===\nTOTAL_EPOCHS = 15\nWARMUP_EPOCHS = 5  # Freeze embeddings for first N epochs\nBATCH_SIZE = 4     # Reduced due to larger latent grid\nBASE_LR = 3e-4\nEMBEDDING_LR_SCALE = 0.1  # Embeddings train 10x slower\nUSE_AMP = True\nGRAD_ACCUM_STEPS = 4\n\nSEED = 42\nNUM_WORKERS = 2\n\nprint(\"VQ-VAE v4 Configuration:\")\nprint(f\"  Latent grid: 8x8x8 (64:1 compression)\")\nprint(f\"  Hidden dims: {HIDDEN_DIMS}\")\nprint(f\"  Epochs: {TOTAL_EPOCHS} ({WARMUP_EPOCHS} warmup + {TOTAL_EPOCHS - WARMUP_EPOCHS} full)\")\nprint(f\"  Embedding loss alpha: {EMBEDDING_LOSS_ALPHA}\")\nprint(f\"  Structure weight: {STRUCTURE_WEIGHT}x\")\nprint(f\"\\nShape Preservation (NEW):\")\nprint(f\"  False air weight: {FALSE_AIR_WEIGHT}\")\nprint(f\"  Volume weight: {VOLUME_WEIGHT}\")\nprint(f\"  Structure->air weight: {STRUCTURE_TO_AIR_WEIGHT}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: Load Vocabulary and Embeddings\n",
    "# ============================================================\n",
    "\n",
    "with open(VOCAB_PATH, 'r') as f:\n",
    "    tok2block = {int(k): v for k, v in json.load(f).items()}\n",
    "\n",
    "block2tok = {v: k for k, v in tok2block.items()}\n",
    "VOCAB_SIZE = len(tok2block)\n",
    "print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
    "\n",
    "# Find air tokens\n",
    "AIR_TOKENS = set()\n",
    "for tok, block in tok2block.items():\n",
    "    if 'air' in block.lower() and 'stair' not in block.lower():\n",
    "        AIR_TOKENS.add(tok)\n",
    "        print(f\"  Air token: {tok} = {block}\")\n",
    "\n",
    "AIR_TOKENS_LIST = sorted(AIR_TOKENS)\n",
    "AIR_TOKENS_TENSOR = torch.tensor(AIR_TOKENS_LIST, dtype=torch.long)\n",
    "\n",
    "# Load V3 embeddings (compositional)\n",
    "v3_embeddings = np.load(V3_EMBEDDINGS_PATH).astype(np.float32)\n",
    "EMBEDDING_DIM = v3_embeddings.shape[1]\n",
    "print(f\"V3 embeddings: {v3_embeddings.shape} (dim={EMBEDDING_DIM})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: Dataset\n",
    "# ============================================================\n",
    "\n",
    "class VQVAEDataset(Dataset):\n",
    "    def __init__(self, data_dir: str):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.h5_files = sorted(self.data_dir.glob(\"*.h5\"))\n",
    "        if not self.h5_files:\n",
    "            raise ValueError(f\"No H5 files in {data_dir}\")\n",
    "        print(f\"Found {len(self.h5_files)} structures in {data_dir}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.h5_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.h5_files[idx], 'r') as f:\n",
    "            key = list(f.keys())[0]\n",
    "            structure = f[key][:].astype(np.int64)\n",
    "        return torch.from_numpy(structure).long()\n",
    "\n",
    "train_dataset = VQVAEDataset(DATA_DIR)\n",
    "val_dataset = VQVAEDataset(VAL_DIR)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 5: VQ-VAE v4 Architecture with Shape Preservation\n# ============================================================\n\nclass ResidualBlock3D(nn.Module):\n    def __init__(self, channels: int):\n        super().__init__()\n        self.conv1 = nn.Conv3d(channels, channels, 3, padding=1)\n        self.conv2 = nn.Conv3d(channels, channels, 3, padding=1)\n        self.bn1 = nn.BatchNorm3d(channels)\n        self.bn2 = nn.BatchNorm3d(channels)\n    \n    def forward(self, x):\n        residual = x\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.bn2(self.conv2(x))\n        return F.relu(x + residual)\n\n\nclass VectorQuantizerEMA(nn.Module):\n    \"\"\"EMA-based vector quantizer with dead code reset.\"\"\"\n    \n    def __init__(self, num_codes, latent_dim, commitment_cost=0.5, ema_decay=0.99):\n        super().__init__()\n        self.num_codes = num_codes\n        self.latent_dim = latent_dim\n        self.commitment_cost = commitment_cost\n        self.ema_decay = ema_decay\n        \n        self.register_buffer('codebook', torch.randn(num_codes, latent_dim))\n        self.codebook.data.uniform_(-1/num_codes, 1/num_codes)\n        self.register_buffer('ema_cluster_size', torch.zeros(num_codes))\n        self.register_buffer('ema_embed_sum', torch.zeros(num_codes, latent_dim))\n        self.register_buffer('code_usage', torch.zeros(num_codes))\n    \n    def reset_epoch_stats(self):\n        self.code_usage.zero_()\n    \n    def get_usage_fraction(self):\n        return (self.code_usage > 0).float().mean().item()\n    \n    def get_perplexity(self):\n        if self.code_usage.sum() == 0:\n            return 0.0\n        probs = self.code_usage / self.code_usage.sum()\n        probs = probs[probs > 0]\n        entropy = -(probs * probs.log()).sum()\n        return entropy.exp().item()\n    \n    def forward(self, z_e):\n        z_e_perm = z_e.permute(0, 2, 3, 4, 1).contiguous()\n        flat = z_e_perm.view(-1, self.latent_dim)\n        flat_f32 = flat.float()\n        codebook_f32 = self.codebook.float()\n        \n        d = (flat_f32.pow(2).sum(1, keepdim=True) \n             + codebook_f32.pow(2).sum(1) \n             - 2 * flat_f32 @ codebook_f32.t())\n        \n        indices = d.argmin(dim=1)\n        \n        with torch.no_grad():\n            for idx in indices.unique():\n                self.code_usage[idx] += (indices == idx).sum()\n        \n        z_q_flat = self.codebook[indices]\n        z_q_perm = z_q_flat.view(z_e_perm.shape)\n        \n        if self.training:\n            with torch.no_grad():\n                encodings = F.one_hot(indices, self.num_codes).float()\n                batch_size = encodings.sum(0)\n                \n                self.ema_cluster_size = self.ema_decay * self.ema_cluster_size + (1 - self.ema_decay) * batch_size\n                batch_sum = encodings.t() @ flat_f32\n                self.ema_embed_sum = self.ema_decay * self.ema_embed_sum + (1 - self.ema_decay) * batch_sum\n                \n                n = self.ema_cluster_size.sum()\n                smoothed = (self.ema_cluster_size + 1e-5) / (n + self.num_codes * 1e-5) * n\n                self.codebook.data = self.ema_embed_sum / smoothed.unsqueeze(1)\n                \n                # Dead code reset\n                dead = batch_size < 2\n                if dead.any() and flat_f32.size(0) > 0:\n                    n_dead = dead.sum().item()\n                    rand_idx = torch.randint(0, flat_f32.size(0), (n_dead,), device=flat_f32.device)\n                    self.codebook.data[dead] = flat_f32[rand_idx]\n                    self.ema_cluster_size[dead] = 1\n                    self.ema_embed_sum[dead] = flat_f32[rand_idx]\n        \n        commitment_loss = F.mse_loss(z_e_perm, z_q_perm.detach())\n        vq_loss = self.commitment_cost * commitment_loss\n        \n        z_q_st = z_e_perm + (z_q_perm - z_e_perm).detach()\n        z_q = z_q_st.permute(0, 4, 1, 2, 3).contiguous()\n        \n        return z_q, vq_loss, indices.view(z_e_perm.shape[:-1])\n\n\nclass EncoderV4(nn.Module):\n    \"\"\"32x32x32 -> 8x8x8 encoder (2 stages instead of 3).\"\"\"\n    \n    def __init__(self, in_channels, hidden_dims, latent_dim, dropout=0.1):\n        super().__init__()\n        layers = []\n        current = in_channels\n        \n        for h in hidden_dims:\n            layers.extend([\n                nn.Conv3d(current, h, 4, stride=2, padding=1),\n                nn.BatchNorm3d(h),\n                nn.ReLU(inplace=True),\n                nn.Dropout3d(dropout),\n                ResidualBlock3D(h),\n            ])\n            current = h\n        \n        # Extra capacity at 8x8x8\n        layers.extend([\n            ResidualBlock3D(current),\n            ResidualBlock3D(current),\n            nn.Conv3d(current, latent_dim, 3, padding=1),\n        ])\n        \n        self.encoder = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.encoder(x)\n\n\nclass DecoderV4(nn.Module):\n    \"\"\"8x8x8 -> 32x32x32 decoder.\"\"\"\n    \n    def __init__(self, latent_dim, hidden_dims, num_blocks, dropout=0.1):\n        super().__init__()\n        layers = [\n            ResidualBlock3D(latent_dim),\n            ResidualBlock3D(latent_dim),\n        ]\n        \n        current = latent_dim\n        for h in hidden_dims:\n            layers.extend([\n                ResidualBlock3D(current),\n                nn.ConvTranspose3d(current, h, 4, stride=2, padding=1),\n                nn.BatchNorm3d(h),\n                nn.ReLU(inplace=True),\n                nn.Dropout3d(dropout),\n            ])\n            current = h\n        \n        layers.append(nn.Conv3d(current, num_blocks, 3, padding=1))\n        self.decoder = nn.Sequential(*layers)\n    \n    def forward(self, z_q):\n        return self.decoder(z_q)\n\n\ndef compute_similarity_matrix(embeddings):\n    \"\"\"Compute cosine similarity matrix scaled to [0,1].\"\"\"\n    with torch.no_grad():\n        normed = F.normalize(embeddings, dim=1)\n        sim = normed @ normed.t()\n        return (sim + 1) / 2\n\n\nclass ShapePreservationLoss(nn.Module):\n    \"\"\"Loss functions to prevent buildings from disappearing.\n    \n    Philosophy: SHAPE FIRST, DETAILS SECOND.\n    It's better to predict the wrong block type than to predict air.\n    \"\"\"\n    \n    def __init__(self, false_air_weight=5.0, volume_weight=2.0):\n        super().__init__()\n        self.false_air_weight = false_air_weight\n        self.volume_weight = volume_weight\n    \n    def forward(self, logits, targets, air_tokens):\n        predictions = logits.argmax(dim=1)\n        \n        is_struct_orig = ~torch.isin(targets, air_tokens)\n        is_air_pred = torch.isin(predictions, air_tokens)\n        is_struct_pred = ~is_air_pred\n        \n        # False air: predicted air where structure existed\n        false_air_mask = is_struct_orig & is_air_pred\n        if is_struct_orig.sum() > 0:\n            false_air_rate = false_air_mask.float().sum() / is_struct_orig.float().sum()\n        else:\n            false_air_rate = torch.tensor(0.0, device=predictions.device)\n        \n        # Volume preservation: penalize losing structure volume\n        orig_vol = is_struct_orig.float().sum()\n        pred_vol = is_struct_pred.float().sum()\n        if orig_vol > 0:\n            volume_loss = F.relu(orig_vol - pred_vol) / orig_vol\n        else:\n            volume_loss = torch.tensor(0.0, device=predictions.device)\n        \n        # Structure recall: fraction of original structure preserved\n        true_struct = is_struct_orig & is_struct_pred\n        if is_struct_orig.sum() > 0:\n            struct_recall = true_struct.float().sum() / is_struct_orig.float().sum()\n        else:\n            struct_recall = torch.tensor(1.0, device=predictions.device)\n        \n        total = self.false_air_weight * false_air_rate + self.volume_weight * volume_loss\n        \n        return {\n            'false_air_rate': false_air_rate,\n            'volume_loss': volume_loss,\n            'structure_recall': struct_recall,\n            'total': total,\n        }\n\n\nclass AsymmetricStructureLoss(nn.Module):\n    \"\"\"Asymmetric CE that penalizes structure->air more than air->structure.\"\"\"\n    \n    def __init__(self, structure_to_air_weight=10.0, air_to_structure_weight=1.0):\n        super().__init__()\n        self.structure_to_air_weight = structure_to_air_weight\n        self.air_to_structure_weight = air_to_structure_weight\n    \n    def forward(self, logits, targets, air_tokens):\n        predictions = logits.argmax(dim=1)\n        \n        is_air_tgt = torch.isin(targets, air_tokens)\n        is_air_pred = torch.isin(predictions, air_tokens)\n        is_struct_tgt = ~is_air_tgt\n        is_struct_pred = ~is_air_pred\n        \n        weights = torch.ones_like(targets, dtype=torch.float)\n        \n        # Structure->air: HEAVY penalty (erases building)\n        struct_to_air = is_struct_tgt & is_air_pred\n        weights[struct_to_air] = self.structure_to_air_weight\n        \n        # Air->structure: light penalty (adds extra blocks)\n        air_to_struct = is_air_tgt & is_struct_pred\n        weights[air_to_struct] = self.air_to_structure_weight\n        \n        ce_loss = F.cross_entropy(logits, targets, reduction='none')\n        return (ce_loss * weights).sum() / weights.sum()\n\n\nclass VQVAEv4(nn.Module):\n    \"\"\"VQ-VAE v4 with trainable embeddings, embedding-aware loss, and SHAPE PRESERVATION.\"\"\"\n    \n    def __init__(self, vocab_size, emb_dim, hidden_dims, latent_dim, num_codes,\n                 pretrained_emb, embedding_loss_alpha=0.5, stability_weight=0.01,\n                 diversity_weight=0.001, false_air_weight=5.0, volume_weight=2.0,\n                 structure_to_air_weight=10.0, dropout=0.1, commitment_cost=0.5, \n                 ema_decay=0.99):\n        super().__init__()\n        self.vocab_size = vocab_size\n        self.emb_dim = emb_dim\n        self.embedding_loss_alpha = embedding_loss_alpha\n        self.stability_weight = stability_weight\n        self.diversity_weight = diversity_weight\n        self.false_air_weight = false_air_weight\n        self.volume_weight = volume_weight\n        self.train_embeddings = False  # Start frozen\n        \n        # Embeddings\n        self.block_emb = nn.Embedding(vocab_size, emb_dim)\n        self.block_emb.weight.data.copy_(torch.from_numpy(pretrained_emb))\n        self.block_emb.weight.requires_grad = False  # Start frozen\n        self.register_buffer('original_embeddings', torch.from_numpy(pretrained_emb.copy()))\n        \n        # Encoder 32->8\n        self.encoder = EncoderV4(emb_dim, hidden_dims, latent_dim, dropout)\n        \n        # Quantizer\n        self.quantizer = VectorQuantizerEMA(num_codes, latent_dim, commitment_cost, ema_decay)\n        \n        # Decoder 8->32\n        self.decoder = DecoderV4(latent_dim, list(reversed(hidden_dims)), vocab_size, dropout)\n        \n        # Shape preservation loss (NEW)\n        self.shape_loss = ShapePreservationLoss(false_air_weight, volume_weight)\n        \n        # Asymmetric loss (NEW)\n        self.asymmetric_loss = AsymmetricStructureLoss(structure_to_air_weight)\n        \n        # Similarity cache\n        self._sim_matrix = None\n        self._sim_valid = False\n    \n    def set_train_embeddings(self, train: bool):\n        \"\"\"Enable/disable embedding training for phased training.\"\"\"\n        self.train_embeddings = train\n        self.block_emb.weight.requires_grad = train\n        if train:\n            self._sim_valid = False\n    \n    def get_similarity_matrix(self):\n        if not self._sim_valid or self._sim_matrix is None:\n            self._sim_matrix = compute_similarity_matrix(self.block_emb.weight.detach())\n            self._sim_valid = True\n        return self._sim_matrix\n    \n    def forward(self, block_ids):\n        x = self.block_emb(block_ids).permute(0, 4, 1, 2, 3).contiguous()\n        z_e = self.encoder(x)\n        z_q, vq_loss, indices = self.quantizer(z_e)\n        logits = self.decoder(z_q)\n        return {'logits': logits, 'vq_loss': vq_loss, 'indices': indices}\n    \n    def compute_embedding_regularization(self):\n        current = self.block_emb.weight\n        original = self.original_embeddings\n        \n        stability = F.mse_loss(current, original)\n        \n        normed = F.normalize(current, dim=1)\n        sim = normed @ normed.t()\n        off_diag = 1 - torch.eye(current.size(0), device=current.device)\n        avg_sim = (sim * off_diag).sum() / off_diag.sum()\n        diversity = F.relu(avg_sim - 0.3)\n        \n        return {'stability': stability, 'diversity': diversity}\n    \n    def compute_loss(self, block_ids, air_tokens, structure_weight, \n                     use_emb_loss=True, use_shape_loss=True, use_asymmetric_loss=True):\n        out = self(block_ids)\n        logits = out['logits']\n        \n        logits_flat = logits.permute(0, 2, 3, 4, 1).reshape(-1, self.vocab_size)\n        targets_flat = block_ids.view(-1)\n        \n        # Air tokens for structure masking\n        air_dev = air_tokens.to(targets_flat.device)\n        is_air = torch.isin(targets_flat, air_dev)\n        is_struct = ~is_air\n        \n        # === PRIMARY LOSS: Asymmetric Cross-Entropy ===\n        if use_asymmetric_loss:\n            ce_loss = self.asymmetric_loss(logits_flat, targets_flat, air_dev)\n        else:\n            weights = torch.ones_like(targets_flat, dtype=torch.float)\n            weights[is_struct] = structure_weight\n            ce = F.cross_entropy(logits_flat, targets_flat, reduction='none')\n            ce_loss = (weights * ce).sum() / weights.sum()\n        \n        # === SHAPE PRESERVATION LOSS ===\n        if use_shape_loss:\n            shape = self.shape_loss(logits_flat, targets_flat, air_dev)\n            shape_loss = shape['total']\n            false_air_rate = shape['false_air_rate']\n            struct_recall = shape['structure_recall']\n        else:\n            shape_loss = torch.tensor(0.0, device=block_ids.device)\n            false_air_rate = torch.tensor(0.0, device=block_ids.device)\n            struct_recall = torch.tensor(0.0, device=block_ids.device)\n        \n        # === EMBEDDING SIMILARITY LOSS ===\n        if use_emb_loss and self.embedding_loss_alpha > 0:\n            probs = F.softmax(logits_flat / 0.1, dim=1)\n            emb_normed = F.normalize(self.block_emb.weight, dim=1)\n            pred_emb = probs @ emb_normed\n            target_emb = emb_normed[targets_flat]\n            similarity = (pred_emb * target_emb).sum(dim=1)\n            emb_loss_raw = 1 - similarity\n            \n            weights = torch.ones_like(targets_flat, dtype=torch.float)\n            weights[is_struct] = structure_weight\n            emb_loss = (weights * emb_loss_raw).sum() / weights.sum()\n        else:\n            emb_loss = torch.tensor(0.0, device=block_ids.device)\n        \n        # === EMBEDDING REGULARIZATION ===\n        if self.train_embeddings:\n            reg = self.compute_embedding_regularization()\n            stab_loss = self.stability_weight * reg['stability']\n            div_loss = self.diversity_weight * reg['diversity']\n        else:\n            stab_loss = torch.tensor(0.0, device=block_ids.device)\n            div_loss = torch.tensor(0.0, device=block_ids.device)\n        \n        # === TOTAL LOSS ===\n        total = (ce_loss + shape_loss + \n                 self.embedding_loss_alpha * emb_loss + \n                 out['vq_loss'] + stab_loss + div_loss)\n        \n        # === COMPUTE METRICS ===\n        with torch.no_grad():\n            preds = logits_flat.argmax(dim=1)\n            correct = (preds == targets_flat).float()\n            \n            exact_acc = correct.mean()\n            struct_exact = correct[is_struct].mean() if is_struct.any() else torch.tensor(0.0)\n            air_exact = correct[is_air].mean() if is_air.any() else torch.tensor(0.0)\n            \n            # Similarity-weighted accuracy\n            sim_matrix = self.get_similarity_matrix().to(preds.device)\n            sim_scores = sim_matrix[preds, targets_flat]\n            sim_acc = sim_scores.mean()\n            struct_sim = sim_scores[is_struct].mean() if is_struct.any() else torch.tensor(0.0)\n            \n            # Volume ratio\n            is_air_pred = torch.isin(preds, air_dev)\n            orig_vol = is_struct.float().sum()\n            pred_vol = (~is_air_pred).float().sum()\n            vol_ratio = pred_vol / orig_vol if orig_vol > 0 else torch.tensor(1.0)\n        \n        return {\n            'loss': total,\n            'ce_loss': ce_loss,\n            'shape_loss': shape_loss,\n            'emb_loss': emb_loss,\n            'vq_loss': out['vq_loss'],\n            'stab_loss': stab_loss,\n            'div_loss': div_loss,\n            'exact_acc': exact_acc,\n            'struct_exact': struct_exact,\n            'air_exact': air_exact,\n            'sim_acc': sim_acc,\n            'struct_sim': struct_sim,\n            # Shape preservation metrics (NEW - KEY METRICS)\n            'false_air_rate': false_air_rate,  # Want LOW (<10%)\n            'struct_recall': struct_recall,     # Want HIGH (>90%)\n            'vol_ratio': vol_ratio,             # Want CLOSE TO 1.0\n        }\n\n\nprint(\"VQ-VAE v4 architecture with shape preservation defined!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 6: Training Functions with Shape Preservation Metrics\n# ============================================================\n\ndef train_epoch(model, loader, optimizer, scaler, device, air_tokens, structure_weight,\n                use_emb_loss, use_shape_loss, use_asymmetric_loss):\n    model.train()\n    model.quantizer.reset_epoch_stats()\n    \n    metrics = {k: 0.0 for k in ['loss', 'ce', 'shape', 'emb', 'vq', 'stab', 'div',\n                                 'exact', 'struct_exact', 'air_exact', 'sim', 'struct_sim',\n                                 'false_air', 'struct_recall', 'vol_ratio']}\n    n = 0\n    optimizer.zero_grad()\n    \n    for batch_idx, batch in enumerate(tqdm(loader, desc=\"Train\", leave=False)):\n        batch = batch.to(device)\n        \n        with torch.amp.autocast('cuda', enabled=USE_AMP):\n            out = model.compute_loss(batch, air_tokens, structure_weight, \n                                     use_emb_loss, use_shape_loss, use_asymmetric_loss)\n            loss = out['loss'] / GRAD_ACCUM_STEPS\n        \n        scaler.scale(loss).backward()\n        \n        if (batch_idx + 1) % GRAD_ACCUM_STEPS == 0:\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n        \n        metrics['loss'] += out['loss'].item()\n        metrics['ce'] += out['ce_loss'].item()\n        metrics['shape'] += out['shape_loss'].item()\n        metrics['emb'] += out['emb_loss'].item()\n        metrics['vq'] += out['vq_loss'].item()\n        metrics['stab'] += out['stab_loss'].item()\n        metrics['div'] += out['div_loss'].item()\n        metrics['exact'] += out['exact_acc'].item()\n        metrics['struct_exact'] += out['struct_exact'].item()\n        metrics['air_exact'] += out['air_exact'].item()\n        metrics['sim'] += out['sim_acc'].item()\n        metrics['struct_sim'] += out['struct_sim'].item()\n        # NEW shape preservation metrics\n        metrics['false_air'] += out['false_air_rate'].item()\n        metrics['struct_recall'] += out['struct_recall'].item()\n        metrics['vol_ratio'] += out['vol_ratio'].item()\n        n += 1\n    \n    metrics['cb_usage'] = model.quantizer.get_usage_fraction()\n    metrics['perplexity'] = model.quantizer.get_perplexity()\n    \n    return {k: v/n if k not in ['cb_usage', 'perplexity'] else v for k, v in metrics.items()}\n\n\n@torch.no_grad()\ndef validate(model, loader, device, air_tokens, structure_weight, \n             use_emb_loss, use_shape_loss, use_asymmetric_loss):\n    model.eval()\n    model.quantizer.reset_epoch_stats()\n    \n    metrics = {k: 0.0 for k in ['loss', 'ce', 'shape', 'emb', 'vq',\n                                 'exact', 'struct_exact', 'air_exact', 'sim', 'struct_sim',\n                                 'false_air', 'struct_recall', 'vol_ratio']}\n    n = 0\n    \n    for batch in tqdm(loader, desc=\"Val\", leave=False):\n        batch = batch.to(device)\n        \n        with torch.amp.autocast('cuda', enabled=USE_AMP):\n            out = model.compute_loss(batch, air_tokens, structure_weight,\n                                     use_emb_loss, use_shape_loss, use_asymmetric_loss)\n        \n        metrics['loss'] += out['loss'].item()\n        metrics['ce'] += out['ce_loss'].item()\n        metrics['shape'] += out['shape_loss'].item()\n        metrics['emb'] += out['emb_loss'].item()\n        metrics['vq'] += out['vq_loss'].item()\n        metrics['exact'] += out['exact_acc'].item()\n        metrics['struct_exact'] += out['struct_exact'].item()\n        metrics['air_exact'] += out['air_exact'].item()\n        metrics['sim'] += out['sim_acc'].item()\n        metrics['struct_sim'] += out['struct_sim'].item()\n        # NEW shape preservation metrics\n        metrics['false_air'] += out['false_air_rate'].item()\n        metrics['struct_recall'] += out['struct_recall'].item()\n        metrics['vol_ratio'] += out['vol_ratio'].item()\n        n += 1\n    \n    metrics['cb_usage'] = model.quantizer.get_usage_fraction()\n    metrics['perplexity'] = model.quantizer.get_perplexity()\n    \n    return {k: v/n if k not in ['cb_usage', 'perplexity'] else v for k, v in metrics.items()}\n\n\nprint(\"Training functions with shape preservation metrics defined!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 7: Create Model and Optimizer\n# ============================================================\n\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(SEED)\n    torch.cuda.empty_cache()\n\n# Data loaders\ng = torch.Generator().manual_seed(SEED)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n                          num_workers=NUM_WORKERS, pin_memory=True, generator=g)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n                        num_workers=NUM_WORKERS, pin_memory=True)\n\n# Create model with shape preservation\nmodel = VQVAEv4(\n    vocab_size=VOCAB_SIZE,\n    emb_dim=EMBEDDING_DIM,\n    hidden_dims=HIDDEN_DIMS,\n    latent_dim=LATENT_DIM,\n    num_codes=NUM_CODEBOOK_ENTRIES,\n    pretrained_emb=v3_embeddings,\n    embedding_loss_alpha=EMBEDDING_LOSS_ALPHA,\n    stability_weight=STABILITY_WEIGHT,\n    diversity_weight=DIVERSITY_WEIGHT,\n    false_air_weight=FALSE_AIR_WEIGHT,\n    volume_weight=VOLUME_WEIGHT,\n    structure_to_air_weight=STRUCTURE_TO_AIR_WEIGHT,\n    dropout=DROPOUT,\n    commitment_cost=COMMITMENT_COST,\n    ema_decay=EMA_DECAY,\n).to(device)\n\n# Count parameters\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Total params: {total_params:,}\")\nprint(f\"Trainable params: {trainable_params:,}\")\nprint(f\"Embeddings trainable: {model.train_embeddings}\")\n\n# Optimizer with separate LR for embeddings\nemb_params = list(model.block_emb.parameters())\nother_params = [p for n, p in model.named_parameters() if 'block_emb' not in n and p.requires_grad]\n\noptimizer = optim.AdamW([\n    {'params': other_params, 'lr': BASE_LR},\n    {'params': emb_params, 'lr': BASE_LR * EMBEDDING_LR_SCALE},\n], weight_decay=1e-5)\n\nscaler = torch.amp.GradScaler('cuda', enabled=USE_AMP)\n\nprint(f\"\\nOptimizer: AdamW\")\nprint(f\"  Base LR: {BASE_LR}\")\nprint(f\"  Embedding LR: {BASE_LR * EMBEDDING_LR_SCALE}\")\nprint(f\"\\nShape Preservation:\")\nprint(f\"  False air weight: {FALSE_AIR_WEIGHT}\")\nprint(f\"  Volume weight: {VOLUME_WEIGHT}\")\nprint(f\"  Structure->air weight: {STRUCTURE_TO_AIR_WEIGHT}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 8: Training Loop with Shape Preservation\n# ============================================================\n\nprint(\"=\"*70)\nprint(\"VQ-VAE V4 TRAINING - SHAPE FIRST, DETAILS SECOND\")\nprint(\"=\"*70)\nprint(f\"Phase 1: Warmup (epochs 1-{WARMUP_EPOCHS}) - Embeddings FROZEN\")\nprint(f\"Phase 2: Full (epochs {WARMUP_EPOCHS+1}-{TOTAL_EPOCHS}) - Embeddings TRAINABLE\")\nprint(f\"\\nShape Preservation Enabled:\")\nprint(f\"  - Asymmetric CE: structure->air penalized {STRUCTURE_TO_AIR_WEIGHT}x\")\nprint(f\"  - False air penalty: {FALSE_AIR_WEIGHT}x\")\nprint(f\"  - Volume preservation: {VOLUME_WEIGHT}x\")\nprint()\n\nhistory = {\n    'train_loss': [], 'train_struct_exact': [], 'train_struct_sim': [],\n    'train_cb_usage': [], 'train_perplexity': [],\n    'train_false_air': [], 'train_struct_recall': [], 'train_vol_ratio': [],\n    'val_loss': [], 'val_struct_exact': [], 'val_struct_sim': [],\n    'val_cb_usage': [], 'val_perplexity': [],\n    'val_false_air': [], 'val_struct_recall': [], 'val_vol_ratio': [],\n    'phase': [],\n}\n\nbest_struct_recall = 0  # NEW: track best shape preservation, not similarity\nbest_epoch = 0\nstart_time = time.time()\n\nfor epoch in range(TOTAL_EPOCHS):\n    # Phased training\n    if epoch < WARMUP_EPOCHS:\n        phase = \"warmup\"\n        model.set_train_embeddings(False)\n        use_emb_loss = False\n    else:\n        phase = \"full\"\n        model.set_train_embeddings(True)\n        use_emb_loss = True\n    \n    # Train\n    train_m = train_epoch(model, train_loader, optimizer, scaler, device,\n                          AIR_TOKENS_TENSOR, STRUCTURE_WEIGHT, use_emb_loss,\n                          USE_SHAPE_LOSS, USE_ASYMMETRIC_LOSS)\n    \n    # Validate\n    val_m = validate(model, val_loader, device, AIR_TOKENS_TENSOR, STRUCTURE_WEIGHT,\n                     use_emb_loss, USE_SHAPE_LOSS, USE_ASYMMETRIC_LOSS)\n    \n    # Record\n    history['train_loss'].append(train_m['loss'])\n    history['train_struct_exact'].append(train_m['struct_exact'])\n    history['train_struct_sim'].append(train_m['struct_sim'])\n    history['train_cb_usage'].append(train_m['cb_usage'])\n    history['train_perplexity'].append(train_m['perplexity'])\n    history['train_false_air'].append(train_m['false_air'])\n    history['train_struct_recall'].append(train_m['struct_recall'])\n    history['train_vol_ratio'].append(train_m['vol_ratio'])\n    \n    history['val_loss'].append(val_m['loss'])\n    history['val_struct_exact'].append(val_m['struct_exact'])\n    history['val_struct_sim'].append(val_m['struct_sim'])\n    history['val_cb_usage'].append(val_m['cb_usage'])\n    history['val_perplexity'].append(val_m['perplexity'])\n    history['val_false_air'].append(val_m['false_air'])\n    history['val_struct_recall'].append(val_m['struct_recall'])\n    history['val_vol_ratio'].append(val_m['vol_ratio'])\n    history['phase'].append(phase)\n    \n    # Best model - now track STRUCTURE RECALL (shape preservation) as the key metric\n    if val_m['struct_recall'] > best_struct_recall:\n        best_struct_recall = val_m['struct_recall']\n        best_epoch = epoch + 1\n        torch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v4_best.pt\")\n    \n    # Log - now with shape preservation metrics\n    emb_status = \"FROZEN\" if phase == \"warmup\" else \"TRAIN\"\n    print(f\"Epoch {epoch+1:2d} [{phase:6s}] | \"\n          f\"Recall: {train_m['struct_recall']:.1%}/{val_m['struct_recall']:.1%} | \"\n          f\"FalseAir: {train_m['false_air']:.1%}/{val_m['false_air']:.1%} | \"\n          f\"Vol: {val_m['vol_ratio']:.2f} | \"\n          f\"Exact: {val_m['struct_exact']:.1%} | \"\n          f\"CB: {val_m['cb_usage']:.0%}\")\n\ntrain_time = time.time() - start_time\nprint(f\"\\nTraining complete in {train_time/60:.1f} minutes\")\nprint(f\"Best val struct_recall: {best_struct_recall:.1%} at epoch {best_epoch}\")\nprint(f\"\\n*** KEY METRIC: Structure Recall = {best_struct_recall:.1%} ***\")\nprint(\"(This measures: of all blocks that SHOULD be structure, how many were NOT erased)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 9: Plot Training Curves - Shape Preservation Focus\n# ============================================================\n\nfig, axes = plt.subplots(2, 4, figsize=(20, 8))\n\nepochs = range(1, TOTAL_EPOCHS + 1)\n\n# Plot 1: STRUCTURE RECALL (THE KEY METRIC)\nax = axes[0, 0]\nax.plot(epochs, history['train_struct_recall'], 'b-', label='Train', linewidth=2)\nax.plot(epochs, history['val_struct_recall'], 'r--', label='Val', linewidth=2)\nax.axvline(x=WARMUP_EPOCHS, color='gray', linestyle=':', label='Warmup end')\nax.axhline(y=0.9, color='green', linestyle='--', alpha=0.5, label='Target (90%)')\nax.set_title('Structure Recall (KEY METRIC)', fontweight='bold')\nax.set_xlabel('Epoch')\nax.set_ylabel('Recall')\nax.legend()\nax.grid(True, alpha=0.3)\nax.set_ylim(0, 1)\n\n# Plot 2: FALSE AIR RATE (lower is better)\nax = axes[0, 1]\nax.plot(epochs, history['train_false_air'], 'b-', label='Train')\nax.plot(epochs, history['val_false_air'], 'r--', label='Val')\nax.axvline(x=WARMUP_EPOCHS, color='gray', linestyle=':')\nax.axhline(y=0.1, color='green', linestyle='--', alpha=0.5, label='Target (<10%)')\nax.set_title('False Air Rate (lower=better)')\nax.set_xlabel('Epoch')\nax.set_ylabel('Rate')\nax.legend()\nax.grid(True, alpha=0.3)\nax.set_ylim(0, 1)\n\n# Plot 3: Volume Ratio (want close to 1.0)\nax = axes[0, 2]\nax.plot(epochs, history['train_vol_ratio'], 'b-', label='Train')\nax.plot(epochs, history['val_vol_ratio'], 'r--', label='Val')\nax.axvline(x=WARMUP_EPOCHS, color='gray', linestyle=':')\nax.axhline(y=1.0, color='green', linestyle='--', alpha=0.5, label='Target (1.0)')\nax.set_title('Volume Ratio (1.0=perfect)')\nax.set_xlabel('Epoch')\nax.set_ylabel('Ratio')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Plot 4: Structure accuracy (exact vs similarity)\nax = axes[0, 3]\nax.plot(epochs, history['train_struct_exact'], 'b-', label='Train Exact')\nax.plot(epochs, history['val_struct_exact'], 'b--', label='Val Exact')\nax.plot(epochs, history['train_struct_sim'], 'g-', label='Train Sim')\nax.plot(epochs, history['val_struct_sim'], 'g--', label='Val Sim')\nax.axvline(x=WARMUP_EPOCHS, color='gray', linestyle=':')\nax.set_title('Structure Accuracy')\nax.set_xlabel('Epoch')\nax.set_ylabel('Accuracy')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Plot 5: Loss\nax = axes[1, 0]\nax.plot(epochs, history['train_loss'], 'b-', label='Train')\nax.plot(epochs, history['val_loss'], 'r--', label='Val')\nax.axvline(x=WARMUP_EPOCHS, color='gray', linestyle=':')\nax.set_title('Total Loss')\nax.set_xlabel('Epoch')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Plot 6: Codebook usage\nax = axes[1, 1]\nax.plot(epochs, history['train_cb_usage'], 'b-', label='Train')\nax.plot(epochs, history['val_cb_usage'], 'r--', label='Val')\nax.axhline(y=0.3, color='gray', linestyle='--', alpha=0.5)\nax.axvline(x=WARMUP_EPOCHS, color='gray', linestyle=':')\nax.set_title('Codebook Usage')\nax.set_xlabel('Epoch')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Plot 7: Perplexity\nax = axes[1, 2]\nax.plot(epochs, history['train_perplexity'], 'b-', label='Train')\nax.plot(epochs, history['val_perplexity'], 'r--', label='Val')\nax.axvline(x=WARMUP_EPOCHS, color='gray', linestyle=':')\nax.set_title('Codebook Perplexity')\nax.set_xlabel('Epoch')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Plot 8: Final comparison bar - SHAPE PRESERVATION FOCUS\nax = axes[1, 3]\nfinal_metrics = {\n    'Struct\\nRecall': history['val_struct_recall'][-1],\n    '1-False\\nAir': 1 - history['val_false_air'][-1],\n    'Exact\\nAcc': history['val_struct_exact'][-1],\n    'Sim\\nAcc': history['val_struct_sim'][-1],\n}\ncolors = ['green', 'orange', 'blue', 'purple']\nbars = ax.bar(final_metrics.keys(), final_metrics.values(), color=colors)\nax.set_title('Final Metrics (Shape Focus)')\nax.set_ylabel('Score')\nax.set_ylim(0, 1)\nfor bar, val in zip(bars, final_metrics.values()):\n    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n            f'{val:.1%}', ha='center', fontsize=9)\n\nplt.tight_layout()\nplt.savefig(f\"{OUTPUT_DIR}/vqvae_v4_training.png\", dpi=150, bbox_inches='tight')\nplt.show()\n\n# Summary\nprint(\"\\n\" + \"=\"*60)\nprint(\"SHAPE PRESERVATION SUMMARY\")\nprint(\"=\"*60)\nprint(f\"Structure Recall: {history['val_struct_recall'][-1]:.1%} (target: >90%)\")\nprint(f\"False Air Rate:   {history['val_false_air'][-1]:.1%} (target: <10%)\")\nprint(f\"Volume Ratio:     {history['val_vol_ratio'][-1]:.2f} (target: ~1.0)\")\nprint(f\"Exact Accuracy:   {history['val_struct_exact'][-1]:.1%}\")\nprint(f\"Sim Accuracy:     {history['val_struct_sim'][-1]:.1%}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CELL 10: Save Results and Checkpoint\n# ============================================================\n\nresults = {\n    'config': {\n        'hidden_dims': HIDDEN_DIMS,\n        'latent_dim': LATENT_DIM,\n        'num_codes': NUM_CODEBOOK_ENTRIES,\n        'total_epochs': TOTAL_EPOCHS,\n        'warmup_epochs': WARMUP_EPOCHS,\n        'batch_size': BATCH_SIZE,\n        'base_lr': BASE_LR,\n        'embedding_lr_scale': EMBEDDING_LR_SCALE,\n        'embedding_loss_alpha': EMBEDDING_LOSS_ALPHA,\n        'stability_weight': STABILITY_WEIGHT,\n        'diversity_weight': DIVERSITY_WEIGHT,\n        'structure_weight': STRUCTURE_WEIGHT,\n        # NEW shape preservation config\n        'false_air_weight': FALSE_AIR_WEIGHT,\n        'volume_weight': VOLUME_WEIGHT,\n        'structure_to_air_weight': STRUCTURE_TO_AIR_WEIGHT,\n        'use_shape_loss': USE_SHAPE_LOSS,\n        'use_asymmetric_loss': USE_ASYMMETRIC_LOSS,\n        'seed': SEED,\n    },\n    'results': {\n        # Shape preservation metrics (THE KEY METRICS)\n        'best_struct_recall': float(best_struct_recall),\n        'best_epoch': best_epoch,\n        'final_struct_recall': float(history['val_struct_recall'][-1]),\n        'final_false_air_rate': float(history['val_false_air'][-1]),\n        'final_vol_ratio': float(history['val_vol_ratio'][-1]),\n        # Original metrics\n        'final_struct_exact': float(history['val_struct_exact'][-1]),\n        'final_struct_sim': float(history['val_struct_sim'][-1]),\n        'final_cb_usage': float(history['val_cb_usage'][-1]),\n        'final_perplexity': float(history['val_perplexity'][-1]),\n        'training_time_min': float(train_time / 60),\n    },\n    'history': {k: [float(x) if isinstance(x, (int, float)) else x for x in v] \n                for k, v in history.items()},\n}\n\nwith open(f\"{OUTPUT_DIR}/vqvae_v4_results.json\", 'w') as f:\n    json.dump(results, f, indent=2)\n\n# Save complete checkpoint with all metadata for visualization script\ncheckpoint = {\n    'model_state_dict': model.state_dict(),\n    'config': {\n        'vocab_size': VOCAB_SIZE,\n        'emb_dim': EMBEDDING_DIM,\n        'hidden_dims': HIDDEN_DIMS,\n        'latent_dim': LATENT_DIM,\n        'num_codes': NUM_CODEBOOK_ENTRIES,\n        'embedding_loss_alpha': EMBEDDING_LOSS_ALPHA,\n        'stability_weight': STABILITY_WEIGHT,\n        'diversity_weight': DIVERSITY_WEIGHT,\n        'false_air_weight': FALSE_AIR_WEIGHT,\n        'volume_weight': VOLUME_WEIGHT,\n        'structure_to_air_weight': STRUCTURE_TO_AIR_WEIGHT,\n        'dropout': DROPOUT,\n        'commitment_cost': COMMITMENT_COST,\n        'ema_decay': EMA_DECAY,\n    },\n    'air_tokens': AIR_TOKENS_LIST,\n    'best_struct_recall': float(best_struct_recall),\n    'best_epoch': best_epoch,\n    'training_time_min': float(train_time / 60),\n}\n\n# Save best and final checkpoints\ntorch.save(checkpoint, f\"{OUTPUT_DIR}/vqvae_v4_best_checkpoint.pt\")\n\ncheckpoint['model_state_dict'] = model.state_dict()  # Update to final state\ntorch.save(checkpoint, f\"{OUTPUT_DIR}/vqvae_v4_final_checkpoint.pt\")\n\n# Also save just the state dict for backwards compatibility\ntorch.save(model.state_dict(), f\"{OUTPUT_DIR}/vqvae_v4_final.pt\")\n\nprint(\"\\nResults saved:\")\nprint(f\"  - {OUTPUT_DIR}/vqvae_v4_results.json\")\nprint(f\"  - {OUTPUT_DIR}/vqvae_v4_best_checkpoint.pt (full checkpoint)\")\nprint(f\"  - {OUTPUT_DIR}/vqvae_v4_final_checkpoint.pt (full checkpoint)\")\nprint(f\"  - {OUTPUT_DIR}/vqvae_v4_final.pt (state dict only)\")\nprint(f\"  - {OUTPUT_DIR}/vqvae_v4_training.png\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"FINAL RESULTS - SHAPE PRESERVATION\")\nprint(\"=\"*70)\nprint(f\"Best structure recall:     {best_struct_recall:.1%} (epoch {best_epoch})\")\nprint(f\"Final structure recall:    {history['val_struct_recall'][-1]:.1%}\")\nprint(f\"Final false air rate:      {history['val_false_air'][-1]:.1%}\")\nprint(f\"Final volume ratio:        {history['val_vol_ratio'][-1]:.2f}\")\nprint(f\"Final structure exact acc: {history['val_struct_exact'][-1]:.1%}\")\nprint(f\"Final codebook usage:      {history['val_cb_usage'][-1]:.1%}\")\nprint(f\"Training time:             {train_time/60:.1f} minutes\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"INTERPRETATION\")\nprint(\"=\"*70)\nprint(\"Structure Recall: % of original building blocks NOT erased\")\nprint(\"  - Target: >90% (buildings should be preserved)\")\nprint(\"  - If low: model is still erasing buildings -> increase shape loss weights\")\nprint()\nprint(\"False Air Rate: % of structure blocks wrongly predicted as air\")\nprint(\"  - Target: <10% (minimal building erasure)\")\nprint(\"  - This is 1 - Structure Recall\")\nprint()\nprint(\"Volume Ratio: predicted_volume / original_volume\")\nprint(\"  - Target: ~1.0 (same amount of blocks)\")\nprint(\"  - <1.0 means buildings shrunk, >1.0 means extra blocks added\")\n\nprint(\"\\n--- NEXT STEPS ---\")\nprint(\"Download vqvae_v4_best_checkpoint.pt and use with visualization script:\")\nprint(\"  python scripts/visualize_reconstruction_mcp.py \\\\\")\nprint(\"      --checkpoint vqvae_v4_best_checkpoint.pt \\\\\")\nprint(\"      --h5-file path/to/build.h5 \\\\\")\nprint(\"      --output commands.txt\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}